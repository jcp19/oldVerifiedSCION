// Copyright 2020 Anapaya Systems
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package router

import (
	"bytes"
	// "crypto/rand"
	"errors"
	// "fmt"
	// "hash"
	// "math/big"
	"net"
	"strconv"
	"sync"
	"time"

	// "github.com/google/gopacket"
	"gobra/dependencies/gopacket"
	// "github.com/google/gopacket/layers"
	"gobra/dependencies/gopacket/layers"
	// "github.com/prometheus/client_golang/prometheus"
	"gobra/dependencies/prometheus/client_golang/prometheus"
	// "golang.org/x/net/ipv4"
	"gobra/dependencies/x/net/ipv4"

	// "github.com/scionproto/scion/go/lib/addr"
	"gobra/lib/addr"
	// "github.com/scionproto/scion/go/lib/common"
	"gobra/lib/common"
	// "github.com/scionproto/scion/go/lib/log"
	// "github.com/scionproto/scion/go/lib/metrics"
	"gobra/lib/metrics"
	// "github.com/scionproto/scion/go/lib/scrypto"
	// "github.com/scionproto/scion/go/lib/serrors"
	"gobra/lib/serrors"
	// "github.com/scionproto/scion/go/lib/slayers"
	"gobra/lib/slayers"
	// "github.com/scionproto/scion/go/lib/slayers/path"
	"gobra/lib/slayers/path"
	// "github.com/scionproto/scion/go/lib/slayers/path/empty"
	"gobra/lib/slayers/path/empty"
	// "github.com/scionproto/scion/go/lib/slayers/path/onehop"
	"gobra/lib/slayers/path/onehop"
	// "github.com/scionproto/scion/go/lib/slayers/path/scion"
	"gobra/lib/slayers/path/scion"
	// "github.com/scionproto/scion/go/lib/topology"
	"gobra/lib/topology"
	// "github.com/scionproto/scion/go/lib/underlay/conn"
	"gobra/lib/underlay/conn"
	// underlayconn "github.com/scionproto/scion/go/lib/underlay/conn"
	underlayconn "gobra/lib/underlay/conn"
	// "github.com/scionproto/scion/go/lib/util"
	"gobra/lib/util"
	// "github.com/scionproto/scion/go/pkg/router/bfd"
	"gobra/pkg/router/bfd"
	// "github.com/scionproto/scion/go/pkg/router/control"
	"gobra/pkg/router/control"

	"gobra/verifyutils"
)

const (
	// Number of packets to read in a single ReadBatch call.
	inputBatchCnt = 64

	// TODO(karampok). Investigate whether that value should be higher.  In
	// theory, PayloadLen in SCION header is 16 bits long, supporting a maximum
	// payload size of 64KB. At the moment we are limited by Ethernet size
	// usually ~1500B, but 9000B to support jumbo frames.
	bufSize = 9000

	// hopFieldDefaultExpTime is the default validity of the hop field
	// and 63 is equivalent to 6h.
	hopFieldDefaultExpTime = 63
)

// (tlino) The scion code base uses a reference implementation of this interface.
// (tlino) This reference implementation is thread-safe.
// (tlino) Thus, it is fine to use wildcard permissions
type bfdSession interface {
	pred Mem()

	requires acc(Mem(), _)
	decreases
	Run() (err error)

	requires acc(Mem(), _)
	ensures  acc(c.SendChannel(), _) && c.SendGivenPerm() == (*layers.BFD).MemWithOutSlices!<_!>;
	decreases
	Messages() (c chan<- *layers.BFD)

	pure
	requires acc(Mem(), _)
	decreases
	IsUp() bool
}

// BatchConn is a connection that supports batch reads and writes.
type BatchConn interface {
	pred Mem()

	preserves acc(Mem(), _)
	preserves msgs.Mem()
	preserves forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
	ensures err == nil ==> 0 <= n && n <= len(msgs) && n <= len(metas)
	ReadBatch(msgs underlayconn.Messages, metas []underlayconn.ReadMeta) (n int, err error)

	preserves acc(Mem(), _)
	preserves acc(msgs.MemSend(), 1/1000)
	ensures err == nil ==> 0 <= n && n <= len(msgs)
	decreases
	WriteBatch(msgs underlayconn.Messages) (n int, err error)

	requires Mem()
	Close() error
}

// DataPlane contains a SCION Border Router's forwarding logic. It reads packets
// from multiple sockets, performs routing, and sends them to their destinations
// (after updating the path, if that is needed).
//
// XXX(lukedirtwalker): this is still in development and not feature complete.
// Currently, only the following features are supported:
//  - initializing connections; MUST be done prior to calling Run
type DataPlane struct {
	external         map[uint16]BatchConn
	linkTypes        map[uint16]topology.LinkType
	neighborIAs      map[uint16]addr.IA
	internal         BatchConn
	internalIP       net.IP
	internalNextHops map[uint16]net.Addr
	svc              *services
//	macFactory       func() hash.Hash
	bfdSessions      map[uint16]bfdSession
	localIA          addr.IA
	mtx              sync.Mutex
	running          bool
	Metrics          *Metrics
}

pred BatchConnsAcc(batchConns map[uint16]BatchConn) {
	batchConns != nil ==> acc(batchConns) &&
	forall btc BatchConn :: btc in range(batchConns) ==> btc.Mem()
}

pred AddrsAcc(addrs map[uint16]net.Addr) {
	addrs != nil ==> acc(addrs) &&
	forall add net.Addr :: add in range(addrs) ==> add.Mem()
}

pred BfdSessionsAcc(bfdSessions map[uint16]bfdSession) {
	bfdSessions != nil ==> acc(bfdSessions) &&
	forall bfd bfdSession :: bfd in range(bfdSessions) ==> bfd.Mem()
}

pred DataPlaneMutexInvariant(d *DataPlane) {
	// access to mtx field ommited
	acc(&d.external) &&
	acc(&d.linkTypes) &&
	acc(&d.neighborIAs) &&
	acc(&d.internal) &&
	acc(&d.internalIP) &&
	acc(&d.internalNextHops) &&
	acc(&d.svc) &&
	acc(&d.bfdSessions) &&
	acc(&d.localIA) &&
	acc(&d.running) &&
	acc(&d.Metrics) &&
	(d.linkTypes != nil ==> acc(d.linkTypes)) &&
	(d.neighborIAs != nil ==> acc(d.neighborIAs)) &&
	(d.svc != nil ==> (d.svc).Mem()) &&
	BfdSessionsAcc(d.bfdSessions) &&
	BatchConnsAcc(d.external) &&
	AddrsAcc(d.internalNextHops) &&
	(d.internal != nil ==> d.internal.Mem()) &&
	(d.Metrics != nil ==> d.Metrics.Mem())
}

// (tlino) start of added getters and setters for DataPlane to simplify verification
requires acc(DataPlaneMutexInvariant(d), _)
decreases
pure func (d *DataPlane) GetLocalAI() addr.IA {
	return unfolding acc(DataPlaneMutexInvariant(d), _) in d.localIA
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures res != nil ==> acc(res.Mem(), _)
decreases
func (d *DataPlane) getInternal() (res BatchConn) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	return d.internal
}

requires acc(DataPlaneMutexInvariant(d), _)
ensures res == unfolding acc(DataPlaneMutexInvariant(d), _) in d.running
decreases
pure func (d *DataPlane) isRunning() (res bool) {
	return unfolding acc(DataPlaneMutexInvariant(d), _) in d.running
}

requires acc(DataPlaneMutexInvariant(d), _)
ensures res == unfolding acc(DataPlaneMutexInvariant(d), _) in (d.linkTypes)[intf]
decreases
pure func (d *DataPlane) GetLinkType(intf uint16) (res topology.LinkType) {
	return unfolding acc(DataPlaneMutexInvariant(d), _) in (d.linkTypes)[intf]
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures res != nil ==> acc(res, _)
decreases
func (d *DataPlane) GetNeighborIAs() (res map[uint16]addr.IA) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	res = d.neighborIAs
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures ok ==> acc(add.Mem(), _)
decreases
func (d *DataPlane) GetInternalNextHop(intf uint16) (add net.Addr, ok bool) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(AddrsAcc(d.internalNextHops), _)
	add, ok = (d.internalNextHops)[intf]
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures ok ==> acc(btc.Mem(), _)
decreases
func (d *DataPlane) GetExternalBatchConn(intf uint16) (btc BatchConn, ok bool) {
    unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BatchConnsAcc(d.external), _)
    btc, ok = (d.external)[intf]
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures ok ==> acc(bfd.Mem(), _)
decreases
func (d *DataPlane) GetBfdSession(intf uint16) (bfd bfdSession, ok bool) {
    unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BfdSessionsAcc(d.bfdSessions), _)
    bfd, ok = (d.bfdSessions)[intf]
}
// (tlino) end of added getter and setter methods for DataPlane

// (tlino) added ghost method to create a *DataPlane object and its invariant
ghost
ensures DataPlaneMutexInvariant(res)
decreases
func soundDataPlaneMutexInvariant() (res *DataPlane) {
	d@ := DataPlane{}
	res = &d
	fold BfdSessionsAcc(d.bfdSessions)
	fold BatchConnsAcc(d.external)
	fold AddrsAcc(d.internalNextHops) 
	fold DataPlaneMutexInvariant(res)
}

//var (
//	alreadySet                    = serrors.New("already set")
//	cannotRoute                   = serrors.New("cannot route, dropping pkt")
//	emptyValue                    = serrors.New("empty value")
//	malformedPath                 = serrors.New("malformed path content")
//	modifyExisting                = serrors.New("modifying a running dataplane is not allowed")
//	noSVCBackend                  = serrors.New("cannot find internal IP for the SVC")
//	unsupportedPathType           = serrors.New("unsupported path type")
//	unsupportedPathTypeNextHeader = serrors.New("unsupported combination")
//	noBFDSessionFound             = serrors.New("no BFD sessions was found")
//	noBFDSessionConfigured        = serrors.New("no BFD sessions have been configured")
//	errBFDDisabled                = serrors.New("BFD is disabled")
//)

/** Globals **/
// (joao): begin alternative to final global variables defined in the previous var block
ensures isComparable(e) && e != nil
decreases
func alreadySet() (e error) { return serrors.New("already set") }

ensures isComparable(e) && e != nil
decreases
func cannotRoute() (e error) { return serrors.New("cannot route, dropping pkt") }

ensures isComparable(e) && e != nil
decreases
func emptyValue() (e error) { return serrors.New("empty value") }

ensures isComparable(e) && e != nil
decreases
func malformedPath() (e error) { return serrors.New("malformed path content") }

ensures isComparable(e) && e != nil
decreases
func modifyExisting() (e error) { return serrors.New("modifying a running dataplane is not allowed") }

ensures isComparable(e) && e != nil
decreases
func noSVCBackend() (e error) { return serrors.New("cannot find internal IP for the SVC") }

ensures isComparable(e) && e != nil
decreases
func unsupportedPathType() (e error) { return serrors.New("unsupported path type") }

ensures isComparable(e) && e != nil
decreases
func unsupportedPathTypeNextHeader() (e error) { return serrors.New("unsupported combination") }

ensures isComparable(e) && e != nil
decreases
func noBFDSessionFound() (e error) { return serrors.New("no BFD sessions was found") }

ensures isComparable(e) && e != nil
decreases
func noBFDSessionConfigured() (e error) { return serrors.New("no BFD sessions have been configured") }

ensures isComparable(e) && e != nil
decreases
func errBFDDisabled() (e error) { return serrors.New("BFD is disabled") }

// (tlino) added this error
pure
ensures isComparable(e) && e != nil
decreases
func invalidDstAddr() (e error)
/** End of Globals **/

type scmpError struct {
	TypeCode slayers.SCMPTypeCode
	Cause    error
}

// (tlino) TODO: built in error.Error() needs to terminate
decreases _
func (e scmpError) Error() string {
	return (serrors.New("scmp", "typecode", e.TypeCode, "cause", e.Cause)).Error()
}

// (joao) Verified
// SetIA sets the local IA for the dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) SetIA(ia addr.IA) error {
	d.mtx.Lock()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if ia.IsZero() {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	if !d.localIA.IsZero() {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return alreadySet
		return alreadySet()
	}
	d.localIA = ia
	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Partially Verified
// SetKey sets the key used for MAC verification. The key provided here should
// already be derived as in scrypto.HFMacFactory.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) SetKey(key []byte) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if len(key) == 0 {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) macFactory still not supported
	// if d.macFactory != nil {
	// 	return alreadySet
	// }
	// // First check for MAC creation errors.
	// if _, err := scrypto.InitMac(key); err != nil {
	// 	return err
	// }
	// d.macFactory = func() hash.Hash {
	// 	mac, _ := scrypto.InitMac(key)
	// return mac
	// }

	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddInternalInterface sets the interface the data-plane will use to
// send/receive traffic in the local AS. This can only be called once; future
// calls will return an error. This can only be called on a not yet running
// dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
requires conn.Mem()
ensures  d.mtx.LockP()
func (d *DataPlane) AddInternalInterface(conn BatchConn, ip net.IP) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	if d.internal != nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return alreadySet
		return alreadySet()
	}
	d.internal = conn
	d.internalIP = ip
	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddExternalInterface adds the inter AS connection for the given interface ID.
// If a connection for the given ID is already set this method will return an
// error. This can only be called on a not yet running dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
requires conn.Mem()
ensures  d.mtx.LockP()
func (d *DataPlane) AddExternalInterface(ifID uint16, conn BatchConn) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code:
	// if _, exists := d.external[ifID]; exists {
	// 		return serrors.WithCtx(alreadySet, "ifID", ifID)
	unfold BatchConnsAcc(d.external)
	if _, exists := (d.external)[ifID]; exists {
		// (joao) no support for defer
		fold BatchConnsAcc(d.external)
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.external == nil {
		d.external = make(map[uint16]BatchConn)
	}
	// (joao) add parentheses surrounding `d.external` to make it parse
 	(d.external)[ifID] = conn
	// (joao) no support for defer
	fold BatchConnsAcc(d.external)
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddNeighborIA adds the neighboring IA for a given interface ID. If an IA for
// the given ID is already set, this method will return an error. This can only
// be called on a yet running dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddNeighborIA(ifID uint16, remote addr.IA) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) defer not supported
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if remote.IsZero() {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code (changed below):
	// if _, exists := d.neighborIAs[ifID]; exists {
	// 	return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	if _, exists := (d.neighborIAs)[ifID]; exists {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.neighborIAs == nil {
		d.neighborIAs = make(map[uint16]addr.IA)
	}
	// (joao) add parentheses surrounding `d.neighborIAs` to make it parse
	(d.neighborIAs)[ifID] = remote
	// (joao) Unlock explictly added, no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddLinkType adds the link type for a given interface ID. If a link type for
// the given ID is already set, this method will return an error. This can only
// be called on a not yet running dataplane.
requires DataPlaneMutexInvariant(d)
ensures DataPlaneMutexInvariant(d)
func (d *DataPlane) AddLinkType(ifID uint16, linkTo topology.LinkType) error {
	// (joao) original code (changed below):
	// if _, exists := d.linkTypes[ifID]; exists {
	// 	return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	unfold DataPlaneMutexInvariant(d)
	if _, exists := (d.linkTypes)[ifID]; exists {
		fold DataPlaneMutexInvariant(d)
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.linkTypes == nil {
		d.linkTypes = make(map[uint16]topology.LinkType)
	}
	// (joao) added parentheses around d.linkTypes to make it parse
	(d.linkTypes)[ifID] = linkTo
	fold DataPlaneMutexInvariant(d)
	return nil
}

// (joao) Partially Verified
// AddExternalInterfaceBFD adds the inter AS connection BFD session.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddExternalInterfaceBFD(ifID uint16, conn BatchConn,
	src, dst control.LinkEnd, cfg control.BFD) error {
	d.mtx.Lock()
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	var m bfd.Metrics
	// if d.Metrics != nil {
	//	labels := []string{
	//		"interface", /* fmt.Sprint(ifID), */ // (joao) fmt Not supported yet
	//		"isd_as", d.localIA.String(),
	//		"neighbor_isd_as", dst.IA.String(),
	//	}
	//	// (joao) without these variables, Gobra cannot parse the following code
	//	tmpMetrics1 := d.Metrics.InterfaceUp
	//	tmpMetrics2 := d.Metrics.BFDInterfaceStateChanges
	//	tmpMetrics3 := d.Metrics.BFDPacketsSent
	//	tmpMetrics4 := d.Metrics.BFDPacketsReceived
	//	m = bfd.Metrics{
	//		Up: (metrics.NewPromGauge(/*d.Metrics.InterfaceUp*/ tmpMetrics1)).With(labels...),
	//		StateChanges: (metrics.NewPromCounter(/*d.Metrics.BFDInterfaceStateChanges*/ tmpMetrics2)).With(labels...),
	//		PacketsSent: (metrics.NewPromCounter(/*d.Metrics.BFDPacketsSent*/ tmpMetrics3)).With(labels...),
	//		PacketsReceived: (metrics.NewPromCounter(/*d.Metrics.BFDPacketsReceived*/tmpMetrics4)).With(labels...),
	//	}
	//}
	s := &bfdSend{
		conn:       conn,
		// srcAddr:    src.Addr,
		// dstAddr:    dst.Addr,
		srcIA:      src.IA,
		dstIA:      dst.IA,
		ifID:       ifID,
		// macFactory: d.macFactory,
	}
	// (joao) rewrote to unfold before returning. Original code:
	// return d.addBFDController(ifID, s, cfg, m)
	// changed code:
	fold DataPlaneMutexInvariant(d)
	res := d.addBFDController(ifID, s, cfg, m)
	unfold DataPlaneMutexInvariant(d)
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return res
}

// (joao) Partially Verified
// TODO: specify `rand`
preserves DataPlaneMutexInvariant(d)
func (d *DataPlane) addBFDController(ifID uint16, s *bfdSend, cfg control.BFD,
	metrics bfd.Metrics) error {
	unfold DataPlaneMutexInvariant(d)
	if cfg.Disable {
		fold DataPlaneMutexInvariant(d)
		// return errBFDDisabled
		return errBFDDisabled()
	}
	unfold BfdSessionsAcc(d.bfdSessions)
	if d.bfdSessions == nil {
		d.bfdSessions = make(map[uint16]bfdSession)
	}

	// // Generate random discriminator. It can't be zero.
	// discInt, err := rand.Int(rand.Reader, big.NewInt(0xfffffffe))
	// if err != nil {
	// 	return err
	// }
	// disc := layers.BFDDiscriminator(uint32(discInt.Uint64()) + 1)
	// d.bfdSessions[ifID] = &bfd.Session{
	// 	Sender:                s,
	// 	DetectMult:            layers.BFDDetectMultiplier(cfg.DetectMult),
	// 	Logger:                log.New("component", "BFD"),
	// 	DesiredMinTxInterval:  cfg.DesiredMinTxInterval,
	// 	RequiredMinRxInterval: cfg.RequiredMinRxInterval,
	// 	LocalDiscriminator:    disc,
	// 	ReceiveQueueSize:      10,
	// 	Metrics:               metrics,
	// }
	fold BfdSessionsAcc(d.bfdSessions)
	fold DataPlaneMutexInvariant(d)
	return nil
}

// (tlino) Verified
// AddSvc adds the address for the given service. This can be called multiple
// times for the same service, with the address added to the list of addresses
// that provide the service.
requires d.mtx.LockP() && acc(a.Mem(), _)
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddSvc(svc addr.HostSVC, a *net.UDPAddr) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// defer d.mtx.Unlock()
	if a == nil {
		// return emptyValue
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return emptyValue()
	}
	if d.svc == nil {
		d.svc = newServices()
	}
	d.svc.AddSvc(svc, a)
	if d.Metrics != nil {
		labels := serviceMetricLabels(d.localIA, svc)
		unfold d.Metrics.Mem()
		// (tlino) use explicit cast to float64, since gobra cannot cast the
		// (tlino) integer argument by default
		// d.Metrics.ServiceInstanceChanges.With(labels).Add(1)
		// d.Metrics.ServiceInstanceCount.With(labels).Add(1)
		(d.Metrics.ServiceInstanceChanges.With(labels)).Add(float64(1))
		(d.Metrics.ServiceInstanceCount.With(labels)).Add(float64(1))
		fold d.Metrics.Mem()
	}
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (tlino) Verified
// DelSvc deletes the address for the given service.
requires d.mtx.LockP() && acc(a.Mem(), _)
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) DelSvc(svc addr.HostSVC, a *net.UDPAddr) error {
	d.mtx.Lock()
	// defer d.mtx.Unlock()
	if a == nil {
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	unfold DataPlaneMutexInvariant!<d!>()
	if d.svc == nil {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return nil
	}
	d.svc.DelSvc(svc, a)
	if d.Metrics != nil {
		labels := serviceMetricLabels(d.localIA, svc)
		unfold d.Metrics.Mem()
		// d.Metrics.ServiceInstanceChanges.With(labels).Add(1)
		// d.Metrics.ServiceInstanceCount.With(labels).Add(-1)
		(d.Metrics.ServiceInstanceChanges.With(labels)).Add(float64(1))
		(d.Metrics.ServiceInstanceCount.With(labels)).Add(float64(-1))
		fold d.Metrics.Mem()
	}
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddNextHop sets the next hop address for the given interface ID. If the
// interface ID already has an address associated this operation fails. This can
// only be called on a not yet running dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
requires a.Mem()
ensures  d.mtx.LockP()
func (d *DataPlane) AddNextHop(ifID uint16, a net.Addr) error {
	d.mtx.Lock()
	// (joao) defer not supported
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}
	if a == nil {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code (changed below):
	// if _, exists := d.internalNextHops[ifID]; exists {
	//	 return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	unfold AddrsAcc(d.internalNextHops)
	if _, exists := (d.internalNextHops)[ifID]; exists {
		// (joao) Unlock explictly added, no support for defer
		fold AddrsAcc(d.internalNextHops)
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.internalNextHops == nil {
		d.internalNextHops = make(map[uint16]net.Addr)
	}
	// d.internalNextHops[ifID] = a
	(d.internalNextHops)[ifID] = a
	// (joao) Unlock explictly added, no support for defer
	fold AddrsAcc(d.internalNextHops)
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) WIP
// AddNextHopBFD adds the BFD session for the next hop address.
// If the remote ifID belongs to an existing address, the existing
// BFD session will be re-used.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddNextHopBFD(ifID uint16, src, dst *net.UDPAddr, cfg control.BFD,
	sibling string) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}

	if dst == nil {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}

	assume false
	// (joao) the following code is still not supported
	/*
	for k, v := range d.internalNextHops {
		if v.String() == dst.String() {
			if c, ok := d.bfdSessions[k]; ok {
				d.bfdSessions[ifID] = c
				return nil
			}
		}
	}
	*/
	var m bfd.Metrics
	if d.Metrics != nil {
		labels := []string{"isd_as", d.localIA.String(), "sibling", sibling}
		tmpMetrics1 := d.Metrics.SiblingReachable
		tmpMetrics2 := d.Metrics.SiblingBFDStateChanges
		tmpMetrics3 := d.Metrics.SiblingBFDPacketsSent
		tmpMetrics4 := d.Metrics.SiblingBFDPacketsReceived
		m = bfd.Metrics{
			Up: (metrics.NewPromGauge(/*d.Metrics.SiblingReachable*/ tmpMetrics1)).With(labels...),
			StateChanges: (metrics.NewPromCounter(/*d.Metrics.SiblingBFDStateChanges*/ tmpMetrics2)).With(labels...),
			PacketsSent: (metrics.NewPromCounter(/*d.Metrics.SiblingBFDPacketsSent*/ tmpMetrics3)).With(labels...),
			PacketsReceived: (metrics.NewPromCounter(/*d.Metrics.SiblingBFDPacketsReceived*/ tmpMetrics4)).With(labels...),
		}
	}
	s := &bfdSend{
		conn:       d.internal,
		srcAddr:    src,
		dstAddr:    dst,
		srcIA:      d.localIA,
		dstIA:      d.localIA,
		ifID:       0,
		// macFactory: d.macFactory,
	}
	return d.addBFDController(ifID, s, cfg, m)
}

// (tlino) Verified
// Run starts running the dataplane. Note that configuration is not possible
// after calling this method.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
func (d *DataPlane) Run() error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	d.running = true
	fold DataPlaneMutexInvariant(d)

	// (tlino) When the border router is running, then it requires that d.Metrics, d.svc, and d.internal are not nil.
	// (tlino) At the moment there is no way to encode this in the precondition of the method, since we cannot
	// (tlino) unfold DataPlaneMutexInvariant!<d!> without aqcuiring a d.mtx.
	assume unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil && d.internal != nil

	d.initMetrics()

	// (joao) At this point, there used to be a closure definition, saved in a variable called "read"
	// (tlino) The closure is replaced by the function RunReadClosure

	// (tlino) range, closures, and the log package are not supported yet, adapted code is below
	// for k, v := range d.bfdSessions {
	// 	go func(ifID uint16, c bfdSession) {
	// 		defer log.HandlePanic()
	// 		if err := c.Run(); err != nil && err != bfd.AlreadyRunning {
	// 			log.Error("BFD session failed to start", "ifID", ifID, "err", err)
	// 		}
	// 	}(k, v)
	// }

	mapKeyUpperBound := 65536

	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		key := uint16(k)
		bfdSess, found := d.GetBfdSession(key)
		if found {
			go bfdLauncher(bfdSess)
		}
	}
	// (tlino) range, closures, and the log package are not supported yet, adapted code is below
	// for ifID, v := range d.external {
	// 	go func(i uint16, c BatchConn) {
	// 		defer log.HandlePanic()
	// 		read(i, c)
	// 	}(ifID, v)
	// }
	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		key := uint16(k)
		batchConn, found := d.GetExternalBatchConn(key)
		if found {
			go RunReadClosure(key, batchConn, d)
		}
	}
	
	// (tlino) log.HandlePanic() not supported, adaped code is below
	// go func(c BatchConn) {
	// 	defer log.HandlePanic()
	// 	read(0, c)
	// }(d.internal)
	unfold acc(DataPlaneMutexInvariant(d), _)
	go RunReadClosure(0, d.internal, d)
	
 	// // (joao) This unlock here is problematic: it gives back access to the lock invariant, and thus, it should not
	// //        be able to check the value of d.running. Instead, every thread running the closure should have a wildcard permission to
	// //        the lock invariant.
	// d.mtx.Unlock()

	// (tlino) use getter
	// for d.running {
	invariant acc(DataPlaneMutexInvariant(d), _)
	for d.isRunning() {
		time.Sleep(time.Second)
	}
	return nil
}

// (tlino) Verified
// (tlino) added helper function
requires acc(bfdSess.Mem(), _)
func bfdLauncher(bfdSess bfdSession) {
	bfdSess.Run()
}

// (tlino) Verified
// (joao) Closure extracted from the body of the Run function
requires acc(rd.Mem(), _)
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
requires ingressID >= 0
func RunReadClosure(ingressID uint16, rd BatchConn, d *DataPlane) {
	// (tlino) outlined code to separate function
	msgs, metas := initReadClosureBuffer()

	// (tlino) use pointer
	// var scmpErr scmpError
	scmpErr := &scmpError{}
	spkt := slayers.SCION{}
	buffer := gopacket.NewSerializeBuffer()
	origPacket := make([]byte, bufSize)

	// (tlino) change structure of loop
	// for d.running {

	invariant forall j int :: 0 <= j && j < len(metas) ==> (&metas[j]).Mem()
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
	invariant acc(rd.Mem(), _)
	invariant msgs.Mem()
	invariant acc(scmpErr)
	invariant isZeroSCION(spkt)
	invariant buffer.Mem()
	invariant forall j int :: 0 <= j && j < len(origPacket) ==> acc(&origPacket[j])
	invariant len(origPacket) == bufSize
	for d.isRunning() {
		pkts, err := rd.ReadBatch(msgs, metas)

		// (tlino) continue not supported by gobra
		// adapted code is below
		// if err != nil {
		// 	log.Debug("Failed to read batch", "err", err)
		// 	// error metric
		// 	continue
		// }
		// if pkts == 0 {
		// 	continue
		// }

		if err != nil {
			// (tlino) log not supported yet
			// log.Debug("Failed to read batch", "err", err)
			// error metric
		} else if pkts > 0 {
			// (tlino) outlined code to separate function
			processBatch(ingressID, rd, d, msgs, metas, pkts, origPacket, scmpErr, buffer, spkt)

			// (tlino) outlined code to separate function
			resetReadClosureBuffers(msgs, pkts)
		}
	}
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
ensures msgs.Mem()
ensures forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
decreases
func initReadClosureBuffer() (msgs underlayconn.Messages, metas []conn.ReadMeta) {
	msgs := conn.NewReadMessages(inputBatchCnt)
	unfold msgs.MemPartiallyInitialized()

	// (tlino) range not supported by Gobra
	// for _, msg := range msgs {
	// 		msg.Buffers[0] = make([]byte, bufSize)
	// }

	invariant 0 <= i && i <= len(msgs)
	invariant forall j int :: 0 <= j && j < i ==> (&msgs[j]).Mem()
	invariant forall j int :: i <= j && j < len(msgs) ==> (&msgs[j]).MemPartiallyInitialized()
	decreases len(msgs) - i
	for i := 0; i < len(msgs); i++ {
		unfold (&msgs[i]).MemPartiallyInitialized()
		(msgs[i].Buffers)[0] = make([]byte, bufSize)
		fold (&msgs[i]).Mem()
	}
	fold msgs.Mem()

	metas := make([]conn.ReadMeta, inputBatchCnt)
	// (tlino) added loop to initialize metas
	ghost
	invariant 0 <= i && i <= len(metas)
	invariant forall j int :: i <= j && j < len(metas) ==> acc(&metas[j]) && metas[j].Src == nil && metas[j].Local == nil
	invariant forall j int :: 0 <= j && j < i ==> (&metas[j]).Mem()
	decreases len(metas) - i
	for i := 0; i < len(metas); i++ {
		fold (&metas[i]).Mem()
	}
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
// (tlino) We cannot prove termination of this method, since processMessage might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
requires ingressID >= 0
requires acc(rd.Mem(), _)
requires 0 <= pkts && pkts <= len(msgs) && pkts <= len(metas)
requires isZeroSCION(spkt)
preserves msgs.Mem()
preserves forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
preserves forall i int :: 0 <= i && i < len(origPacket) ==> acc(&origPacket[i])
preserves cap(origPacket) == bufSize && len(origPacket) == bufSize
preserves acc(scmpErr)
preserves buffer.Mem()
func processBatch(ingressID uint16, rd BatchConn, d *DataPlane, msgs underlayconn.Messages, metas []underlayconn.ReadMeta, pkts int, 
	origPacket []byte, scmpErr *scmpError, buffer gopacket.SerializeBuffer, spkt slayers.SCION) {
	unfold msgs.Mem()

	// (tlino) range not supported by Gobra
	// for _, p := range msgs[:pkts] {
	invariant 0 <= i && i <= pkts
	invariant 0 <= pkts && pkts <= len(msgs)
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
	invariant acc(rd.Mem(), _)
	invariant forall j int :: 0 <= j && j < len(msgs) ==> (&msgs[j]).Mem()
	invariant forall j int :: 0 <= j && j < len(origPacket) ==> acc(&origPacket[j])
	invariant cap(origPacket) == bufSize && len(origPacket) == bufSize
	invariant acc(scmpErr)
	invariant buffer.Mem()
	invariant isZeroSCION(spkt)
	for i := 0; i < pkts; i++ {
		processMessage(ingressID, rd, d, &msgs[i] , origPacket, spkt, buffer, scmpErr)
  	}
	fold msgs.Mem()
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
// (tlino) We cannot prove termination of this method, since d.processPkt might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
requires ingressID >= 0
preserves acc(rd.Mem(), _)
preserves p.Mem()
preserves forall j int :: 0 <= j && j < len(origPacket) ==> acc(&origPacket[j])
preserves cap(origPacket) == bufSize && len(origPacket) == bufSize
preserves isZeroSCION(spkt)
preserves acc(scmpErr)
preserves buffer.Mem()
func processMessage(ingressID uint16, rd BatchConn, d *DataPlane, p *ipv4.Message, origPacket []byte, spkt slayers.SCION, 
	buffer gopacket.SerializeBuffer, scmpErr *scmpError) {

	unfold p.Mem()
	assert forall j int :: 0 <= j && j < p.N ==> &origPacket[j] == &(origPacket[:p.N])[j]
	// (tlino) use local originPacket subslice
	// origPacket = origPacket[:p.N]
	localOrigPacket := origPacket[:p.N]

	// TODO(karampok). Use meta for sanity checks. // (tlino) original scion comment
	
	// (tlino) added parentheses to make it parse
	// p.Buffers[0] = p.Buffers[0][:p.N]
	(p.Buffers)[0] = ((p.Buffers)[0])[:p.N]
	// (tlino) use gobra's copy function
	// copy(origPacket[:p.N], p.Buffers[0])
	verifyutils.OutlineMemorySafeCopy(localOrigPacket, (p.Buffers)[0])
	rawPkt := (p.Buffers)[0]

	// input metric
	// (tlino) use getters to avoid unfolding
	// inputLabels := interfaceToMetricLabels(result.EgressID, d.localIA, d.neighborIAs)
	inputLabels := interfaceToMetricLabels(ingressID, d.GetLocalAI(), d.GetNeighborIAs())
	updateInputMetrics(d, inputLabels, p.N)

	fold verifyutils.BytesAcc((p.Buffers)[0])
	fold verifyutils.BytesAcc(localOrigPacket)

	// (tlino) use local variables
	// result, err := d.processPkt(ingressID, p.Buffers[0], p.Addr, spkt, origPacket,
	//	buffer)
	result, err := d.processPkt(ingressID, rawPkt, p.Addr, spkt, localOrigPacket,
		buffer)

	assert result.Mem()
	assert result.Mem() --* verifyutils.BytesAcc(rawPkt)
	// (tlino) continue isn't supported, move code after switch inside switch cases
	switch {
	case err == nil:
		// (tlino) in the original code processMessage was part of a loop
		// (tlino) and after the non-default switch cases a set of
		// (tlino) statements followd. These statements have been moved to processMessageHelper
		processMessageHelper(d, result, rawPkt)
	case errors.As(err, scmpErr):
		if !scmpErr.TypeCode.InfoMsg() {
			// (tlino) log not yet supported
			// log.Debug("SCMP", "err", scmpErr, "dst_addr", p.Addr)
		}
		// SCMP go back the way they came.
		// (tlino) use setters to simplify verification
		// result.OutAddr = p.Addr
		// result.OutConn = rd

		// unfold result.Mem()
		// result.OutAddr = p.Addr
		// result.OutConn = rd
		// fold result.Mem()

		// r := &result
		// r.setOutAddr(p.Addr)
		// r.setOutConn(rd)
	
		// (tlino) in the original code processMessage was part of a loop
		// (tlino) and after the non-default switch cases a set of
		// (tlino) statements followd. These statements have been moved to processMessageHelper
		processMessageHelper(d, result, rawPkt)
	default:
		// log.Debug("Error processing packet", "err", err)

		// (tlino) outline metric update to function
		// d.Metrics.DroppedPacketsTotal.With(inputLabels).Inc()
		updateDroppedPackets(d, inputLabels)

		// (tlino) continue not supported
		// continue
	}
	apply result.Mem() --* verifyutils.BytesAcc(rawPkt)

	unfold verifyutils.BytesAcc(localOrigPacket)
	unfold verifyutils.BytesAcc((p.Buffers)[0])
	fold p.Mem()
}

// (tlino) Verified
// (tlino) added helper function to simplify verification
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
preserves acc(inputLabels, _)
decreases
func updateInputMetrics(d *DataPlane, inputLabels prometheus.Labels, totalInputBytes int) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	// (tlino) use getter to avoid unfolding d.Metrics.Mem()
	// d.Metrics.InputPacketsTotal.With(inputLabels).Inc()
	// d.Metrics.InputBytesTotal.With(inputLabels).Add(float64(p.N))
	((d.Metrics.GetInputPacketsTotal()).With(inputLabels)).Inc()
	((d.Metrics.GetInputBytesTotal()).With(inputLabels)).Add(float64(totalInputBytes))
}

// (tlino) Verified
// (tlino) added helper function to simplify verification
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
preserves acc(inputLabels, _)
decreases
func updateDroppedPackets(d *DataPlane, inputLabels prometheus.Labels) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	((d.Metrics.GetDroppedPacketsTotal()).With(inputLabels)).Inc()
}

// (tlino) Verified
// (tlino) added helper function to simplify verification
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
preserves result.Mem()
preserves result.Mem() --* verifyutils.BytesAcc(rawPkt)
decreases
func processMessageHelper(d *DataPlane, result processResult, rawPkt []byte) {
	unfold result.Mem()
	if result.OutConn == nil { // e.g. BFD case no message is forwarded
		// (tlino) This helper function used to be a part of a loop,
		// (tlino) since the continue isn't supported we use a return statement
		// continue
		fold result.Mem()
		return
	}
	// (tlino) original code, adapted code is below
	// _, err = result.OutConn.WriteBatch(underlayconn.Messages([]ipv4.Message{{
	// 	Buffers: [][]byte{result.OutPkt},
	// 	Addr:    result.OutAddr,
	// }}))

	fold result.Mem()
	result.getAddrAndRawPktAcc()
	assert (acc(result.OutAddr.Mem(), 1/1000) && acc(verifyutils.BytesAcc(result.OutPkt), 1/1000) && acc(result.OutConn.Mem(), 1/1000)) --* result.Mem()

	// (tlino) moved message creation to outlined function
	// (tlino) use new variables to make gobra work
	pld := result.OutPkt
	address := result.OutAddr
	connection := result.OutConn
	messages := createMessages(pld, address, connection)
	assert acc(messages.MemSend(), 1/1000) --* (acc(verifyutils.BytesAcc(pld), 1/1000) && acc(address.Mem(), 1/1000) && acc(connection.Mem(), 1/1000))

	_, err := result.OutConn.WriteBatch(messages)

	apply acc(messages.MemSend(), 1/1000) --* (acc(verifyutils.BytesAcc(pld), 1/1000) && acc(address.Mem(), 1/1000) && acc(connection.Mem(), 1/1000))
	assert (acc(result.OutAddr.Mem(), 1/1000) && acc(verifyutils.BytesAcc(result.OutPkt), 1/1000) && acc(result.OutConn.Mem(), 1/1000)) --* result.Mem()
	apply (acc(result.OutAddr.Mem(), 1/1000) && acc(verifyutils.BytesAcc(result.OutPkt), 1/1000) && acc(result.OutConn.Mem(), 1/1000)) --* result.Mem()
	assert result.Mem()
	if err != nil {
		// (tlino) log not supported yet
		// log.Debug("Error writing packet", "err", err)
		// error metric // (tlino) original scion comment
		// (tlino) This helper function used to be a part of a loop,
		// (tlino) since the continue isn't supported we use a return statement
		// continue
		return
	}
	// ok metric
	// (tlino) use getters to simplify verification
	outputLabels := interfaceToMetricLabels(result.GetEgressID(), d.GetLocalAI(), d.GetNeighborIAs())
	// d.Metrics.OutputPacketsTotal.With(outputLabels).Inc()
	// d.Metrics.OutputBytesTotal.With(outputLabels).Add(float64(len(result.OutPkt)))
	unfold acc(DataPlaneMutexInvariant(d), _)
	((d.Metrics.GetOutputPacketsTotal()).With(outputLabels)).Inc()
	((d.Metrics.GetOutputBytesTotal()).With(outputLabels)).Add(float64(result.GetOutPktLen()))
}

// (tlino) Verified
// (tlino) added helper function
requires acc(verifyutils.BytesAcc(payload), 1/1000)
requires acc(address.Mem(), 1/1000)
requires acc(connection.Mem(), 1/1000)
ensures acc(msgs.MemSend(), 1/1000)
ensures acc(msgs.MemSend(), 1/1000) --* (acc(verifyutils.BytesAcc(payload), 1/1000) && acc(address.Mem(), 1/1000) && acc(connection.Mem(), 1/1000))
decreases
func createMessages(payload []byte, address net.Addr, connection BatchConn) (msgs underlayconn.Messages) {
	unfold acc(verifyutils.BytesAcc(payload), 1/1000)
	msgs := make(underlayconn.Messages, 1)
	msgs[0].Buffers = make([][]byte, 1)
	(msgs[0].Buffers)[0] = payload 
	msgs[0].Addr = address
	assert forall i int :: 0 <= i && i < len((msgs[0].Buffers)[0]) ==> acc(&((msgs[0].Buffers)[0])[i], 1/1000)
	fold acc((&msgs[0]).MemSend(), 1/1000)
	fold acc(msgs.MemSend(), 1/1000)

	package acc(msgs.MemSend(), 1/1000) --* (acc(verifyutils.BytesAcc(payload), 1/1000) && acc(address.Mem(), 1/1000) && acc(connection.Mem(), 1/1000)) {
		unfold acc(msgs.MemSend(), 1/1000)
		unfold acc((&msgs[0]).MemSend(), 1/1000)
		fold acc(verifyutils.BytesAcc(payload), 1/1000)
	}
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
requires 0 <= pkts && pkts <= len(msgs)
preserves msgs.Mem()
decreases
func resetReadClosureBuffers(msgs underlayconn.Messages, pkts int) {
	unfold msgs.Mem()

	// Reset buffers to original capacity.
	// (tlino) range no supported by Gobra
	// for _, p := range msgs[:pkts] {
	// 	p.Buffers[0] = p.Buffers[0][:bufSize]
	// }

	invariant 0 <= i && i <= pkts
	invariant forall j int :: 0 <= j && j < len(msgs) ==> (&msgs[j]).Mem()
	decreases pkts - i
	for i := 0; i < pkts; i++ {
		unfold (&msgs[i]).Mem()
		(msgs[i].Buffers)[0] = ((msgs[i].Buffers)[0])[:bufSize]
		fold (&msgs[i]).Mem()
	}
	fold msgs.Mem()
}

// (tlino) Verified
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
decreases
func (d *DataPlane) initMetrics() {
	labels := interfaceToMetricLabels(0, d.GetLocalAI(), d.GetNeighborIAs())
	unfold acc(DataPlaneMutexInvariant(d), _)
	// (tlino) use getters to simplify verification, need to use float64 cast since gobra
	// (tlino) cannot cast a numeric argument to float64
	// d.Metrics.InputBytesTotal.With(labels).Add(0)
	// d.Metrics.InputPacketsTotal.With(labels).Add(0)
	// d.Metrics.OutputBytesTotal.With(labels).Add(0)
	// d.Metrics.OutputPacketsTotal.With(labels).Add(0)
	// d.Metrics.DroppedPacketsTotal.With(labels).Add(0)
	((d.Metrics.GetInputBytesTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetInputPacketsTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetOutputBytesTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetOutputPacketsTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetDroppedPacketsTotal()).With(labels)).Add(float64(0))

	// (tlino) range is not supported yet by gobra, iterate over all keys instead
	// (tlino) adapted code is below
	// for id := range d.neighborIAs {
	// 	if _, notOwned := d.internalNextHops[id]; notOwned {
	// 		continue
	// 	}
	// 	labels = interfaceToMetricLabels(id, d.localIA, d.neighborIAs)
	// 	d.Metrics.InputBytesTotal.With(labels).Add(0)
	// 	d.Metrics.InputPacketsTotal.With(labels).Add(0)
	// 	d.Metrics.OutputBytesTotal.With(labels).Add(0)
	// 	d.Metrics.OutputPacketsTotal.With(labels).Add(0)
	// 	d.Metrics.DroppedPacketsTotal.With(labels).Add(0)
	// }

	mapKeyUpperBound := 65536

	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		unfold acc(DataPlaneMutexInvariant(d), _)
		key := uint16(k)
		_ , found := (d.neighborIAs)[key]
		if found {
			if _, notOwned := d.GetInternalNextHop(key); !notOwned {
				labels = interfaceToMetricLabels(key, d.GetLocalAI(), d.GetNeighborIAs())
				// (tlino) use getters to simplify verification, need to use float64 cast since gobra
				// (tlino) cannot cast a numeric argument to float64
				((d.Metrics.GetInputBytesTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetInputPacketsTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetOutputBytesTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetOutputPacketsTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetDroppedPacketsTotal()).With(labels)).Add(float64(0))
			}
		}
	}
}

type processResult struct {
	EgressID uint16
	OutConn  BatchConn
	OutAddr  net.Addr
	OutPkt   []byte
}

// (tlino) added getter and setter methods to simplify verification
pure
requires acc(pr.Mem(), _)
ensures res == unfolding acc(pr.Mem(), _) in pr.EgressID
ensures res >= 0
decreases
func (pr processResult) GetEgressID() (res uint16) {
	return unfolding acc(pr.Mem(), _) in pr.EgressID
}

pure
requires acc(pr.Mem(), _)
ensures res == unfolding acc(pr.Mem(), _) in len(pr.OutPkt)
decreases
func (pr processResult) GetOutPktLen() (res int) {
	return unfolding acc(pr.Mem(), _) in len(pr.OutPkt)
}

// (tlino) TODO: cannot verify body with this contracts, 
// (tlino) however function verifies if we use "requires pr.Mem()" instead of "preserves pr.Mem()"
preserves acc(pr) && (*pr).Mem()
decreases
func (pr *processResult) setOutAddr(add net.Addr) {
	unfold (*pr).Mem()
	(*pr).OutAddr = add
	fold (*pr).Mem()
}

// (tlino) TODO: cannot verify body with this contracts, 
// (tlino) however function verifies if we use "requires pr.Mem()" instead of "preserves pr.Mem()"
preserves acc(pr) && (*pr).Mem()
requires acc(b.Mem(), _)
decreases
func (pr *processResult) setOutConn(b BatchConn) {
	unfold (*pr).Mem()
	(*pr).OutConn = b
	fold (*pr).Mem()
}
// (tlino) end of getters and setters

// (tlino) helper method to get read access to OutAddr, OutPkt, and OutConn.
// (tlino) OutAddr contains a subslice of OutPkt.
// (tlino) However, giving both read access is ok.
// (tlino) The OutConn object is an entry in DataPlane.external with wildcard permission.
// (tlino) We cannot give a wildcard permission amount to OutConn whithin a magic wand, 
// (tlino) thus we use a concrete permission amount
ghost
requires pr.Mem()
ensures acc(pr.OutAddr.Mem(), 1/1000) && acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000) && acc(pr.OutConn.Mem(), 1/1000)
ensures (acc(pr.OutAddr.Mem(), 1/1000) && acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000) && acc(pr.OutConn.Mem(), 1/1000)) --* pr.Mem()
decreases _
func (pr processResult) getAddrAndRawPktAcc()

pred (pr processResult) Mem() {
	(pr.EgressID >= 0) &&
	(pr.OutConn != nil ==> acc(pr.OutConn.Mem(), _)) &&
	(pr.OutPkt != nil ==> verifyutils.BytesAcc(pr.OutPkt))
}

decreases
pure func isZeroSCION(s slayers.SCION) bool {
	return s.EmbeddedBaseLayer.Contents == nil &&
		s.EmbeddedBaseLayer.Payload == nil &&
		s.Version == 0 &&
		s.TrafficClass == 0 &&
		s.FlowID == 0 &&
		s.NextHdr == 0 &&
		s.HdrLen == 0 &&
		s.PayloadLen == 0 &&
		s.PathType == 0 &&
		s.DstAddrType == 0 &&
		s.DstAddrLen == 0 &&
		s.SrcAddrType == 0 &&
		s.SrcAddrLen == 0 &&
		s.DstIA.I == 0 &&
		s.DstIA.A == 0 &&
		s.SrcIA.I == 0 &&
		s.SrcIA.A == 0 &&
		s.RawDstAddr == nil &&
		s.RawSrcAddr  == nil &&
		s.Path == nil
}

// (tlino) Verified
// (tlino) added helper method to construct magic wand in processPkt
ghost
requires scionLayer.Mem()
requires rawPkt == scionLayer.getRawPkt()
preserves pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
decreases
func processPktHelper(pr processResult, scionLayer *slayers.SCION, rawPkt []byte) {
	scionLayer.getRawPktAccWithoutPreservePath(rawPkt)
	package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {}
}

// (tlino) Verified
// (tlino) We cannot prove termination of this method, since d.processSCION() and d.processOHP() might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires ingressID >= 0
requires verifyutils.BytesAcc(rawPkt)
requires isZeroSCION(s)
preserves verifyutils.BytesAcc(origPacket)
preserves cap(rawPkt) == bufSize
preserves acc(srcAddr.Mem(), 1/1000)
preserves buffer.Mem()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
func (d *DataPlane) processPkt(ingressID uint16, rawPkt []byte, srcAddr net.Addr, s slayers.SCION,
	origPacket []byte, buffer gopacket.SerializeBuffer) (pr processResult, errRet error) {
	// (joao) `s` should always have the zero value of slayers.SCION;
	// (joao) in the code, we use `s` where an *slayers.SCION is expected. In Go, this modifies `s` but in Gobra, that idiom is still not supported;
	// (joao) we use the following transformation - we check that s is always the zero value and we introduce a new shared variable `sNew` of type slayers.SCION{}
	//        that gets mutated
	sNew := &slayers.SCION{}

	df := gopacket.NilDecodeFeedback{}
	fold df.Mem()
	// (joao) Adapted to conform to changes in gopacket and sNew
	// if err := s.DecodeFromBytes(rawPkt, gopacket.NilDecodeFeedback); err != nil {
	if err := sNew.DecodeFromBytes(rawPkt, df); err != nil {
		// (tlino) original code, adapted code is below 
		// return processResult{}, err

		pr, errRet =  processResult{}, err
		fold pr.Mem()
		
		package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {}
		return
	}
	
	// (joao) already lost access to rawPkt here
	if err := buffer.Clear(); err != nil {
		// (tlino) original code, adapted code is below 
		// return processResult{}, serrors.WrapStr("Failed to clear buffer", err)

		pr, errRet = processResult{}, serrors.WrapStr("Failed to clear buffer", err)
		fold pr.Mem()
		ghost processPktHelper(pr, sNew, rawPkt)
		return
	}

	// (tlino) use sNew.getPathType() instead of s
	// switch s.PathType {
	switch sNew.getPathType() {
	case slayers.PathTypeEmpty:
		// (tlino) use sNew instead of s and use getters
		// if s.NextHdr == common.L4BFD {
		if sNew.getNextHdr() == common.L4BFD {
			// (tlino) original code, adapted code is below
			// return processResult{}, d.processIntraBFD(srcAddr, s.Payload)
			unfold sNew.Mem()
			pr, errRet = processResult{}, d.processIntraBFD(srcAddr, sNew.EmbeddedBaseLayer.Payload)
			fold sNew.Mem()
			fold pr.Mem()
			ghost processPktHelper(pr, sNew, rawPkt)
			return 
		}
		// (tlino) original code, adapted code is below
		// return processResult{}, serrors.WithCtx(unsupportedPathTypeNextHeader,
		// 	"type", s.PathType, "header", s.NextHdr)
		
		pr, errRet = processResult{}, serrors.WithCtx(unsupportedPathTypeNextHeader(),
		 	"type", sNew.getPathType(), "header", sNew.getNextHdr())
		fold pr.Mem()
		ghost processPktHelper(pr, sNew, rawPkt)
		return 
	case slayers.PathTypeOneHop:
		// (tlino) use sNew instead of s and use getters
		// if s.NextHdr == common.L4BFD {
		if sNew.getNextHdr() == common.L4BFD {
			unfold sNew.Mem()
			// (tlino) use sNew instead of s
			// ohp, ok := s.Path.(*onehop.Path)
			ohp, ok := (sNew.Path).(*onehop.Path)
			fold sNew.Mem()
			if !ok {
				// (tlino) original code, adapted code is below
				// return processResult{}, malformedPath
				pr, errRet = processResult{}, malformedPath()
				fold pr.Mem()
				ghost processPktHelper(pr, sNew, rawPkt)
				return
			}
			
			// (tlino) original code, adapted code is below
			// return processResult{}, d.processInterBFD(ingressID, ohp, s.Payload)
			unfold sNew.Mem()
			pr, errRet = processResult{}, d.processInterBFD(ingressID, ohp, sNew.EmbeddedBaseLayer.Payload)
			fold sNew.Mem()
			fold pr.Mem()
			ghost processPktHelper(pr, sNew, rawPkt)
			return
		}
		// (tlino) original code, adapted code is below
		// return d.processOHP(ingressID, rawPkt, s, buffer)

		pr, errRet = d.processOHP(ingressID, rawPkt, sNew, buffer)
		return
	case slayers.PathTypeSCION:
		// (tlino) original code, adapted code is below 
		// return d.processSCION(ingressID, rawPkt, s, origPacket, buffer)

		pr, errRet = d.processSCION(ingressID, rawPkt, sNew, origPacket, buffer)
		return
	default:
		// (tlino) original code, adapted code is below 
		// return processResult{}, serrors.WithCtx(unsupportedPathType, "type", s.PathType)

		pr, errRet = processResult{}, serrors.WithCtx(unsupportedPathType(), "type", sNew.getPathType())
		fold pr.Mem()
		ghost processPktHelper(pr, sNew, rawPkt)
		return
 	}
}

// (tlino) Verified
// (joao) `oh` is not used anywhere in the function
requires acc(DataPlaneMutexInvariant(d), _)
preserves verifyutils.BytesAcc(data)
decreases
func (d *DataPlane) processInterBFD(ingressID uint16, oh *onehop.Path, data []byte) error {
	unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BfdSessionsAcc(d.bfdSessions), _)
	if len(d.bfdSessions) == 0 {
		// (joao) no globals
		// return noBFDSessionConfigured
		return noBFDSessionConfigured()
	}

	p := &layers.BFD{}
	// (joao) TODO: gopacket.NilDecodeFeedback is a var in gopacket but Luca implemented as a type (should be changed).
	//              Code adapted below.
	//if err := p.DecodeFromBytes(data, gopacket.NilDecodeFeedback); err != nil {
	//	return err
	//}
	tmp := gopacket.NilDecodeFeedback{}
	fold tmp.Mem()
	unfold verifyutils.BytesAcc(data)
	if err := p.DecodeFromBytes(data, tmp); err != nil {
		fold verifyutils.BytesAcc(data)
		return err
	}
	fold verifyutils.BytesAcc(data)

	ghost translateBFDMemPred(p)

	// (joao) add parentheses surrounding `d.bfdSessions`
	if v, ok := (d.bfdSessions)[ingressID]; ok {
		v.Messages() <- p
		return nil
	}

	// (joao) no globals
	// return noBFDSessionFound
	return noBFDSessionFound()
}

ghost
requires b.MemWithOutSlices()
ensures  (*layers.BFD).MemWithOutSlices!<_!>(b)
decreases
func translateBFDMemPred(b *layers.BFD) {
	unfold (*layers.BFD).MemWithOutSlices(b)
	fold (*layers.BFD).MemWithOutSlices!<_!>(b)
}

// (tlino) Verified
requires acc(DataPlaneMutexInvariant(d), _)
preserves acc(src.Mem(), 1/1000)
preserves verifyutils.BytesAcc(data)
decreases
func (d *DataPlane) processIntraBFD(src net.Addr, data []byte) error {
	unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BfdSessionsAcc(d.bfdSessions), _)
	if len(d.bfdSessions) == 0 {
		// (tlino) golbals not supported
		// return noBFDSessionConfigured
		return noBFDSessionConfigured()
	}
	p := &layers.BFD{}

	// (tlino) TODO: gopacket.NilDecodeFeedback is a var in gopacket but Luca implemented as a type (should be changed).
	//              Code adapted below.
	// if err := p.DecodeFromBytes(data, gopacket.NilDecodeFeedback); err != nil {
	// 	return err
	// }

	tmp := gopacket.NilDecodeFeedback{}
	fold tmp.Mem()
	unfold verifyutils.BytesAcc(data)
	if err := p.DecodeFromBytes(data, tmp); err != nil {
		fold verifyutils.BytesAcc(data)
		return err
	}
	fold verifyutils.BytesAcc(data)
	ghost translateBFDMemPred(p)

	ifID := uint16(0)
	srcUDPAddr, ok := src.(*net.UDPAddr)
	if !ok {
		// (joao) No support for fmt
		// return serrors.New("type assertion failure", "from", fmt.Sprintf("%v(%T)", src, src),
		//	"expected", "*net.IPAddr")
		return serrors.New("error") // (joao) TODO: remove after adding support for fmt
	}

	// (tlino) range not supported yet.
	// (tlino) Thus, we iterate over all possible keys (keyspace: 0,1,2,...,2^16 -1)
	// (tlino) adapted code is below
	// for k, v := range (d.internalNextHops) {
		// remoteUDPAddr, ok := v.(*net.UDPAddr)
		// if !ok {
		// 	return serrors.New("type assertion failure", "from",
		// 		fmt.Sprintf("%v(%T)", remoteUDPAddr, remoteUDPAddr), "expected", "*net.UDPAddr")
		// }
		// if bytes.Equal(remoteUDPAddr.IP, srcUDPAddr.IP) && remoteUDPAddr.Port == srcUDPAddr.Port {
		// 	ifID = k
		// 	continue
		// }
	// }
	mapKeyUpperBound := 65536

	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant acc(srcUDPAddr.Mem(), 1/1000)
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		key := uint16(k)
		v, found := d.GetInternalNextHop(key)
		if found {
			remoteUDPAddr, ok := v.(*net.UDPAddr)
			if !ok {
				// (tlino) No support for fmt
				// return serrors.New("type assertion failure", "from",
				// 	fmt.Sprintf("%v(%T)", remoteUDPAddr, remoteUDPAddr), "expected", "*net.UDPAddr")
				return serrors.New("error")
			}
			unfold acc(remoteUDPAddr.Mem(), _)
			unfold acc(srcUDPAddr.Mem(), 1/1000)
			if bytes.Equal(remoteUDPAddr.IP, srcUDPAddr.IP) && remoteUDPAddr.Port == srcUDPAddr.Port {
				ifID = key
			}
			fold acc(srcUDPAddr.Mem(), 1/1000)
		}
	}

 	// (tlino) added parantheses to make it parse
 	// if v, ok := d.bfdSessions[ifID]; ok {
	if v, ok := (d.bfdSessions)[ifID]; ok {
		v.Messages() <- p
		return nil
	}

	// (tlino) globals not supported
	// return noBFDSessionFound
	return noBFDSessionFound()
}

// (tlino) Verified
// (tlino) We cannot prove termination of this method, since p.process() might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires s != nil && s.Mem() && s.getRawPkt() == rawPkt
preserves verifyutils.BytesAcc(origPacket)
preserves cap(rawPkt) == bufSize
preserves buffer.Mem()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
// (joao) s is now a *slayers.SCION
// func (d *DataPlane) processSCION(ingressID uint16, rawPkt []byte, s slayers.SCION,
func (d *DataPlane) processSCION(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	origPacket []byte, buffer gopacket.SerializeBuffer) (pr processResult, err error) {

	// (joao) added `&` before `scionPacketProcessor` to make this type check
	p := &scionPacketProcessor{
		d:          d,
		ingressID:  ingressID,
		rawPkt:     rawPkt,
		scionLayer: s,
		origPacket: origPacket,
		buffer:     buffer,
	}
	// (tlino) use ghost argument to relate the argument of processSCION to process
	// return p.process()
	return p.process(rawPkt)
}

type scionPacketProcessor struct {
	// d is a reference to the dataplane instance that initiated this processor.
	d *DataPlane
	// ingressID is the interface ID this packet came in, determined from the
	// socket.
	ingressID uint16
	// rawPkt is the raw packet, it is updated during processing to contain the
	// message to send out.
	rawPkt []byte
	// scionLayer is the SCION gopacket layer.
	// (joao) adapted to make this type check in Gobra
	// scionLayer slayers.SCION
	scionLayer *slayers.SCION
	// origPacket is the raw original packet, must not be modified.
	origPacket []byte
	// buffer is the buffer that can be used to serialize gopacket layers.
	buffer gopacket.SerializeBuffer

	// path is the raw SCION path. Will be set during processing.
	path *scion.Raw
	// hopField is the current hopField field, is updated during processing.
	hopField *path.HopField
	// infoField is the current infoField field, is updated during processing.
	infoField *path.InfoField
	// segmentChange indicates if the path segment was changed during processing.
	segmentChange bool
}

pred (p *scionPacketProcessor) Mem() {
	acc(&p.d, _) &&
	acc(&p.ingressID, 1/4) &&
	acc(&p.rawPkt, 1/4) &&
	acc(&p.scionLayer, 1/4) &&
	acc(&p.origPacket, 1/4) &&
	acc(&p.buffer, 1/4) &&
	acc(&p.path) &&
	acc(&p.hopField) &&
	acc(&p.infoField) &&
	acc(&p.segmentChange) &&
	acc(DataPlaneMutexInvariant(p.d), _) &&
	(unfolding acc(DataPlaneMutexInvariant(p.d), _) in p.d.svc != nil) &&
	verifyutils.BytesAcc(p.origPacket) &&
	acc(p.infoField) &&
	path.HopFieldInv(p.hopField) &&
	p.buffer.Mem() &&
	p.scionLayer != nil && p.scionLayer.Mem() &&
	cap(p.rawPkt) == bufSize &&
	p.path != nil && p.path == p.scionLayer.getRawScionPath() &&
 	p.rawPkt == p.scionLayer.getRawPkt()
}

// (tlino) Verified
// TODO: next. "slayers.UDP", "slayers.HopByHopExtn", slayers.EndToEndExtn, *SCION <: DecodingLayer
requires scmpH.Mem() && scmpP.Mem()
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) packSCMP(scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer,
	cause error) (pr processResult, errRet error) {
	unfold p.Mem()
	// parse everything to see if the original packet was an SCMP error.
	var (
		scionLayer slayers.SCION
		// (joao) not supported yet
		// udpLayer   slayers.UDP
		// hbhExtn    slayers.HopByHopExtn
		// e2eExtn    slayers.EndToEndExtn
		scmpLayer  slayers.SCMP
	)
	// (joao) currently not supported, rewritten below
	// parser := gopacket.NewDecodingLayerParser(
	//	slayers.LayerTypeSCION, &scionLayer, &udpLayer, &hbhExtn, &e2eExtn, &scmpLayer,
	// )
	parser := gopacket.NewDecodingLayerParser(slayers.LayerTypeSCION())

	decoded@ := make([]gopacket.LayerType, 5)
	assert forall i int :: 0 <= i && i < len(decoded) ==> acc(&decoded[i])
	assert len(decoded) == 5
	if err := parser.DecodeLayers(p.origPacket, &decoded); err != nil {
		if _, ok := err.(gopacket.UnsupportedLayerType); !ok {
			assert len(decoded) == 5
			assert forall j int :: 0 <= j && j < len(decoded) ==> acc(&decoded[j])
			fold p.Mem()
			pr, errRet = processResult{}, serrors.WrapStr("decoding packet", err)
			fold pr.Mem()
			return 
		}
		assert len(decoded) == 5
		assert forall j int :: 0 <= j && j < len(decoded) ==> acc(&decoded[j])
	}
	assert forall i int :: 0 <= i && i < len(decoded) ==> acc(&decoded[i])
	assert len(decoded) == 5
	assert acc(&(decoded[len(decoded)-1]))
	// in reply to an SCMP error do nothing:
	// if decoded[len(decoded)-1] == slayers.LayerTypeSCMP && !scmpLayer.TypeCode.InfoMsg() {
	if decoded[len(decoded)-1] == slayers.LayerTypeSCMP() && !scmpLayer.TypeCode.InfoMsg() {
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("SCMP error for SCMP error pkt -> DROP", cause)
		fold pr.Mem()
		return 
	}

	// the quoted packet is the packet in its current state
	// (tlino) use getter to reduce verification overhead, see adapted code below
	// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	rp := p.rawPkt
	scionL := p.scionLayer
	scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	// (tlino) use getter for currINF to reduce verification overhead
	// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {
	if err := p.path.SetInfoField(p.infoField, int( unfolding p.path.Mem() in scion.getCurrINF(&(p.path.Base)))); err != nil {
		// (tlino) get back access to scionLayer and fold scionPacketProcessor
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("update info field", err)
		fold pr.Mem()
		return 
	}

	// (tlino) use getter for currHF to reduce verification overhead
	// if err := p.path.SetHopField(p.hopField, int(p.path.PathMeta.CurrHF)); err != nil {
	if err := p.path.SetHopField(p.hopField, int( unfolding p.path.Mem() in scion.getCurrHF(&(p.path.Base)))); err != nil {
		// (tlino) get back access to scionLayer and fold scionPacketProcessor
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("update hop field", err)
		fold pr.Mem()
		return 
	}

	// (tlino) get back access to scionLayer
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())

	if err := p.buffer.Clear(); err != nil {
		fold p.Mem()
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}

	if err := p.scionLayer.SerializeTo(p.buffer, gopacket.SerializeOptions{}); err != nil {
		fold p.Mem()
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}
	// quoteLen is used to limit the size of the quote buffer, the final quote
	// length is calculated inside the scmpPacker.
	quoteLen := len(p.origPacket)
	if quoteLen > slayers.MaxSCMPPacketLen {
		quoteLen = slayers.MaxSCMPPacketLen
	}
	quote := make([]byte, quoteLen)
	// (tlino) use varable b to make magic wands work. Magic wands don't work directly on p.buffer
	b := p.buffer
	updated := b.Bytes()
	assert verifyutils.BytesAcc(updated) --* b.Mem()
	unfold verifyutils.BytesAcc(updated)

	// (tlino) use Gobra's copy function
	// copy(quote[:len(updated)], updated)
	// (tlino) the updated byte representation of the header fields cannot be longer then the length of the quote
	assume len(updated) <= len(quote)
	assert forall i int :: 0 <= i && i < len(quote) ==> acc(&quote[i])
	assert forall i int :: 0 <= i && i < len(updated) ==> acc(&updated[i], 1/100000)
	assert forall i int :: 0 <= i && i < len(updated) ==> &(quote[:len(updated)])[i] == &quote[i]
	assert forall i int :: 0 <= i && i < len(updated) ==> acc(&(quote[:len(updated)])[i])
	
	verifyutils.OutlineMemorySafeCopy(quote[:len(updated)], updated)

	// (tlino) use Gobra's copy function
	// copy(quote[len(updated):], p.origPacket[len(updated):quoteLen])
	unfold verifyutils.BytesAcc(p.origPacket)
	assert forall i int :: 0 <= i && i < (len(quote) - len(updated)) ==> &(quote[len(updated):])[i] == &quote[i + len(updated)]
	assert forall i int :: 0 <= i && i < (len(quote) - len(updated)) ==> acc(&(quote[len(updated):])[i])
	assert forall i int :: 0 <= i && i < len(p.origPacket) ==>  acc(&(p.origPacket)[i], 1/100000)
	assert forall i int :: 0 <= i && i < (quoteLen - len(updated)) ==> &((p.origPacket)[len(updated):quoteLen])[i] == &(p.origPacket)[i + len(updated)]
	assert forall i int :: 0 <= i && i < (quoteLen - len(updated)) ==> acc(&((p.origPacket)[len(updated):quoteLen])[i],  1/100000)
	verifyutils.OutlineMemorySafeCopy(quote[len(updated):], (p.origPacket)[len(updated):quoteLen])

	fold verifyutils.BytesAcc(updated)
	apply verifyutils.BytesAcc(updated) --* b.Mem()
	fold verifyutils.BytesAcc(p.origPacket)
	pr, errRet := packSCMP2(p.d, quote, p.origPacket, p.ingressID, p.scionLayer, b, scmpH, scmpP, cause)
	fold p.Mem()
}

// (tlino) Verified
// (tlino) outlined part of packSCMP
requires acc(DataPlaneMutexInvariant(d), _)
requires forall i int :: 0 <= i && i < len(quote) ==> acc(&quote[i])
requires scmpH.Mem() && scmpP.Mem()
preserves scionLayer.Mem() && buffer.Mem() 
preserves verifyutils.BytesAcc(origPacket)
ensures scionLayer.getRawScionPath() == old(scionLayer.getRawScionPath())
ensures scionLayer.getRawPkt() == old(scionLayer.getRawPkt())
ensures pr.Mem()
decreases
func packSCMP2(d *DataPlane, quote []byte, origPacket []byte, ingressID uint16, scionLayer *slayers.SCION, 
	buffer gopacket.SerializeBuffer, scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer, cause error) (pr processResult, err error) {
	
	// (tlino) use getter to simplify verification 
	// _, external := p.d.external[p.ingressID]
	_, external := d.GetExternalBatchConn(ingressID)

	// (tlino) original code, adapted code is below
	// rawSCMP, err := scmpPacker{
	// 	internalIP: p.d.internalIP,
	// 	localIA:    p.d.localIA,
	// 	origPacket: p.origPacket,
	// 	ingressID:  p.ingressID,
	// 	scionL:     &p.scionLayer,
	// 	buffer:     p.buffer,
	// 	quote:      quote,
	// }.prepareSCMP(
	// 	scmpH,
	// 	scmpP,
	// 	external,
	// 	cause,
	// )

	fold verifyutils.BytesAcc(quote)
	unfold acc(DataPlaneMutexInvariant(d), _)

	scmp := scmpPacker{
		internalIP: d.internalIP,
		localIA:    d.localIA,
		origPacket: origPacket,
		ingressID:  ingressID,
		scionL:     scionLayer,
		buffer:     buffer,
		quote:      quote,
	}

	rawSCMP, err := scmp.prepareSCMP(
		scmpH,
		scmpP,
		external,
		cause,
	)
	pr, err = processResult{OutPkt: rawSCMP}, err
	fold pr.Mem()
}

// (tlino) Verified
requires acc(&p.d, _) && acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4) && acc(&p.origPacket, 1/4)
requires acc(&p.buffer, 1/4) && acc(&p.path) && acc(&p.hopField) && acc(&p.infoField) && acc(&p.segmentChange)
requires p.scionLayer != nil && (p.scionLayer).Mem() && (p.buffer).Mem() && verifyutils.BytesAcc(p.origPacket)
requires (cap(p.rawPkt) == bufSize) && p.rawPkt == p.scionLayer.getRawPkt()
requires acc(DataPlaneMutexInvariant(p.d), _)
requires unfolding acc(DataPlaneMutexInvariant(p.d), _) in p.d.svc != nil
ensures errRet != nil ==> acc(&p.d, _) && acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4) && acc(&p.origPacket, 1/4)
ensures errRet != nil ==> acc(&p.buffer, 1/4) && acc(&p.path) && acc(&p.hopField) && acc(&p.infoField) && acc(&p.segmentChange)
ensures errRet != nil ==> (p.scionLayer).Mem() && (p.buffer).Mem() && verifyutils.BytesAcc(p.origPacket)
ensures errRet != nil ==> (cap(p.rawPkt) == bufSize) && p.rawPkt == p.scionLayer.getRawPkt()
ensures errRet == nil ==> p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) parsePath() (pr processResult, errRet error) {
	var ok bool
	unfold p.scionLayer.Mem()
	assert p.scionLayer.Path != nil
	p.path, ok = (p.scionLayer.Path).(*scion.Raw)
	if !ok {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) gobra doesn't support globals yet
		// return processResult{}, malformedPath
		fold p.scionLayer.Mem()
		pr, errRet = processResult{}, malformedPath()
		fold pr.Mem()
		return 
	}
	fold p.scionLayer.Mem()
	assert p.path == p.scionLayer.getRawScionPath()
	var err error

	// (tlino) we know that this holds, since (SCION).DecodeFromBytes has already decoded the path.
	// (tlino) a decoded path is always not nil and in this function of dynamic type *scion.Raw.
	// (tlino) however, (p.scionLayer.Path).(*scion.Raw) cannot deduce that p.path != nil.
	assume p.path != nil

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	scionL := p.scionLayer
	rp := p.rawPkt
	scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	p.hopField, err = p.path.GetCurrentHopField()
	if err != nil {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) get back access to p.scionLayer
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	p.infoField, err = p.path.GetCurrentInfoField()
	if err != nil {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) get back access to p.scionLayer
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	// (tlino) get back access to p.scionLayer
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	fold p.Mem()
	if r, err := p.validateHopExpiry(); err != nil {
		unfold p.Mem()
		return r, err
	}
	if r, err := p.validateIngressID(); err != nil {
		unfold p.Mem()
		return r, err
	}
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateHopExpiry() (pr processResult, errRet error) {
	// (joao) Add to separate this in two lines
	// expiration := util.SecsToTime(p.infoField.Timestamp).
	//	Add(path.ExpTimeToDuration(p.hopField.ExpTime))
	unfold  p.Mem()
	tmp := util.SecsToTime(p.infoField.Timestamp)
	expiration := tmp.Add(path.ExpTimeToDuration(unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ExpTime))
	expired := expiration.Before(time.Now())
	if !expired {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	} 
	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
	// 		slayers.SCMPCodePathExpired),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
	// 	serrors.New("expired hop", "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
	// 		"curr_inf", p.path.PathMeta.CurrINF, "curr_hf", p.path.PathMeta.CurrHF),
	// )
	fold p.Mem()
	scmpH := &slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
		slayers.SCMPCodePathExpired)}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
	fold scmpP.Mem()
	unfold p.Mem()

	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	e := serrors.New("expired hop", "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
		"curr_inf", p.path.GetCurrINF(), "curr_hf", p.path.GetCurrHF())
	
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	fold p.Mem()
	return p.packSCMP(scmpH, scmpP, e)
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateIngressID() (pr processResult, errRet error) {
	unfold p.Mem()
	pktIngressID := unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ConsIngress
	errCode := slayers.SCMPCodeUnknownHopFieldIngress
	if !p.infoField.ConsDir {
		pktIngressID = unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ConsEgress
		errCode = slayers.SCMPCodeUnknownHopFieldEgress
	}
	if p.ingressID != 0 && p.ingressID != pktIngressID {
		// (tlino) original code, adapted code is below
		// return p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
		// 	},
		// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
		// 	serrors.New("ingress interface invalid",
		// 		"pkt_ingress", pktIngressID, "router_ingress", p.ingressID),
		// )
		fold p.Mem()
		scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
			}
		fold scmpH.Mem()
		scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
		fold scmpP.Mem()
		e := serrors.New("ingress interface invalid",
		 		"pkt_ingress", pktIngressID, "router_ingress", (unfolding acc(p.Mem(), 1/1000) in p.ingressID))
		return p.packSCMP(scmpH, scmpP, e)
	}
	fold p.Mem()
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateEgressID() (pr processResult, errRet error) {
	pktEgressID := p.egressInterface()
	unfold p.Mem()
	// (tlino) add parantheses to make it parse
	// _, ih := p.d.internalNextHops[pktEgressID]
	// _, eh := p.d.external[pktEgressID]
	_, ih := p.d.GetInternalNextHop(pktEgressID)
	_, eh := p.d.GetExternalBatchConn(pktEgressID)
	if !ih && !eh {
		errCode := slayers.SCMPCodeUnknownHopFieldEgress
		if !p.infoField.ConsDir {
			errCode = slayers.SCMPCodeUnknownHopFieldIngress
		}
		// (tlino) original code, adapted code is below
		// return p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
		// 	},
		// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
		// 	cannotRoute,
		// )

		scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
			}
		fold scmpH.Mem()
		fold p.Mem()
		scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
		fold scmpP.Mem()
		e := cannotRoute()
		return p.packSCMP(scmpH, scmpP, e)
	}

	if !p.segmentChange {
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		fold p.Mem()
		return 
	}
	// Check that the interface pair is valid on a segment switch. // (tlino) original scion comment
	// Having a segment change received from the internal interface is never valid. // (tlino) original scion comment
	// (tlino) use getter to simplify verification
	// ingress, egress := p.d.linkTypes[p.ingressID], p.d.linkTypes[pktEgressID]
	ingress, egress := p.d.GetLinkType(p.ingressID), p.d.GetLinkType(pktEgressID)
	fold p.Mem()
	switch {
	case ingress == topology.Core && egress == topology.Child:
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	case ingress == topology.Child && egress == topology.Core:
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	case ingress == topology.Child && egress == topology.Child:
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	default:
		// (tlino) original code, adapted code is below
		// return p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(
		// 			slayers.SCMPTypeParameterProblem,
		// 			slayers.SCMPCodeInvalidSegmentChange,
		// 		),
		// 	},
		// 	&slayers.SCMPParameterProblem{Pointer: p.currentInfoPointer()},
		// 	serrors.WithCtx(cannotRoute, "ingress_id", p.ingressID, "ingress_type", ingress,
		// 		"egress_id", pktEgressID, "egress_type", egress))
		scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(
					slayers.SCMPTypeParameterProblem,
					slayers.SCMPCodeInvalidSegmentChange,
				),
			}
		fold scmpH.Mem()
		scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentInfoPointer()}
		fold scmpP.Mem()
		e := serrors.WithCtx(cannotRoute(), "ingress_id", unfolding acc(p.Mem(), 1/1000) in p.ingressID, "ingress_type", ingress,
		 		"egress_id", pktEgressID, "egress_type", egress)
		return p.packSCMP(scmpH, scmpP, e)
	}
}

// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) updateNonConsDirIngressSegID() (err error) {
	// against construction dir the ingress router updates the SegID, ifID == 0
	// means this comes from this AS itself, so nothing has to be done.
	// TODO(lukedirtwalker): For packets destined to peer links this shouldn't
	// be updated.
	unfold p.Mem()
	if !p.infoField.ConsDir && p.ingressID != 0 {
		unfold path.HopFieldInv(p.hopField)
		p.infoField.UpdateSegID(p.hopField.Mac)
		fold path.HopFieldInv(p.hopField)

		// get access to path, use new variables to make Gobra work
		assert p.scionLayer != nil
		assert p.path != nil
		sl := p.scionLayer
		pp := p.path
		rawPkt := p.rawPkt
		sl.getPathAcc(pp, rawPkt)
		assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
		assert pp.Mem()

		if err := p.path.SetInfoField(p.infoField, int( unfolding p.path.Mem() in scion.getCurrINF(&(p.path.Base)))); err != nil {
			apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
			fold p.Mem()
			return serrors.WrapStr("update info field", err)
		}
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
		if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
			fold p.Mem()
			return err
		}
	}
	fold p.Mem()
	return nil
}
 
// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) currentInfoPointer() uint16 {
	// (tlino) needs to use getPathAcc to obtain access to p.path
	// return uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() +
	// 	scion.MetaLen + path.InfoLen*int(p.path.PathMeta.CurrINF))
	unfold p.Mem()
	
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	currINF := uint16(p.path.GetCurrINF())
	infoLen := uint16(path.InfoLen)
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	offset := uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() + scion.MetaLen)
	pointer := offset + infoLen * currINF
	fold p.Mem()
	return pointer
}

// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) currentHopPointer() uint16 {
	// (tlino) needs to use getPathAcc to obtain access to p.path
	// return  uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() +
	// 	scion.MetaLen + path.InfoLen*p.path.NumINF + path.HopLen*int(p.path.PathMeta.CurrHF))
	unfold p.Mem()
	
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()
	
	numInf := uint16(p.path.GetNumINF())
	currHF := uint16(p.path.GetCurrHF())
	infoLen := uint16(path.InfoLen)
	hopLen := uint16(path.HopLen)
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	offset := uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() + scion.MetaLen)
	pointer := offset + infoLen * numInf + hopLen * currHF
	fold p.Mem()
	return pointer
}

// (tlino) not verified yet
// (joao) currently not supported
preserves p.Mem()
ensures pr.Mem()
decreases _
func (p *scionPacketProcessor) verifyCurrentMAC() (pr processResult, err error) //{
// 	if err := path.VerifyMAC(p.d.macFactory(), p.infoField, p.hopField); err != nil {
// 		return p.packSCMP(
// 			&slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
// 				slayers.SCMPCodeInvalidHopFieldMAC),
// 			},
// 			&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
// 			serrors.WithCtx(err, "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
// 				"curr_inf", p.path.PathMeta.CurrINF, "curr_hf", p.path.PathMeta.CurrHF,
// 				"seg_id", p.infoField.SegID),
// 		)
// 	}
// 	return processResult{}, nil
// }

// (tlino) Verified
// (tlino) TODO: catch other errors of resolveLocalDst than noSVCBackend
// (tlino) for now we assume this method catches all possible errors from resolveLocalDst
// (tlino) we cannot prove termination of this method since p.d.resolveLocalDst() might not terminate
preserves p.Mem()
ensures pr.Mem()
func (p *scionPacketProcessor) resolveInbound() (address net.Addr, pr processResult, errRet error) {
	unfold p.Mem()
	sl := p.scionLayer
	a, err := p.d.resolveLocalDst(sl)
	switch {
	// (tlino) globals not supported
	// case errors.Is(err, noSVCBackend):
	case errors.Is(err, noSVCBackend()):
		// (tlino) original code, adapted code is below
		// r, err := p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeDestinationUnreachable,
		// 			slayers.SCMPCodeNoRoute),
		// 	},
		// 	&slayers.SCMPDestinationUnreachable{}, err)
		// return nil, r, err
		scmpH := &slayers.SCMP{
			TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeDestinationUnreachable,
				slayers.SCMPCodeNoRoute),
		}
		fold scmpH.Mem()
		scmpP := &slayers.SCMPDestinationUnreachable{}
		fold scmpP.Mem()
		e := err
		fold p.Mem()
		address = nil
		pr, errRet = p.packSCMP(scmpH, scmpP, e)
	default:
		// (tlino) original code, adpated code is below
		// return a, processResult{}, nil
		fold p.Mem()
		address, pr, errRet = a, processResult{}, nil
		fold pr.Mem()
	}
}

// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) processEgress() error {
	// we are the egress router and if we go in construction direction we
	// need to update the SegID.

	unfold p.Mem()

	// (tlino) get access to p.path
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	if p.infoField.ConsDir {
		unfold path.HopFieldInv(p.hopField)
		p.infoField.UpdateSegID(p.hopField.Mac)
		fold path.HopFieldInv(p.hopField)

		// (tlino) use helper function to access CurrINF
		// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {
		if err := p.path.SetInfoField(p.infoField, int(p.path.GetCurrINF())); err != nil {
			// TODO parameter problem invalid path
			apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
			fold p.Mem()
			return serrors.WrapStr("update info field", err)
		}
	}

	if err := p.path.IncPath(); err != nil {
		// TODO parameter problem invalid path
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		fold p.Mem()
		return serrors.WrapStr("incrementing path", err)
	}
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
		fold p.Mem()
		return err
	}
	fold p.Mem()
	return nil
}

// (tlino) Verified
requires p.Mem()
ensures errRet == nil ==> p.Mem()
ensures errRet != nil ==> acc(&p.d, _) && acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4)
ensures errRet != nil ==> acc(&p.origPacket, 1/4) && acc(&p.buffer, 1/4) && acc(&p.path) && acc(&p.hopField)
ensures errRet != nil ==> acc(&p.infoField) && acc(&p.segmentChange)
ensures errRet != nil ==> acc(DataPlaneMutexInvariant(p.d), _) && verifyutils.BytesAcc(p.origPacket)
ensures errRet != nil ==> p.buffer.Mem() && p.scionLayer.Mem() && cap(p.rawPkt) == bufSize
ensures errRet != nil ==> p.path != nil && p.scionLayer != nil && p.path == p.scionLayer.getRawScionPath()
ensures errRet != nil ==> p.rawPkt == p.scionLayer.getRawPkt()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) doXover() (pr processResult, errRet error) {
	unfold p.Mem()
	p.segmentChange = true

	// (tlino) get access to p.path
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	if err := p.path.IncPath(); err != nil {
		// TODO parameter problem invalid path // (tlino) original scion comment
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		pr, errRet = processResult{}, serrors.WrapStr("incrementing path", err)
		fold pr.Mem()
		return
	}
	var err error
	if p.hopField, err = p.path.GetCurrentHopField(); err != nil {
		// TODO parameter problem invalid path // (tlino) original scion comment
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}
	if p.infoField, err = p.path.GetCurrentInfoField(); err != nil {
		// TODO parameter problem invalid path // (tlino) original scion comment
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	// (tlino) get back access to scionLayer
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}
	fold p.Mem()
	if r, err := p.validateHopExpiry(); err != nil {
		pr, errRet = r, err
		unfold p.Mem()
		return 
	}
	// verify the new block
	if r, err := p.verifyCurrentMAC(); err != nil {
		pr, errRet = r, serrors.WithCtx(err, "info", "after xover")
		unfold p.Mem()
		return 
	}
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return
}

// (tlino) Verified
preserves acc(p.Mem(), 1/10)
ensures res >= 0
decreases
func (p *scionPacketProcessor) egressInterface() (res uint16) {
	unfold acc(p.Mem(), 1/10)
	if p.infoField.ConsDir {
		res = unfolding acc(path.HopFieldInv(p.hopField), 1/100) in p.hopField.ConsEgress
		fold acc(p.Mem(), 1/10)
		return
	}
	res = unfolding acc(path.HopFieldInv(p.hopField), 1/100) in p.hopField.ConsIngress
	fold acc(p.Mem(), 1/10)
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateEgressUp() (pr processResult, errRet error) {
	egressID := p.egressInterface()
	unfold p.Mem()
	// (tlino) use getter function to avoid unfold
	// if v, ok := p.d.bfdSessions[egressID]; ok {
	if v, ok := p.d.GetBfdSession(egressID); ok {
		assert acc(v.Mem(), _)
		if !v.IsUp() {
			scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeExternalInterfaceDown, 0),
			}
			var scmpP gopacket.SerializableLayer = &slayers.SCMPExternalInterfaceDown{
				// (tlino) use getter function to avoid unfold
				// IA:   p.d.localIA,
				IA:   p.d.GetLocalAI(),
				IfID: uint64(egressID),
			}
			// (tlino) use getter function to avoid unfold
			// if _, external := p.d.external[egressID]; !external {
			if _, external := p.d.GetExternalBatchConn(egressID); !external {
				scmpH.TypeCode =
					slayers.CreateSCMPTypeCode(slayers.SCMPTypeInternalConnectivityDown, 0)
				scmpP = &slayers.SCMPInternalConnectivityDown{
					// (tlino) use getter function to avoid unfold
					// IA:      p.d.localIA,
					IA:      p.d.GetLocalAI(),
					Ingress: uint64(p.ingressID),
					Egress:  uint64(egressID),
				}
			}
			fold scmpH.Mem()
			fold scmpP.Mem()
			fold p.Mem()
			pr, errRet =  p.packSCMP(scmpH, scmpP, serrors.New("bfd session down"))
			return
		}
	}
	fold p.Mem()
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleIngressRouterAlert() (pr processResult, errRet error) {
	unfold p.Mem()
	if p.ingressID == 0 {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	unfold path.HopFieldInv(p.hopField)
	ingressAlert := (!p.infoField.ConsDir && p.hopField.EgressRouterAlert) ||
		(p.infoField.ConsDir && p.hopField.IngressRouterAlert)
	if !ingressAlert {
		fold path.HopFieldInv(p.hopField)
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	p.hopField.IngressRouterAlert = false
	fold path.HopFieldInv(p.hopField)
	ingressID := p.ingressID
	fold p.Mem()
	// (tlino) use new variable for argument
	// return p.handleSCMPTraceRouteRequest(p.ingressID)
	return p.handleSCMPTraceRouteRequest(ingressID)
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleEgressRouterAlert() (pr processResult, errRet error) {
	unfold p.Mem()
	unfold path.HopFieldInv(p.hopField)
	egressAlert := (p.infoField.ConsDir && p.hopField.EgressRouterAlert) ||
		(!p.infoField.ConsDir && p.hopField.IngressRouterAlert)
	fold path.HopFieldInv(p.hopField)
	fold p.Mem()
	if !egressAlert {
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	egressID := p.egressInterface()
	unfold p.Mem()
	unfold path.HopFieldInv(p.hopField)
	// (tlino) use getter to simplify verification
	// if _, ok := (p.d.external)[egressID]; !ok {
	if _, ok := p.d.GetExternalBatchConn(egressID); !ok {
		fold path.HopFieldInv(p.hopField)
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	p.hopField.EgressRouterAlert = false
	fold path.HopFieldInv(p.hopField)
	fold p.Mem()
	return p.handleSCMPTraceRouteRequest(egressID)
}

// (tlino) Verified
// (tlino) p.scionLayer.Payload is subsliced in scmpH and scmpP
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleSCMPTraceRouteRequest(
	interfaceID uint16) (pr processResult, errRet error) {
	// (tlino) use pointer type
	// var scmpH slayers.SCMP
	var scmpH *slayers.SCMP = &slayers.SCMP{}
	unfold p.Mem()

	// (tlino) get access to payload, use new variables to make it work
	sl := p.scionLayer
	rp := p.rawPkt
	pp := p.path
	pl := p.scionLayer.LayerPayload()
	sl.getLayerPayloadAcc(pl, pp, rp)
	assert verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
	assert verifyutils.BytesAcc(pl)

	// (tlino) access Payload over EmbeddedBaseLayer, since Gobra has no support for embedded fields.
	// (tlino) use gopacket.NilDecodeFeedback{} instead of var gopacket.NilDecodeFeedback.
	// if err := scmpH.DecodeFromBytes(p.scionLayer.Payload, gopacket.NilDecodeFeedback); err != nil {
	df := gopacket.NilDecodeFeedback{}
	fold df.Mem()
	if err := scmpH.DecodeFromBytes(pl, df); err != nil {
		// (tlino) log not supported yet
		// log.Debug("Parsing SCMP header of router alert", "err", err)

		// get back access to scionLayer
		apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
		fold p.Mem()

		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	}
	
	// (tlino) use getter for TypeCode to speed up verification
	// if scmpH.TypeCode != slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteRequest, 0) {
	if scmpH.GetTypeCode() != slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteRequest, 0) {
		// (tlino) log not supported yet
		// log.Debug("Packet with router alert, but not traceroute request",
		// 	"type_code", scmpH.TypeCode)

		// (tlino) get back access to payload from scmpH
		scmpH.getRawPktAcc(pl)
		assert verifyutils.BytesAcc(pl) --* scmpH.MemAfterDecode()
		assert verifyutils.BytesAcc(pl)
		// (tlino) get back access to scionLayer
		apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
		fold p.Mem()

		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	}

	// (tlino) get access to scmpH.Payload, use new variables to make it work
	scmpHPayload := scmpH.GetPayload()
	scmpH.getPayloadAcc(scmpHPayload, pl)
	assert verifyutils.BytesAcc(scmpHPayload) --* (scmpH.MemAfterDecode() && scmpHPayload == scmpH.GetPayload() && pl == scmpH.GetRawPkt())
	assert verifyutils.BytesAcc(scmpHPayload)

	// (tlino) use pointer type 
	// var scmpP slayers.SCMPTraceroute
	var scmpP *slayers.SCMPTraceroute = &slayers.SCMPTraceroute{}
	// (tlino) use gopacket.NilDecodeFeedback{} instead of var gopacket.NilDecodeFeedback
	// if err := scmpP.DecodeFromBytes(scmpH.Payload, gopacket.NilDecodeFeedback); err != nil {
	df2 := gopacket.NilDecodeFeedback{}
	fold df2.Mem()
	if err := scmpP.DecodeFromBytes(scmpHPayload, df2); err != nil {
		// (tlino) log not supported yet
		// log.Debug("Parsing SCMPTraceroute", "err", err)

		// get back access to scmpH
		apply verifyutils.BytesAcc(scmpHPayload) --* (scmpH.MemAfterDecode() && scmpHPayload == scmpH.GetPayload() && pl == scmpH.GetRawPkt())
		// (tlino) get back access to payload from scmpH
		scmpH.getRawPktAcc(pl)
		assert verifyutils.BytesAcc(pl) --* scmpH.MemAfterDecode()
		assert verifyutils.BytesAcc(pl)
		// (tlino) get back access to scionLayer
		apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
		fold p.Mem()

		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	}
	// (tlino) get values from scmpP
	scmpPIdent := scmpP.GetIdentifier()
	scmpPSeq := scmpP.GetSequence()

	// (tlino) get back acces to scmpHPayload
	scmpP.GetRawPktAcc(scmpHPayload)
	assert verifyutils.BytesAcc(scmpHPayload) --* (scmpP.Mem() && scmpHPayload == scmpP.GetRawPkt())
	assert verifyutils.BytesAcc(scmpHPayload)
	// (tlino) get back acces to scmpH
	apply verifyutils.BytesAcc(scmpHPayload) --* (scmpH.MemAfterDecode() && scmpHPayload == scmpH.GetPayload() && pl == scmpH.GetRawPkt())
	// (tlino) get back access to scionLayer.Payload
	scmpH.getRawPktAcc(pl)
	assert verifyutils.BytesAcc(pl) --* scmpH.MemAfterDecode()
	assert verifyutils.BytesAcc(pl)
	// (tlino) get back access to scionLayer
	apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())


	// // (tlino) original code, outlined to function
	// // scmpH = slayers.SCMP{
	// // 	TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteReply, 0),
	// // }
	// // scmpP = slayers.SCMPTraceroute{
	// // 	Identifier: scmpP.Identifier,
	// // 	Sequence:   scmpP.Sequence,
	// // 	IA:         p.d.localIA,
	// // 	Interface:  uint64(interfaceID),
	// // }
	// // return p.packSCMP(&scmpH, &scmpP, nil)

	fold p.Mem()
	return p.handleSCMPTraceRouteRequest2(interfaceID, scmpPIdent, scmpPSeq)
}

// (tlino) Verified
// (tlino) added method to simplify verification
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleSCMPTraceRouteRequest2(interfaceID uint16, scmpPIdent uint16, 
	scmpPSeq uint16) (pr processResult, errRet error) {

	scmpH := &slayers.SCMP{
		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteReply, 0),
	}
	fold scmpH.Mem()

	unfold p.Mem()
	scmpP := &slayers.SCMPTraceroute{
		Identifier: scmpPIdent,
		Sequence:   scmpPSeq,
		// (tlino) use getter to simplify verification
		// IA:         p.d.localIA,
		IA:         p.d.GetLocalAI(),
		Interface:  uint64(interfaceID),
	}
	fold p.Mem()
	fold scmpP.Mem()
	return p.packSCMP(scmpH, scmpP, nil)
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validatePktLen() (pr processResult, errRet error) {
	unfold p.Mem()
	// (joao) adapted to avoid unfolding predicates
	// if int(p.scionLayer.PayloadLen) == len(p.scionLayer.Payload) {
	if int(p.scionLayer.getPayloadLen()) == len(p.scionLayer.LayerPayload()) {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{
	// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
	// 			slayers.SCMPCodeInvalidPacketSize),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: 0},
	// 	serrors.New("bad packet size",
	// 		"header", p.scionLayer.PayloadLen, "actual", len(p.scionLayer.Payload)),
	// )

	scmpH := &slayers.SCMP{
			TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
			slayers.SCMPCodeInvalidPacketSize),
		}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: 0}
	fold scmpP.Mem()
	e := serrors.New("bad packet size", 
		"header", p.scionLayer.getPayloadLen(), "actual", len(p.scionLayer.LayerPayload()))
	
	fold p.Mem()
	return p.packSCMP(scmpH, scmpP, e)
}

// (tlino) Verified
// (tlino) added helper function to create magic wand 
ghost
requires pr.Mem()
requires scionLayer.Mem()
requires rawPkt != nil && rawPkt == scionLayer.getRawPkt()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
decreases
func processHelper(pr processResult, scionLayer *slayers.SCION, rawPkt []byte) {
	scionLayer.getRawPktAccWithoutPreservePath(rawPkt)
	assert verifyutils.BytesAcc(rawPkt)
	package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {}
}

// (tlino) Verified
// (tlino) This method needs an alias to rawPkt as ghost argument, such that it can relate
// (tlino) pr.Mem() --* verifyutils.BytesAcc(rawPktAlias) to pr.Mem() --* verifyutils.BytesAcc(p.rawPkt)
// (tlino) We cannot prove termination of this method, since p.resolveInbound() might not terminate
requires acc(&p.d, _) && acc(&p.ingressID, 1/2) && acc(&p.rawPkt, 1/2) && acc(&p.scionLayer, 1/2)
requires acc(&p.origPacket, 1/2) && acc(&p.buffer, 1/2) && acc(&p.path) && acc(&p.hopField)
requires acc(&p.infoField) && acc(&p.segmentChange)
requires acc(DataPlaneMutexInvariant(p.d), _)
requires unfolding acc(DataPlaneMutexInvariant(p.d), _) in p.d.svc != nil
requires verifyutils.BytesAcc(p.origPacket)
requires cap(p.rawPkt) == bufSize
requires (p.buffer).Mem()
requires p.scionLayer != nil && (p.scionLayer).Mem() && (p.scionLayer).getRawPkt() == p.rawPkt
requires rawPktAlias == p.rawPkt
ensures acc(&p.d, _) && acc(&p.ingressID, 1/2) && acc(&p.rawPkt, 1/2) && acc(&p.scionLayer, 1/2)
ensures acc(&p.origPacket, 1/2) && acc(&p.buffer, 1/2) && acc(&p.path) && acc(&p.hopField)
ensures acc(&p.infoField) && acc(&p.segmentChange)
ensures verifyutils.BytesAcc(p.origPacket)
ensures (p.buffer).Mem()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
func (p *scionPacketProcessor) process(ghost rawPktAlias []byte) (pr processResult, errProcess error) {
	if r, err := p.parsePath(); err != nil {
		pr, errProcess := r, err
		
		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}

	// (tlino) keep read access to fields, they aren't modified
	assert acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4) && acc(&p.origPacket, 1/4) && acc(&p.buffer, 1/4)

	if r, err := p.validatePktLen(); err != nil {
		// (tlino) original code, adapted code is below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		
		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}

	if err := p.updateNonConsDirIngressSegID(); err != nil {
		// (tlino) original code, adapted code is below
		// return processResult{}, err

		unfold p.Mem()
		pr, errProcess = processResult{}, err
		fold pr.Mem()

		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}
	
	if r, err := p.verifyCurrentMAC(); err != nil {
		// (tlino) original code, adapted code is below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err

		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}
	
	if r, err := p.handleIngressRouterAlert(); err != nil {
		// (tlino) original code, adapted code is below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err

		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}
	
	// (tlino) added code, get some values
	unfold p.Mem()
	dstIA := p.scionLayer.getDstIA()
	localIA := p.d.GetLocalAI()

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	rp := p.rawPkt
	scionL := p.scionLayer
	scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	currHF := pp.GetCurrHF()
	numHops := pp.GetNumHops()

	// Inbound: pkts destined to the local IA.
	// (tlino) use getters above to avoid unfoldings
	// if p.scionLayer.DstIA.Equal(p.d.localIA) && int(p.path.PathMeta.CurrHF)+1 == p.path.NumHops {
	if dstIA.Equal(localIA) && int(currHF)+1 == numHops {
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		a, r, err := p.resolveInbound()
		if err != nil {
			// (tlino) original code, adapted code below
			// return r, err

			unfold p.Mem()
			pr, errProcess = r, err

			processHelper(pr, p.scionLayer, p.rawPkt)

			assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
			return pr, errProcess
		}
		// (tlino) original code, adapted code below
		// return processResult{OutConn: p.d.internal, OutAddr: a, OutPkt: p.rawPkt}, nil
		unfold p.Mem()

		// get access to rawPkt, use new variables to make Gobra work
		assert p.scionLayer.Mem()
		sl := p.scionLayer
		rp := p.rawPkt
		sl.getRawPktAccWithoutPreservePath(rp)
		assert verifyutils.BytesAcc(rp)

		pr, errProcess = processResult{OutConn: p.d.getInternal(), OutAddr: a, OutPkt: p.rawPkt}, nil
		fold pr.Mem()
		assert pr.Mem()

		package pr.Mem() --* (verifyutils.BytesAcc(rp)) {
			unfold pr.Mem()
		}

		assert pr.Mem() --* (verifyutils.BytesAcc(rp))
		return pr, errProcess
	}

	// Outbound: pkts leaving the local IA.
	// BRTransit: pkts leaving from the same BR different interface.

	// (tlino) check acces to p.path
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	isXover := p.path.IsXover()
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	fold p.Mem()

	// (tlino) use variable instead of p.path.IsXover()
	// if p.path.IsXover() {
	if isXover {
		if r, err := p.doXover(); err != nil {
			// (tlino) original code, adapted code below
			// return r, err

			pr, errProcess = r, err

			processHelper(pr, p.scionLayer, p.rawPkt)

			assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
			return pr, errProcess
		}
	}
	
	if r, err := p.validateEgressID(); err != nil {
		// (tlino) original code, adapted code below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		assert pr.Mem()
		assert p.scionLayer.Mem()
		
		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}
	
	// handle egress router alert before we check if it's up because we want to
	// send the reply anyway, so that trace route can pinpoint the exact link
	// that failed.
	if r, err := p.handleEgressRouterAlert(); err != nil {
		// (tlino) original code, adapted code below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err

		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}
	if r, err := p.validateEgressUp(); err != nil {
		// (tlino) original code, adapted code below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err

		processHelper(pr, p.scionLayer, p.rawPkt)

		assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
		return pr, errProcess
	}
	egressID := p.egressInterface()

	// (tlino) use getter to simplify verification
	// if c, ok := p.d.external[egressID]; ok {
	if c, ok := p.d.GetExternalBatchConn(egressID); ok {
		if err := p.processEgress(); err != nil {
			// (tlino) original code,  adapted code below
			// return processResult{}, err

			unfold p.Mem()
			pr, errProcess = processResult{}, err
			fold pr.Mem()

			processHelper(pr, p.scionLayer, p.rawPkt)

			assert pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
			return pr, errProcess
		}
		// (tlino) original code, adapted code is below
		// return processResult{EgressID: egressID, OutConn: c, OutPkt: p.rawPkt}, nil

		unfold p.Mem()

		// get access to rawPkt, use new variables to make Gobra work
		assert p.scionLayer.Mem()
		sl := p.scionLayer
		rp := p.rawPkt
		sl.getRawPktAccWithoutPreservePath(rp)
		assert verifyutils.BytesAcc(rp)
		
		assert acc(c.Mem(), _)

		pr, errProcess = processResult{EgressID: egressID, OutConn: c, OutPkt: p.rawPkt}, nil
		fold pr.Mem()
		assert pr.Mem()

		package pr.Mem() --* (verifyutils.BytesAcc(rp)) {
			unfold pr.Mem()
		}

		assert pr.Mem() --* (verifyutils.BytesAcc(rp))
		return pr, errProcess
	}
	
	// ASTransit: pkts leaving from another AS BR.

	// (tlino) use getter to simplify verification
	// if a, ok := p.d.internalNextHops[egressID]; ok {
	if a, ok := p.d.GetInternalNextHop(egressID); ok {
		// (tlino) original code, adapted code is below
		// return processResult{OutConn: p.d.internal, OutAddr: a, OutPkt: p.rawPkt}, nil

		unfold p.Mem()

		// get access to rawPkt, use new variables to make Gobra work
		assert p.scionLayer.Mem()
		sl := p.scionLayer
		rp := p.rawPkt
		sl.getRawPktAccWithoutPreservePath(rp)
		assert verifyutils.BytesAcc(rp)

		pr, errProcess = processResult{OutConn: p.d.getInternal(), OutAddr: a, OutPkt: p.rawPkt}, nil
		fold pr.Mem()
		assert pr.Mem()

		package pr.Mem() --* (verifyutils.BytesAcc(rp)) {
			unfold pr.Mem()
		}

		assert pr.Mem() --* (verifyutils.BytesAcc(rp))
		return pr, errProcess
	}

	assert p.Mem()

	errCode := slayers.SCMPCodeUnknownHopFieldEgress
	consDir := unfolding acc(p.Mem(), 1/1000) in p.infoField.ConsDir
	// (tlino) use variable for ConsDir, simplifies verification
	// if !p.infoField.ConsDir {
	if !consDir {
		errCode = slayers.SCMPCodeUnknownHopFieldIngress
	}

	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{
	// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
	// 	cannotRoute,
	// )
	scmpH := &slayers.SCMP{
		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
	}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
	fold scmpP.Mem()
	e := cannotRoute()
	pr, errProcess = p.packSCMP(scmpH, scmpP, e)

	assert pr.Mem()
	unfold p.Mem()

	// get access to rawPkt, use new variables to make Gobra work
	assert p.scionLayer.Mem()
	sl := p.scionLayer
	rp := p.rawPkt
	sl.getRawPktAccWithoutPreservePath(rp)
	assert verifyutils.BytesAcc(rp)

	package pr.Mem() --* (verifyutils.BytesAcc(rp)) {
		unfold pr.Mem()
	}

	assert pr.Mem() --* (verifyutils.BytesAcc(rp))
	return pr, errProcess
}

// (tlino) Specified
// (tlino) added helper function to simulate the result of a MAC computation
requires acc(DataPlaneMutexInvariant(d), _)
preserves acc(p.Mem(), 1/1000)
ensures len(res) == path.MacLen
ensures forall i int :: 0 <= i && i < len(res) ==> acc(&res[i])
decreases _
func (d *DataPlane) getDummyMac(p *onehop.Path) (res []byte)

// (tlino) Verified
// (tlino) added helper function to create the magic wand
ghost
requires scionLayer.Mem()
requires rawPkt == scionLayer.getRawPkt()
preserves pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
decreases
func processOHPHelper(pr processResult, scionLayer *slayers.SCION, rawPkt []byte) {
	package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {
		scionLayer.getRawPktAccWithoutPreservePath(rawPkt)
	}
}

// (tlino) Verified
// (tlino) we cannot prove termination of this method, since processOHP2 might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires ingressID >= 0
requires s.Mem() && s.getRawPkt() == rawPkt
preserves buffer.Mem()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
// (tlino) s is now a *slayers.SCION
// func (d *DataPlane) processOHP(ingressID uint16, rawPkt []byte, s slayers.SCION,
//	buffer gopacket.SerializeBuffer) (processResult, error) {
func (d *DataPlane) processOHP(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	buffer gopacket.SerializeBuffer) (pr processResult, errRet error) {
		
	// (tlino) add path variable
	unfold s.Mem()
	p, ok := (s.Path).(*onehop.Path)
	if !ok {
		// TODO parameter problem -> invalid path // (tlino) original scion comment
		// (tlino) globals not supported
		// return processResult{}, malformedPath
		pr, errRet = processResult{}, malformedPath()
		fold pr.Mem()
		fold s.Mem()
		ghost processOHPHelper(pr, s, rawPkt)
		return 
	}
	// (tlino) the deserializer enforces that p != nil holds
	// (tlino) however, gobra cannot deduce that after
	// (tlino) asserting the dynamic type ((s.Path).(*onehop.Path))
	assume p != nil
	assert p.Mem()
	
	// (tlino) use getter to simplify verification
	// if !p.Info.ConsDir {
	if !p.GetConsDir() {
		// TODO parameter problem -> invalid path // (tlino) original scion comment
		
		// (tlino) globals not supported
		// return processResult{}, serrors.WrapStr(
		// 	"OneHop path in reverse construction direction is not allowed",
		// 	malformedPath, "srcIA", s.SrcIA, "dstIA", s.DstIA)

		pr, errRet = processResult{}, serrors.WrapStr(
			"OneHop path in reverse construction direction is not allowed",
			malformedPath(), "srcIA", s.SrcIA, "dstIA", s.DstIA)
		fold pr.Mem()
		fold s.Mem()
		ghost processOHPHelper(pr, s, rawPkt)
		return 
	}
	
	// (tlino) use getter to simplify verification
	// if !d.localIA.Equal(s.DstIA) && !d.localIA.Equal(s.SrcIA) {
	if !(d.GetLocalAI()).Equal(s.DstIA) && !(d.GetLocalAI()).Equal(s.SrcIA) {
		// TODO parameter problem -> invalid path // (tlino) original scion comment
		
		// (tlino) globals not supported
		// return processResult{}, serrors.WrapStr("OneHop neither destined or originating from IA",
		// 	cannotRoute, "localIA", d.localIA, "srcIA", s.SrcIA, "dstIA", s.DstIA)

		pr, errRet = processResult{}, serrors.WrapStr("OneHop neither destined or originating from IA",
			cannotRoute(), "localIA", d.GetLocalAI(), "srcIA", s.SrcIA, "dstIA", s.DstIA)

		fold pr.Mem()
		fold s.Mem()
		ghost processOHPHelper(pr, s, rawPkt)
		return 
	}

	// OHP leaving our IA

	// (tlino) use getter to simplify verification
	// if d.localIA.Equal(s.SrcIA) {
	if (d.GetLocalAI()).Equal(s.SrcIA) {
		// (tlino) function pointers (macFactory) aren't supported yet
		// if err := path.VerifyMAC(d.macFactory(), &p.Info, &p.FirstHop); err != nil {
		// 	// TODO parameter problem -> invalid MAC // (tlino) original scion comment
		// 	return processResult{}, serrors.WithCtx(err, "type", "ohp")
		// }

		// (tlino) use update function to avoid unfolding p
		// p.Info.UpdateSegID(p.FirstHop.Mac)
		p.InfoUpdateSegID()

		fold s.Mem()
		assert p == s.getOHPPath()
		if err := updateSCIONLayer(rawPkt, s, buffer); err != nil {
			// (tlino) original code, adapted code is below
			// return processResult{}, err
			pr, errRet = processResult{}, err
			fold pr.Mem()
			ghost processOHPHelper(pr, s, rawPkt)
			return 
		}

		// (tlino) added code to get back relation between p and s.Path
		assert p != nil && p == s.getOHPPath()
		unfold s.Mem()
		assert p.Mem()

		// OHP should always be directed to the correct BR. // (tlino) original scion comment
		// (tlino) use getter to simplify verification
		// if c, ok := d.external[p.FirstHop.ConsEgress]; ok {
		fristHopConsEgress := p.GetFristHopConsEgress()
		if c, ok := d.GetExternalBatchConn(fristHopConsEgress); ok {
			// buffer should already be correct // (tlino) original scion comment

			// (tlino) get access to rawPkt
			fold s.Mem()
			s.getRawPktAccWithoutPreservePath(rawPkt)
			assert verifyutils.BytesAcc(rawPkt)

			// (tlino) use getter to simplify verification
			// return processResult{EgressID: p.FirstHop.ConsEgress, OutConn: c, OutPkt: rawPkt}, nil
			assert acc(c.Mem(), _)
			pr, errRet = processResult{EgressID: fristHopConsEgress, OutConn: c, OutPkt: rawPkt}, nil
			fold pr.Mem()
			package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {
				unfold pr.Mem()
			}
			return 
		}
		
		// TODO parameter problem invalid interface // (tlino) original scion comment
		// (tlino) use getter to simplify verification
		// return processResult{}, serrors.WithCtx(cannotRoute, "type", "ohp",
		// 	"egress", p.FirstHop.ConsEgress, "consDir", p.Info.ConsDir)

		pr, errRet = processResult{}, serrors.WithCtx(cannotRoute(), "type", "ohp",
			"egress", p.GetFristHopConsEgress(), "consDir", p.GetConsDir())

		fold pr.Mem()
		fold s.Mem()
		ghost processOHPHelper(pr, s, rawPkt)
		return 
	}

	// (tlino) outlined the rest of the method
	fold s.Mem()
	pr, errRet = d.processOHP2(ingressID, rawPkt, s, buffer, p)
	return
}

// (tlino) Verified
// (tlino) added method to simplify verification
// (tlino) we cannot prove termination of this method, since d.resolveLocalDst() might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires ingressID >= 0
requires s.Mem() && s.getRawPkt() == rawPkt
requires p != nil && p == s.getOHPPath() 
preserves buffer.Mem()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
func (d *DataPlane) processOHP2(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	buffer gopacket.SerializeBuffer, p *onehop.Path) (pr processResult, errRet error) {

	// (tlino) get access to p.Mem()
	unfold s.Mem()
	assert p.Mem()

	// (tlino) use setter function to avoid unfolding p
	// (tlino) macFactory isn't supported, usse dummy MAC instead
	// (tlino) the dummyMac function has slithly different arguments then the
	// (tlino) real one, but it also requieres read permission to p
	// OHP entering our IA
	// p.SecondHop = path.HopField{
	// 	ConsIngress: ingressID,
	// 	ExpTime:     p.FirstHop.ExpTime,
	// }
	// p.SecondHop.Mac = path.MAC(d.macFactory(), &p.Info, &p.SecondHop)
	secondHop := path.HopField{
		ConsIngress: ingressID,
		ExpTime:     p.GetFirstHopExpTime(),
	}
	secondHop.Mac = d.getDummyMac(p)
	p.SetSecondHop(secondHop)

	fold s.Mem()
	if err := updateSCIONLayer(rawPkt, s, buffer); err != nil {
		// (tlino) original code, adapted code is below
		// return processResult{}, err
		pr, errRet = processResult{}, err
		fold pr.Mem()
		ghost processOHPHelper(pr, s, rawPkt)
		return 
	}
	
	a, err := d.resolveLocalDst(s)
	if err != nil {
		// (tlino) original code, adapted code is below
		// return processResult{}, err
		pr, errRet = processResult{}, err
		fold pr.Mem()
		ghost processOHPHelper(pr, s, rawPkt)
		return
	}
	// (tlino) original code, adapted code is below
	// return processResult{OutConn: d.internal, OutAddr: a, OutPkt: rawPkt}, nil
	// (tlino) get access to rawPkt
	s.getRawPktAccWithoutPreservePath(rawPkt)
	assert verifyutils.BytesAcc(rawPkt)
	unfold acc(DataPlaneMutexInvariant(d), _)
	pr, errRet = processResult{OutConn: d.getInternal(), OutAddr: a, OutPkt: rawPkt}, nil
	fold pr.Mem()
	package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {
		unfold pr.Mem()
	}
	return
}

// (tlino) Verified
// (tlino) res contains a subslice of s.rawPkt
// (tlino) This method doesn't establish res.Mem(), since the caller embedds res
// (tlino) in a processResult together with the rawPkt.
// (tlino) we cannot prove termination of this method, since  d.svc.Any() might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
preserves acc(s.Mem(), 1/100)
// (tlino) use *slayers.SCION instead of slayers.SCION
// func (d *DataPlane) resolveLocalDst(s slayers.SCION) (net.Addr, error)
func (d *DataPlane) resolveLocalDst(s *slayers.SCION) (res net.Addr, errRet error) {
	// (joao) DstAddr expects a *SCION, not a SCION. Gobra does not support this
	dst, err := s.DstAddr()
	if err != nil {
		// TODO parameter problem. // (joao) this is an original comment from SCION
		return nil, invalidDstAddr()
	}
	assert acc(dst.Mem(), 1/200)
	if v, ok := dst.(addr.HostSVC); ok {
		// For map lookup use the Base address, i.e. strip the multi cast // (tlino) original scion comment
		// information, because we only register base addresses in the map. // (tlino) original scion comment
		unfold acc(DataPlaneMutexInvariant(d), _)
		s.AddReadDstAddr(dst)
		a, ok := d.svc.Any(v.Base())
		if !ok {
			// (tlino) globals are not supported
			// return nil, noSVCBackend
			return nil, noSVCBackend()
		}
		return a, nil
	}
	res = addEndhostPort(dst)
	s.AddReadDstAddr(dst)
	return res, nil
}

// (tlino) Verified
// (tlino) This method may not establish ret.Mem()
preserves acc(dst.Mem(), 1/200)
decreases
func addEndhostPort(dst net.Addr) (ret net.Addr) {
	if ip, ok := dst.(*net.IPAddr); ok {
		unfold acc(ip.Mem(), 1/200)
		ret := &net.UDPAddr{IP: ip.IP, Port: topology.EndhostPort}
		fold acc(ip.Mem(), 1/200)
		return ret
	}
	ret := dst
	return dst
}

// (tlino) Verified
preserves s.Mem() && buffer.Mem()
preserves rawPkt == s.getRawPkt()
ensures s.getRawPkt() == old(s.getRawPkt()) && s.getRawScionPath() == old(s.getRawScionPath()) && s.getOHPPath() == old(s.getOHPPath())
decreases
// (tlino) use *slayers.SCION instead of slayers.SCION
// func updateSCIONLayer(rawPkt []byte, s slayers.SCION, buffer gopacket.SerializeBuffer) error {
func updateSCIONLayer(rawPkt []byte, s *slayers.SCION, buffer gopacket.SerializeBuffer) (err error) {
	if err := buffer.Clear(); err != nil {
		return err
	}
	if err := s.SerializeTo(buffer, gopacket.SerializeOptions{}); err != nil {
		return err
	}
	// TODO(lukedirtwalker): We should add a method to the scion layers
	// which can write into the existing buffer, see also the discussion in
	// https://fsnets.slack.com/archives/C8ADBBG0J/p1592805884250700
	
	// (tlino) obtain access to rawPkt
	s.getRawPktAcc(rawPkt)
	assert verifyutils.BytesAcc(rawPkt) --* (s.Mem() && rawPkt == s.getRawPkt() && s.getRawScionPath() == old(s.getRawScionPath()) && s.getOHPPath() == old(s.getOHPPath()))
	unfold verifyutils.BytesAcc(rawPkt)

	rawContents := buffer.Bytes()
	assert verifyutils.BytesAcc(rawContents) --* buffer.Mem()
	unfold verifyutils.BytesAcc(rawContents)
	// (tlino) use Gobra's copy
	// copy(rawPkt[:len(rawContents)], rawContents)

	// rawContents cannot have a higher length than rawPkt, since it only contains the SCION fields without the payload
	assume len(rawContents) <= len(rawPkt)
	assert forall i int :: { rawContents[i] } (0 <= i && i < len(rawContents)) ==> acc(&rawContents[i], 1/100000)
	assert forall i int :: { rawPkt[i] } (0 <= i && i < len(rawPkt)) ==> acc(&rawPkt[i])
	assert forall i int :: 0 <= i && i < len(rawContents) ==> &(rawPkt[:len(rawContents)])[i] == &rawPkt[i]
	assert forall i int :: 0 <= i && i < len(rawContents) ==> acc(&(rawPkt[:len(rawContents)])[i])

	verifyutils.OutlineMemorySafeCopy(rawPkt[:len(rawContents)], rawContents)

	fold verifyutils.BytesAcc(rawPkt)
	apply verifyutils.BytesAcc(rawPkt) --* (s.Mem() && rawPkt == s.getRawPkt() && s.getRawScionPath() == old(s.getRawScionPath()) && s.getOHPPath() == old(s.getOHPPath()))

	fold verifyutils.BytesAcc(rawContents)
	apply verifyutils.BytesAcc(rawContents) --* buffer.Mem()

	return nil
}

type bfdSend struct {
	conn             BatchConn
	srcAddr, dstAddr *net.UDPAddr
	srcIA, dstIA     addr.IA
//	macFactory       func() hash.Hash
	ifID             uint16
}

//pure func (b *bfdSend) String() string {
//	return b.srcAddr.String()
//}

//func (b *bfdSend) Send(bfd *layers.BFD) error {
//	scn := &slayers.SCION{
//		Version:      0,
//		TrafficClass: 0xb8,
//		FlowID:       0xdead,
//		NextHdr:      common.L4BFD,
//		SrcIA:        b.srcIA,
//		DstIA:        b.dstIA,
//	}
//
//	if err := scn.SetSrcAddr(&net.IPAddr{IP: b.srcAddr.IP}); err != nil {
//		return err
//	}
//	if err := scn.SetDstAddr(&net.IPAddr{IP: b.dstAddr.IP}); err != nil {
//		return err
//	}
//
//	if b.ifID == 0 {
//		scn.PathType = slayers.PathTypeEmpty
//		scn.Path = &empty.Path{}
//	} else {
//		ohp := &onehop.Path{
//			Info: path.InfoField{
//				ConsDir: true,
//				// Subtract 10 seconds to deal with possible clock drift.
//				Timestamp: uint32(time.Now().Unix() - 10),
//			},
//			FirstHop: path.HopField{
//				ConsEgress: b.ifID,
//				ExpTime:    hopFieldDefaultExpTime,
//			},
//		}
//		ohp.FirstHop.Mac = path.MAC(b.macFactory(), &ohp.Info, &ohp.FirstHop)
//		scn.PathType = slayers.PathTypeOneHop
//		scn.Path = ohp
//	}
//
//	buffer := gopacket.NewSerializeBuffer()
//	err := gopacket.SerializeLayers(buffer, gopacket.SerializeOptions{FixLengths: true},
//		scn, bfd)
//	if err != nil {
//		return err
//	}
//	msg := ipv4.Message{}
//	msg.Buffers = make([][]byte, 1)
//	raw := buffer.Bytes()
//	msg.Buffers[0] = make([]byte, len(raw))
//	copy(msg.Buffers[0], raw)
//	msg.N = len(raw)
//	msg.Addr = b.dstAddr
//	_, err = b.conn.WriteBatch(underlayconn.Messages{msg})
//	return err
//}

// (tlino) This interface is never used
//type pathUpdater interface {
//	update(p *scion.Raw) error
//}

type scmpPacker struct {
	internalIP net.IP
	localIA    addr.IA
	origPacket []byte
	ingressID  uint16

	scionL *slayers.SCION
	buffer gopacket.SerializeBuffer
	quote  []byte
}

// (tlino) For the moment we don't verify this method, since it is hard to verify,
// (tlino) and it's implementation significantly changed in the mean time in the original scion repo.
// (tlino) Unfortunatly, we cannot just easy merge the most current implementation in our VerifiedScion code base,
// (tlino) since this would require to adapt other structs and methods too.
requires scmpH.Mem() && scmpP.Mem()
preserves s.scionL.Mem() && s.buffer.Mem()
preserves verifyutils.BytesAcc(s.origPacket)
ensures s.scionL == old(s.scionL)
ensures s.scionL.getRawScionPath() == old(s.scionL.getRawScionPath())
ensures s.scionL.getRawPkt() == old(s.scionL.getRawPkt())
ensures b != nil ==> verifyutils.BytesAcc(b)
decreases _
func (s scmpPacker) prepareSCMP(scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer, 
	incPath bool, cause error) (b []byte, e error) //{

	// // We use the original packet but put the already updated path, because usually a router will
	// // not keep a copy of the original/unmodified packet around.
	// unfold s.Mem()
	// unfold s.scionL.Mem()
	// // (tlino) access Raw over tmp, added check
	// // (tlino) find more elegant solution
	// // pathRaw := (s.scionL.Path).(*scion.Raw).Raw
	// tmpPath, ok := (s.scionL.Path).(*scion.Raw)
	// // if !ok {
	// // 	assume false
	// // 	panic(e)
	// // }

	// assume typeOf(tmpPath) == *scion.Raw && tmpPath != nil
	// unfold tmpPath.Mem()
	// pathRaw := tmpPath.Raw
	// assert forall i int :: 0 <= i && i < len(pathRaw) ==> acc(&pathRaw[i])
	// // (tlino) use gopacket.NilDecodeFeedback{} instead of global gopacket.NilDecodeFeedback
	// // if err := s.scionL.DecodeFromBytes(s.origPacket, gopacket.NilDecodeFeedback); err != nil {
	// // 	panic(err)
	// // }
	
	// fold tmpPath.Mem()
	// unfold verifyutils.BytesAcc(s.origPacket)
	// df := gopacket.NilDecodeFeedback{}
	// fold df.Mem()
	// if err := s.scionL.DecodeFromBytes(s.origPacket, df); err != nil {
	// 	assume false
	// 	panic(err)
	// }

	// unfold s.scionL.Mem()
	// path := (s.scionL.Path).(*scion.Raw)

 	// path.Raw = pathRaw
// 	decPath, err := path.ToDecoded()
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "decoding raw path")
// 	}
// 	s.scionL.Path = decPath
// 	if err := decPath.Reverse(); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "reversing path for SCMP")
// 	}
// 	if incPath || decPath.IsXover() {
// 		infoField := decPath.InfoFields[decPath.PathMeta.CurrINF]
// 		if infoField.ConsDir {
// 			hopField := decPath.HopFields[decPath.PathMeta.CurrHF]
// 			infoField.UpdateSegID(hopField.Mac)
// 		}
// 		if err := decPath.IncPath(); err != nil {
// 			return nil, serrors.Wrap(cannotRoute, err, "details", "incrementing path for SCMP")
// 		}
// 	}

// 	s.scionL.DstIA = s.scionL.SrcIA
// 	s.scionL.SrcIA = s.localIA
// 	srcA, err := s.scionL.SrcAddr()
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "extracting src addr")
// 	}
// 	if err := s.scionL.SetDstAddr(srcA); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "setting dest addr")
// 	}
// 	if err := s.scionL.SetSrcAddr(&net.IPAddr{IP: s.internalIP}); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "setting src addr")
// 	}
// 	s.scionL.NextHdr = common.L4SCMP

// 	scmpH.SetNetworkLayerForChecksum(s.scionL)

// 	if err := s.buffer.Clear(); err != nil {
// 		return nil, err
// 	}

// 	sopts := gopacket.SerializeOptions{
// 		ComputeChecksums: true,
// 		FixLengths:       true,
// 	}
// 	scmpLayers := []gopacket.SerializableLayer{s.scionL, scmpH, scmpP}
// 	if cause != nil {
// 		add quote for errors.
// 		hdrLen := slayers.CmnHdrLen + s.scionL.AddrHdrLen() + s.scionL.Path.Len()
// 		switch scmpH.TypeCode.Type() {
// 		case slayers.SCMPTypeExternalInterfaceDown:
// 			hdrLen += 20
// 		case slayers.SCMPTypeInternalConnectivityDown:
// 			hdrLen += 28
// 		default:
// 			hdrLen += 8
// 		}
// 		maxQuoteLen := slayers.MaxSCMPPacketLen - hdrLen
// 		if len(s.quote) > maxQuoteLen {
// 			s.quote = s.quote[:maxQuoteLen]
// 		}
// 		scmpLayers = append(scmpLayers, gopacket.Payload(s.quote))
// 	}
// 	err = gopacket.SerializeLayers(s.buffer, sopts, scmpLayers...)
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "serializing SCMP message")
// 	}
// 	return s.buffer.Bytes(), scmpError{TypeCode: scmpH.TypeCode, Cause: cause}
//}

// (tlino) This type is never used
type segIDUpdater struct{}

// (tlino) This function is never used
//func (segIDUpdater) update(p *scion.Raw) error {
//	cHF, err := p.GetCurrentHopField()
//	if err != nil {
//		return err
//	}
//	cIF, err := p.GetCurrentInfoField()
//	if err != nil {
//		return err
//	}
//	cIF.UpdateSegID(cHF.Mac)
//	return nil
//}

// (tlino) This type is never used
type pathIncrementer struct{}

// (tlino) This function is never used
//func (pathIncrementer) update(p *scion.Raw) error {
//	return p.IncPath()
//}

// (tlino) Verified
requires neighbors != nil ==> acc(neighbors, _)
requires id >= 0
ensures acc(res)
decreases
func interfaceToMetricLabels(id uint16, localIA addr.IA,
	neighbors map[uint16]addr.IA) (res prometheus.Labels) {

	if id == 0 {
		return prometheus.Labels{
			"isd_as":          localIA.String(),
			"interface":       "internal",
			"neighbor_isd_as": localIA.String(),
		}
	}
	return prometheus.Labels{
		"isd_as":          localIA.String(),
		"interface":       strconv.FormatUint(uint64(id), 10),
		"neighbor_isd_as": neighbors[id].String(),
	}
}

ensures acc(res)
decreases
func serviceMetricLabels(localIA addr.IA, svc addr.HostSVC) (res prometheus.Labels) {
	return prometheus.Labels{
		"isd_as":  localIA.String(),
		"service": svc.BaseString(),
	}
}