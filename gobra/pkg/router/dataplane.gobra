// Copyright 2020 Anapaya Systems
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package router

import (
	"bytes"
	// "crypto/rand"
	"errors"
	// "fmt"
	// "hash"
	// "math/big"
	"net"
	"strconv"
	"sync"
	"time"

	// "github.com/google/gopacket"
	"gobra/dependencies/gopacket"
	// "github.com/google/gopacket/layers"
	"gobra/dependencies/gopacket/layers"
	// "github.com/prometheus/client_golang/prometheus"
	"gobra/dependencies/prometheus/client_golang/prometheus"
	// "golang.org/x/net/ipv4"
	"gobra/dependencies/x/net/ipv4"

	// "github.com/scionproto/scion/go/lib/addr"
	"gobra/lib/addr"
	// "github.com/scionproto/scion/go/lib/common"
	"gobra/lib/common"
	// "github.com/scionproto/scion/go/lib/log"
	// "github.com/scionproto/scion/go/lib/metrics"
	"gobra/lib/metrics"
	// "github.com/scionproto/scion/go/lib/scrypto"
	// "github.com/scionproto/scion/go/lib/serrors"
	"gobra/lib/serrors"
	// "github.com/scionproto/scion/go/lib/slayers"
	"gobra/lib/slayers"
	// "github.com/scionproto/scion/go/lib/slayers/path"
	"gobra/lib/slayers/path"
	// "github.com/scionproto/scion/go/lib/slayers/path/empty"
	"gobra/lib/slayers/path/empty"
	// "github.com/scionproto/scion/go/lib/slayers/path/onehop"
	"gobra/lib/slayers/path/onehop"
	// "github.com/scionproto/scion/go/lib/slayers/path/scion"
	"gobra/lib/slayers/path/scion"
	// "github.com/scionproto/scion/go/lib/topology"
	"gobra/lib/topology"
	// "github.com/scionproto/scion/go/lib/underlay/conn"
	"gobra/lib/underlay/conn"
	// underlayconn "github.com/scionproto/scion/go/lib/underlay/conn"
	underlayconn "gobra/lib/underlay/conn"
	// "github.com/scionproto/scion/go/lib/util"
	"gobra/lib/util"
	// "github.com/scionproto/scion/go/pkg/router/bfd"
	"gobra/pkg/router/bfd"
	// "github.com/scionproto/scion/go/pkg/router/control"
	"gobra/pkg/router/control"

	"gobra/verifyutils"
)

const (
	// Number of packets to read in a single ReadBatch call.
	inputBatchCnt = 64

	// TODO(karampok). Investigate whether that value should be higher.  In
	// theory, PayloadLen in SCION header is 16 bits long, supporting a maximum
	// payload size of 64KB. At the moment we are limited by Ethernet size
	// usually ~1500B, but 9000B to support jumbo frames.
	bufSize = 9000

	// hopFieldDefaultExpTime is the default validity of the hop field
	// and 63 is equivalent to 6h.
	hopFieldDefaultExpTime = 63
)

// (tlino) The scion code base uses a reference implementation of this interface.
// (tlino) This reference implementation is thread-safe.
// (tlino) Thus, it is fine to use wildcard permissions
type bfdSession interface {
	pred Mem()

	requires acc(Mem(), _)
	decreases
	Run() (err error)

	requires acc(Mem(), _)
	ensures  acc(c.SendChannel(), _) && c.SendGivenPerm() == (*layers.BFD).MemWithOutSlices!<_!>;
	decreases
	Messages() (c chan<- *layers.BFD)

	pure
	requires acc(Mem(), _)
	decreases
	IsUp() bool
}

// BatchConn is a connection that supports batch reads and writes.
type BatchConn interface {
	pred Mem()

	requires token(t) && readBatch_p(t)
	preserves acc(Mem(), _)
	preserves msgs.Mem()
	preserves forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
	ensures err == nil ==> 0 < n && n <= len(msgs) && n <= len(metas)
	ensures err == nil ==> absMsgs == ToAbsMessages(msgs, n)
	ensures err == nil ==> forall i int :: { GetAbsMessagePayload(absMsgs[i]) } (0 <= i && i < n) ==> (GetAbsMessagePayload(absMsgs[i]) == (unfolding msgs.Mem() in MessageToAbsBytesBounded(&msgs[i])))
	ensures err == nil ==> token(t1) && t1 == old(get_readBatch_t1(t)) && absMsgs == old(get_readBatch_msgs(t))
	ensures err != nil ==> t1 == t && token(t1) && readBatch_p(t1) && get_readBatch_t1(t) == old(get_readBatch_t1(t)) && get_readBatch_msgs(t) == old(get_readBatch_msgs(t))
	ReadBatch(msgs underlayconn.Messages, metas []underlayconn.ReadMeta, ghost t Place) (n int, err error, ghost absMsgs seq[AbsMessage], ghost t1 Place)

	requires acc(msgs.MemSend(), 1/1000)
	requires token(t) && writeBatch_p(t, absMsgs)
	requires len(msgs) == 1
	requires absMsgs == unfolding acc(msgs.MemSend(), 1/1000) in ToAbsMessage_MemSend(&msgs[0])
	preserves acc(Mem(), _)
	ensures acc(msgs.MemSend(), 1/1000)
	ensures err == nil ==> 0 < n && n <= len(msgs)
	ensures err == nil ==> token(t1) && t1 == old(get_writeBatch_t1(t, absMsgs))
	ensures err != nil ==> t1 == t && token(t1) && writeBatch_p(t, absMsgs) && get_writeBatch_t1(t, absMsgs) == old(get_writeBatch_t1(t, absMsgs))
	decreases
	WriteBatch(msgs underlayconn.Messages, ghost t Place, ghost absMsgs AbsMessage) (n int, err error, ghost t1 Place)

	requires Mem()
	Close() error
}

// DataPlane contains a SCION Border Router's forwarding logic. It reads packets
// from multiple sockets, performs routing, and sends them to their destinations
// (after updating the path, if that is needed).
//
// XXX(lukedirtwalker): this is still in development and not feature complete.
// Currently, only the following features are supported:
//  - initializing connections; MUST be done prior to calling Run
type DataPlane struct {
	external         map[uint16]BatchConn
	linkTypes        map[uint16]topology.LinkType
	neighborIAs      map[uint16]addr.IA
	internal         BatchConn
	internalIP       net.IP
	internalNextHops map[uint16]net.Addr
	svc              *services
//	macFactory       func() hash.Hash
	bfdSessions      map[uint16]bfdSession
	localIA          addr.IA
	mtx              sync.Mutex
	running          bool
	Metrics          *Metrics
}

pred BatchConnsAcc(batchConns map[uint16]BatchConn) {
	batchConns != nil ==> acc(batchConns) &&
	forall btc BatchConn :: btc in range(batchConns) ==> btc.Mem()
}

pred AddrsAcc(addrs map[uint16]net.Addr) {
	addrs != nil ==> acc(addrs) &&
	forall add net.Addr :: add in range(addrs) ==> add.Mem()
}

pred BfdSessionsAcc(bfdSessions map[uint16]bfdSession) {
	bfdSessions != nil ==> acc(bfdSessions) &&
	forall bfd bfdSession :: bfd in range(bfdSessions) ==> bfd.Mem()
}

pred DataPlaneMutexInvariant(d *DataPlane) {
	// access to mtx field ommited
	acc(&d.external) &&
	acc(&d.linkTypes) &&
	acc(&d.neighborIAs) &&
	acc(&d.internal) &&
	acc(&d.internalIP) &&
	acc(&d.internalNextHops) &&
	acc(&d.svc) &&
	acc(&d.bfdSessions) &&
	acc(&d.localIA) &&
	acc(&d.running) &&
	acc(&d.Metrics) &&
	(d.linkTypes != nil ==> acc(d.linkTypes)) &&
	(d.neighborIAs != nil ==> acc(d.neighborIAs)) &&
	(d.svc != nil ==> (d.svc).Mem()) &&
	BfdSessionsAcc(d.bfdSessions) &&
	BatchConnsAcc(d.external) &&
	AddrsAcc(d.internalNextHops) &&
	(d.internal != nil ==> d.internal.Mem()) &&
	(d.Metrics != nil ==> d.Metrics.Mem())
}

// (tlino) start of added getters and setters for DataPlane to simplify verification
requires acc(DataPlaneMutexInvariant(d), _)
decreases
pure func (d *DataPlane) GetLocalAI() addr.IA {
	return unfolding acc(DataPlaneMutexInvariant(d), _) in d.localIA
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures res != nil ==> acc(res.Mem(), _)
decreases
func (d *DataPlane) getInternal() (res BatchConn) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	return d.internal
}

requires acc(DataPlaneMutexInvariant(d), _)
ensures res == unfolding acc(DataPlaneMutexInvariant(d), _) in d.running
decreases
pure func (d *DataPlane) isRunning() (res bool) {
	return unfolding acc(DataPlaneMutexInvariant(d), _) in d.running
}

// (tlino) We cannot prove termination of this function due to an issue in Gobra.
// (tlino) The issue occurs when we try to access a map entry within a pure function.
// (tlino) See Issue report for details: https://github.com/viperproject/gobra/issues/401
requires acc(DataPlaneMutexInvariant(d), _)
ensures res == unfolding acc(DataPlaneMutexInvariant(d), _) in (d.linkTypes)[intf]
decreases _
pure func (d *DataPlane) GetLinkType(intf uint16) (res topology.LinkType) {
	return unfolding acc(DataPlaneMutexInvariant(d), _) in (d.linkTypes)[intf]
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures res != nil ==> acc(res, _)
decreases
func (d *DataPlane) GetNeighborIAs() (res map[uint16]addr.IA) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	res = d.neighborIAs
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures ok ==> acc(add.Mem(), _)
decreases
func (d *DataPlane) GetInternalNextHop(intf uint16) (add net.Addr, ok bool) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(AddrsAcc(d.internalNextHops), _)
	add, ok = (d.internalNextHops)[intf]
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures ok ==> acc(btc.Mem(), _)
decreases
func (d *DataPlane) GetExternalBatchConn(intf uint16) (btc BatchConn, ok bool) {
    unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BatchConnsAcc(d.external), _)
    btc, ok = (d.external)[intf]
}

preserves acc(DataPlaneMutexInvariant(d), _)
ensures ok ==> acc(bfd.Mem(), _)
decreases
func (d *DataPlane) GetBfdSession(intf uint16) (bfd bfdSession, ok bool) {
    unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BfdSessionsAcc(d.bfdSessions), _)
    bfd, ok = (d.bfdSessions)[intf]
}
// (tlino) end of added getter and setter methods for DataPlane

// (tlino) added ghost method to create a *DataPlane object and its invariant
ghost
ensures DataPlaneMutexInvariant(res)
decreases
func soundDataPlaneMutexInvariant() (res *DataPlane) {
	d@ := DataPlane{}
	res = &d
	fold BfdSessionsAcc(d.bfdSessions)
	fold BatchConnsAcc(d.external)
	fold AddrsAcc(d.internalNextHops) 
	fold DataPlaneMutexInvariant(res)
}

//var (
//	alreadySet                    = serrors.New("already set")
//	cannotRoute                   = serrors.New("cannot route, dropping pkt")
//	emptyValue                    = serrors.New("empty value")
//	malformedPath                 = serrors.New("malformed path content")
//	modifyExisting                = serrors.New("modifying a running dataplane is not allowed")
//	noSVCBackend                  = serrors.New("cannot find internal IP for the SVC")
//	unsupportedPathType           = serrors.New("unsupported path type")
//	unsupportedPathTypeNextHeader = serrors.New("unsupported combination")
//	noBFDSessionFound             = serrors.New("no BFD sessions was found")
//	noBFDSessionConfigured        = serrors.New("no BFD sessions have been configured")
//	errBFDDisabled                = serrors.New("BFD is disabled")
//)

/** Globals **/
// (joao): begin alternative to final global variables defined in the previous var block
ensures isComparable(e) && e != nil
decreases
func alreadySet() (e error) { return serrors.New("already set") }

ensures isComparable(e) && e != nil
decreases
func cannotRoute() (e error) { return serrors.New("cannot route, dropping pkt") }

ensures isComparable(e) && e != nil
decreases
func emptyValue() (e error) { return serrors.New("empty value") }

ensures isComparable(e) && e != nil
decreases
func malformedPath() (e error) { return serrors.New("malformed path content") }

ensures isComparable(e) && e != nil
decreases
func modifyExisting() (e error) { return serrors.New("modifying a running dataplane is not allowed") }

ensures isComparable(e) && e != nil
decreases
func noSVCBackend() (e error) { return serrors.New("cannot find internal IP for the SVC") }

ensures isComparable(e) && e != nil
decreases
func unsupportedPathType() (e error) { return serrors.New("unsupported path type") }

ensures isComparable(e) && e != nil
decreases
func unsupportedPathTypeNextHeader() (e error) { return serrors.New("unsupported combination") }

ensures isComparable(e) && e != nil
decreases
func noBFDSessionFound() (e error) { return serrors.New("no BFD sessions was found") }

ensures isComparable(e) && e != nil
decreases
func noBFDSessionConfigured() (e error) { return serrors.New("no BFD sessions have been configured") }

ensures isComparable(e) && e != nil
decreases
func errBFDDisabled() (e error) { return serrors.New("BFD is disabled") }

// (tlino) added this error
pure
ensures isComparable(e) && e != nil
decreases _
func invalidDstAddr() (e error)
/** End of Globals **/

type scmpError struct {
	TypeCode slayers.SCMPTypeCode
	Cause    error
}

// (tlino) TODO: built in error.Error() needs to terminate
decreases _
func (e scmpError) Error() string {
	return (serrors.New("scmp", "typecode", e.TypeCode, "cause", e.Cause)).Error()
}

// (joao) Verified
// SetIA sets the local IA for the dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) SetIA(ia addr.IA) error {
	d.mtx.Lock()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if ia.IsZero() {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	if !d.localIA.IsZero() {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return alreadySet
		return alreadySet()
	}
	d.localIA = ia
	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Partially Verified
// SetKey sets the key used for MAC verification. The key provided here should
// already be derived as in scrypto.HFMacFactory.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) SetKey(key []byte) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if len(key) == 0 {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) macFactory still not supported
	// if d.macFactory != nil {
	// 	return alreadySet
	// }
	// // First check for MAC creation errors.
	// if _, err := scrypto.InitMac(key); err != nil {
	// 	return err
	// }
	// d.macFactory = func() hash.Hash {
	// 	mac, _ := scrypto.InitMac(key)
	// return mac
	// }

	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddInternalInterface sets the interface the data-plane will use to
// send/receive traffic in the local AS. This can only be called once; future
// calls will return an error. This can only be called on a not yet running
// dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
requires conn.Mem()
ensures  d.mtx.LockP()
func (d *DataPlane) AddInternalInterface(conn BatchConn, ip net.IP) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	if d.internal != nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return alreadySet
		return alreadySet()
	}
	d.internal = conn
	d.internalIP = ip
	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddExternalInterface adds the inter AS connection for the given interface ID.
// If a connection for the given ID is already set this method will return an
// error. This can only be called on a not yet running dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
requires conn.Mem()
ensures  d.mtx.LockP()
func (d *DataPlane) AddExternalInterface(ifID uint16, conn BatchConn) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code:
	// (tlino) rename exists to ex, since exists clashes with a reserved Gobra keyword
	// if _, exists := d.external[ifID]; exists {
	// 		return serrors.WithCtx(alreadySet, "ifID", ifID)
	unfold BatchConnsAcc(d.external)
	if _, ex := (d.external)[ifID]; ex {
		// (joao) no support for defer
		fold BatchConnsAcc(d.external)
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.external == nil {
		d.external = make(map[uint16]BatchConn)
	}
	// (joao) add parentheses surrounding `d.external` to make it parse
 	(d.external)[ifID] = conn
	// (joao) no support for defer
	fold BatchConnsAcc(d.external)
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddNeighborIA adds the neighboring IA for a given interface ID. If an IA for
// the given ID is already set, this method will return an error. This can only
// be called on a yet running dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddNeighborIA(ifID uint16, remote addr.IA) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) defer not supported
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if remote.IsZero() {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code (changed below):
	// (tlino) rename exists to ex, since exists clashes with a reserved Gobra keyword
	// if _, exists := d.neighborIAs[ifID]; exists {
	// 	return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	if _, ex := (d.neighborIAs)[ifID]; ex {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.neighborIAs == nil {
		d.neighborIAs = make(map[uint16]addr.IA)
	}
	// (joao) add parentheses surrounding `d.neighborIAs` to make it parse
	(d.neighborIAs)[ifID] = remote
	// (joao) Unlock explictly added, no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddLinkType adds the link type for a given interface ID. If a link type for
// the given ID is already set, this method will return an error. This can only
// be called on a not yet running dataplane.
requires DataPlaneMutexInvariant(d)
ensures DataPlaneMutexInvariant(d)
func (d *DataPlane) AddLinkType(ifID uint16, linkTo topology.LinkType) error {
	// (joao) original code (changed below):
	// (tlino) rename exists to ex, since exists clashes with a reserved Gobra keyword
	// if _, exists := d.linkTypes[ifID]; exists {
	// 	return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	unfold DataPlaneMutexInvariant(d)
	if _, ex := (d.linkTypes)[ifID]; ex {
		fold DataPlaneMutexInvariant(d)
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.linkTypes == nil {
		d.linkTypes = make(map[uint16]topology.LinkType)
	}
	// (joao) added parentheses around d.linkTypes to make it parse
	(d.linkTypes)[ifID] = linkTo
	fold DataPlaneMutexInvariant(d)
	return nil
}

// (joao) Partially Verified
// AddExternalInterfaceBFD adds the inter AS connection BFD session.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddExternalInterfaceBFD(ifID uint16, conn BatchConn,
	src, dst control.LinkEnd, cfg control.BFD) error {
	d.mtx.Lock()
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	var m bfd.Metrics
	// if d.Metrics != nil {
	//	labels := []string{
	//		"interface", /* fmt.Sprint(ifID), */ // (joao) fmt Not supported yet
	//		"isd_as", d.localIA.String(),
	//		"neighbor_isd_as", dst.IA.String(),
	//	}
	//	// (joao) without these variables, Gobra cannot parse the following code
	//	tmpMetrics1 := d.Metrics.InterfaceUp
	//	tmpMetrics2 := d.Metrics.BFDInterfaceStateChanges
	//	tmpMetrics3 := d.Metrics.BFDPacketsSent
	//	tmpMetrics4 := d.Metrics.BFDPacketsReceived
	//	m = bfd.Metrics{
	//		Up: (metrics.NewPromGauge(/*d.Metrics.InterfaceUp*/ tmpMetrics1)).With(labels...),
	//		StateChanges: (metrics.NewPromCounter(/*d.Metrics.BFDInterfaceStateChanges*/ tmpMetrics2)).With(labels...),
	//		PacketsSent: (metrics.NewPromCounter(/*d.Metrics.BFDPacketsSent*/ tmpMetrics3)).With(labels...),
	//		PacketsReceived: (metrics.NewPromCounter(/*d.Metrics.BFDPacketsReceived*/tmpMetrics4)).With(labels...),
	//	}
	//}
	s := &bfdSend{
		conn:       conn,
		// srcAddr:    src.Addr,
		// dstAddr:    dst.Addr,
		srcIA:      src.IA,
		dstIA:      dst.IA,
		ifID:       ifID,
		// macFactory: d.macFactory,
	}
	// (joao) rewrote to unfold before returning. Original code:
	// return d.addBFDController(ifID, s, cfg, m)
	// changed code:
	fold DataPlaneMutexInvariant(d)
	res := d.addBFDController(ifID, s, cfg, m)
	unfold DataPlaneMutexInvariant(d)
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return res
}

// (joao) Partially Verified
// TODO: specify `rand`
preserves DataPlaneMutexInvariant(d)
func (d *DataPlane) addBFDController(ifID uint16, s *bfdSend, cfg control.BFD,
	metrics bfd.Metrics) error {
	unfold DataPlaneMutexInvariant(d)
	if cfg.Disable {
		fold DataPlaneMutexInvariant(d)
		// return errBFDDisabled
		return errBFDDisabled()
	}
	unfold BfdSessionsAcc(d.bfdSessions)
	if d.bfdSessions == nil {
		d.bfdSessions = make(map[uint16]bfdSession)
	}

	// // Generate random discriminator. It can't be zero.
	// discInt, err := rand.Int(rand.Reader, big.NewInt(0xfffffffe))
	// if err != nil {
	// 	return err
	// }
	// disc := layers.BFDDiscriminator(uint32(discInt.Uint64()) + 1)
	// d.bfdSessions[ifID] = &bfd.Session{
	// 	Sender:                s,
	// 	DetectMult:            layers.BFDDetectMultiplier(cfg.DetectMult),
	// 	Logger:                log.New("component", "BFD"),
	// 	DesiredMinTxInterval:  cfg.DesiredMinTxInterval,
	// 	RequiredMinRxInterval: cfg.RequiredMinRxInterval,
	// 	LocalDiscriminator:    disc,
	// 	ReceiveQueueSize:      10,
	// 	Metrics:               metrics,
	// }
	fold BfdSessionsAcc(d.bfdSessions)
	fold DataPlaneMutexInvariant(d)
	return nil
}

// (tlino) Verified
// AddSvc adds the address for the given service. This can be called multiple
// times for the same service, with the address added to the list of addresses
// that provide the service.
requires d.mtx.LockP() && acc(a.Mem(), _)
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddSvc(svc addr.HostSVC, a *net.UDPAddr) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// defer d.mtx.Unlock()
	if a == nil {
		// return emptyValue
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return emptyValue()
	}
	if d.svc == nil {
		d.svc = newServices()
	}
	d.svc.AddSvc(svc, a)
	if d.Metrics != nil {
		labels := serviceMetricLabels(d.localIA, svc)
		unfold d.Metrics.Mem()
		// (tlino) use explicit cast to float64, since gobra cannot cast the
		// (tlino) integer argument by default
		// d.Metrics.ServiceInstanceChanges.With(labels).Add(1)
		// d.Metrics.ServiceInstanceCount.With(labels).Add(1)
		(d.Metrics.ServiceInstanceChanges.With(labels)).Add(float64(1))
		(d.Metrics.ServiceInstanceCount.With(labels)).Add(float64(1))
		fold d.Metrics.Mem()
	}
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (tlino) Verified
// DelSvc deletes the address for the given service.
requires d.mtx.LockP() && acc(a.Mem(), _)
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) DelSvc(svc addr.HostSVC, a *net.UDPAddr) error {
	d.mtx.Lock()
	// defer d.mtx.Unlock()
	if a == nil {
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	unfold DataPlaneMutexInvariant!<d!>()
	if d.svc == nil {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return nil
	}
	d.svc.DelSvc(svc, a)
	if d.Metrics != nil {
		labels := serviceMetricLabels(d.localIA, svc)
		unfold d.Metrics.Mem()
		// d.Metrics.ServiceInstanceChanges.With(labels).Add(1)
		// d.Metrics.ServiceInstanceCount.With(labels).Add(-1)
		(d.Metrics.ServiceInstanceChanges.With(labels)).Add(float64(1))
		(d.Metrics.ServiceInstanceCount.With(labels)).Add(float64(-1))
		fold d.Metrics.Mem()
	}
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddNextHop sets the next hop address for the given interface ID. If the
// interface ID already has an address associated this operation fails. This can
// only be called on a not yet running dataplane.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
requires a.Mem()
ensures  d.mtx.LockP()
func (d *DataPlane) AddNextHop(ifID uint16, a net.Addr) error {
	d.mtx.Lock()
	// (joao) defer not supported
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}
	if a == nil {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code (changed below):
	// (tlino) rename exists to ex, since exists clashes with a reserved Gobra keyword
	// if _, exists := d.internalNextHops[ifID]; exists {
	//	 return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	unfold AddrsAcc(d.internalNextHops)
	if _, ex := (d.internalNextHops)[ifID]; ex {
		// (joao) Unlock explictly added, no support for defer
		fold AddrsAcc(d.internalNextHops)
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.internalNextHops == nil {
		d.internalNextHops = make(map[uint16]net.Addr)
	}
	// d.internalNextHops[ifID] = a
	(d.internalNextHops)[ifID] = a
	// (joao) Unlock explictly added, no support for defer
	fold AddrsAcc(d.internalNextHops)
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) WIP
// AddNextHopBFD adds the BFD session for the next hop address.
// If the remote ifID belongs to an existing address, the existing
// BFD session will be re-used.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures  d.mtx.LockP()
func (d *DataPlane) AddNextHopBFD(ifID uint16, src, dst *net.UDPAddr, cfg control.BFD,
	sibling string) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}

	if dst == nil {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}

	assume false
	// (joao) the following code is still not supported
	/*
	for k, v := range d.internalNextHops {
		if v.String() == dst.String() {
			if c, ok := d.bfdSessions[k]; ok {
				d.bfdSessions[ifID] = c
				return nil
			}
		}
	}
	*/
	var m bfd.Metrics
	if d.Metrics != nil {
		labels := []string{"isd_as", d.localIA.String(), "sibling", sibling}
		tmpMetrics1 := d.Metrics.SiblingReachable
		tmpMetrics2 := d.Metrics.SiblingBFDStateChanges
		tmpMetrics3 := d.Metrics.SiblingBFDPacketsSent
		tmpMetrics4 := d.Metrics.SiblingBFDPacketsReceived
		m = bfd.Metrics{
			Up: (metrics.NewPromGauge(/*d.Metrics.SiblingReachable*/ tmpMetrics1)).With(labels...),
			StateChanges: (metrics.NewPromCounter(/*d.Metrics.SiblingBFDStateChanges*/ tmpMetrics2)).With(labels...),
			PacketsSent: (metrics.NewPromCounter(/*d.Metrics.SiblingBFDPacketsSent*/ tmpMetrics3)).With(labels...),
			PacketsReceived: (metrics.NewPromCounter(/*d.Metrics.SiblingBFDPacketsReceived*/ tmpMetrics4)).With(labels...),
		}
	}
	s := &bfdSend{
		conn:       d.internal,
		srcAddr:    src,
		dstAddr:    dst,
		srcIA:      d.localIA,
		dstIA:      d.localIA,
		ifID:       0,
		// macFactory: d.macFactory,
	}
	return d.addBFDController(ifID, s, cfg, m)
}

// (tlino) Verified
// Run starts running the dataplane. Note that configuration is not possible
// after calling this method.
requires d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
func (d *DataPlane) Run() error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	d.running = true
	fold DataPlaneMutexInvariant(d)

	// (tlino) When the border router is running, then it requires that d.Metrics, d.svc, and d.internal are not nil.
	// (tlino) At the moment there is no way to encode this in the precondition of the method, since we cannot
	// (tlino) unfold DataPlaneMutexInvariant!<d!> without aqcuiring a d.mtx.
	assume unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil && d.internal != nil

	d.initMetrics()

	// (joao) At this point, there used to be a closure definition, saved in a variable called "read"
	// (tlino) The closure is replaced by the function RunReadClosure

	// (tlino) range, closures, and the log package are not supported yet, adapted code is below
	// for k, v := range d.bfdSessions {
	// 	go func(ifID uint16, c bfdSession) {
	// 		defer log.HandlePanic()
	// 		if err := c.Run(); err != nil && err != bfd.AlreadyRunning {
	// 			log.Error("BFD session failed to start", "ifID", ifID, "err", err)
	// 		}
	// 	}(k, v)
	// }

	mapKeyUpperBound := 65536

	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		key := uint16(k)
		bfdSess, found := d.GetBfdSession(key)
		if found {
			// (tlino) Due to a problem in Gobra we need to outline the Run() call to a separate method
			// (tlino) Issue: https://github.com/viperproject/gobra/issues/383
			go bfdLauncher(bfdSess)
		}
	}
	// (tlino) range, closures, and the log package are not supported yet, adapted code is below
	// for ifID, v := range d.external {
	// 	go func(i uint16, c BatchConn) {
	// 		defer log.HandlePanic()
	// 		read(i, c)
	// 	}(ifID, v)
	// }
	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		key := uint16(k)
		batchConn, found := d.GetExternalBatchConn(key)
		if found {
			go RunReadClosure(key, batchConn, d)
		}
	}
	
	// (tlino) log.HandlePanic() not supported, adaped code is below
	// go func(c BatchConn) {
	// 	defer log.HandlePanic()
	// 	read(0, c)
	// }(d.internal)
	unfold acc(DataPlaneMutexInvariant(d), _)
	go RunReadClosure(0, d.internal, d)
	
 	// (joao) This unlock here is problematic: it gives back access to the lock invariant, and thus, it should not
	//        be able to check the value of d.running. Instead, every thread running the closure should have a wildcard permission to
	//        the lock invariant.
	// d.mtx.Unlock()

	// (tlino) use getter
	// for d.running {
	invariant acc(DataPlaneMutexInvariant(d), _)
	for d.isRunning() {
		time.Sleep(time.Second)
	}
	return nil
}

// (tlino) Verified
// (tlino) added helper function
// (tlino) Due to a problem in Gobra we need this helper function to launch the BFD sessions
// (tlino) Issue: https://github.com/viperproject/gobra/issues/383
requires acc(bfdSess.Mem(), _)
func bfdLauncher(bfdSess bfdSession) {
	bfdSess.Run()
}

// (tlino) Verified
// (joao) Closure extracted from the body of the Run function
requires acc(rd.Mem(), _)
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
requires ingressID >= 0
func RunReadClosure(ingressID uint16, rd BatchConn, d *DataPlane) {
	// (tlino) outlined code to separate function
	msgs, metas := initReadClosureBuffer()

	// (tlino) Here, we initialize the state and token for the IO spec
	// (tlino) Thus, we need to inhale these predicates
	ghost var currentPlace Place
	ghost var state mset[Fact]
	inhale token(currentPlace) && P(currentPlace, state)

	// (tlino) use pointer
	// var scmpErr scmpError
	scmpErr := &scmpError{}
	spkt := slayers.SCION{}
	buffer := gopacket.NewSerializeBuffer()
	origPacket := make([]byte, bufSize)

	// (tlino) change structure of loop
	// for d.running {

	invariant forall j int :: 0 <= j && j < len(metas) ==> (&metas[j]).Mem()
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
	invariant acc(rd.Mem(), _)
	invariant msgs.Mem()
	invariant acc(scmpErr)
	invariant isZeroSCION(spkt)
	invariant buffer.Mem()
	invariant forall j int :: 0 <= j && j < len(origPacket) ==> acc(&origPacket[j])
	invariant len(origPacket) == bufSize
	invariant token(currentPlace) && P(currentPlace, state)
	for d.isRunning() {
		unfold P(currentPlace, state)
		unfold P_readBatch(currentPlace, state)
		pkts, err, absMessages, t1 := rd.ReadBatch(msgs, metas, currentPlace)
		ghost currentPlace = t1

		// (tlino) continue not supported by gobra
		// adapted code is below
		// if err != nil {
		// 	log.Debug("Failed to read batch", "err", err)
		// 	// error metric
		// 	continue
		// }
		// if pkts == 0 {
		// 	continue
		// }

		if err != nil {
			// (tlino) log not supported yet
			// log.Debug("Failed to read batch", "err", err)
			// error metric
			fold P_readBatch(currentPlace, state)
			fold P(currentPlace, state)
			assert P(currentPlace, state)
		} else if pkts > 0 {
			assert absMessages == ToAbsMessages(msgs, pkts)
			ghost state = state union ToMset(absMessages)
			assert forall i int :: 0 <= i && i < pkts ==> mset[Fact]{inFact(absMessages[i])} subset state
			// (tlino) outlined code to separate function
			currentPlace, state = processBatch(ingressID, rd, d, msgs, metas, pkts, origPacket, scmpErr, buffer, spkt, currentPlace, state, absMessages)
			assert P(currentPlace, state)

			// (tlino) outlined code to separate function
			resetReadClosureBuffers(msgs, pkts)
		}
	}
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
ensures msgs.Mem()
ensures forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
decreases
func initReadClosureBuffer() (msgs underlayconn.Messages, metas []conn.ReadMeta) {
	msgs := conn.NewReadMessages(inputBatchCnt)
	unfold msgs.MemPartiallyInitialized()

	// (tlino) range not supported by Gobra
	// for _, msg := range msgs {
	// 		msg.Buffers[0] = make([]byte, bufSize)
	// }

	invariant 0 <= i && i <= len(msgs)
	invariant forall j int :: 0 <= j && j < i ==> (&msgs[j]).Mem()
	invariant forall j int :: i <= j && j < len(msgs) ==> (&msgs[j]).MemPartiallyInitialized()
	decreases len(msgs) - i
	for i := 0; i < len(msgs); i++ {
		unfold (&msgs[i]).MemPartiallyInitialized()
		(msgs[i].Buffers)[0] = make([]byte, bufSize)
		fold (&msgs[i]).Mem()
	}
	fold msgs.Mem()

	metas := make([]conn.ReadMeta, inputBatchCnt)
	// (tlino) added loop to initialize metas
	ghost
	invariant 0 <= i && i <= len(metas)
	invariant forall j int :: i <= j && j < len(metas) ==> acc(&metas[j]) && metas[j].Src == nil && metas[j].Local == nil
	invariant forall j int :: 0 <= j && j < i ==> (&metas[j]).Mem()
	decreases len(metas) - i
	for i := 0; i < len(metas); i++ {
		fold (&metas[i]).Mem()
	}
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
// (tlino) We cannot prove termination of this method, since processMessage might not terminate
requires token(t) && P(t, s)
requires msgs.Mem()
requires 0 <= pkts && pkts <= len(msgs) && pkts <= len(metas)
requires absMsgs == ToAbsMessages(msgs, pkts)
requires forall i int :: 0 <= i && i < pkts ==> inFact(absMsgs[i]) in s
requires forall i int :: { GetAbsMessagePayload(absMsgs[i]) } (0 <= i && i < pkts) ==> (GetAbsMessagePayload(absMsgs[i]) == (unfolding msgs.Mem() in MessageToAbsBytesBounded(&msgs[i])))
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
requires ingressID >= 0
requires acc(rd.Mem(), _)
requires isZeroSCION(spkt)
preserves forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
preserves forall i int :: 0 <= i && i < len(origPacket) ==> acc(&origPacket[i])
preserves cap(origPacket) == bufSize && len(origPacket) == bufSize
preserves acc(scmpErr)
preserves buffer.Mem()
ensures msgs.Mem()
ensures token(t1) && P(t1, s1)
func processBatch(ingressID uint16, rd BatchConn, d *DataPlane, msgs underlayconn.Messages, metas []underlayconn.ReadMeta, pkts int, 
	origPacket []byte, scmpErr *scmpError, buffer gopacket.SerializeBuffer, spkt slayers.SCION, ghost t Place, ghost s mset[Fact], ghost absMsgs seq[AbsMessage]) (ghost t1 Place, ghost s1 mset[Fact]) {
	unfold msgs.Mem()

	ghost var currentPlace Place = t
	ghost var currentState mset[Fact] = s

	// (tlino) range not supported by Gobra
	// for _, p := range msgs[:pkts] {
	invariant 0 <= i && i <= pkts
	invariant 0 <= pkts && pkts <= len(msgs)
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
	invariant acc(rd.Mem(), _)
	invariant forall j int :: 0 <= j && j < len(msgs) ==> (&msgs[j]).Mem()
	invariant forall j int :: 0 <= j && j < len(origPacket) ==> acc(&origPacket[j])
	invariant cap(origPacket) == bufSize && len(origPacket) == bufSize
	invariant acc(scmpErr)
	invariant buffer.Mem()
	invariant isZeroSCION(spkt)
	invariant token(currentPlace) && P(currentPlace, currentState)
	invariant forall j int :: i <= j && j < pkts ==> inFact(absMsgs[j]) in currentState
	invariant forall j int :: { GetAbsMessagePayload(absMsgs[j]) } (i <= j && j < pkts) ==> (GetAbsMessagePayload(absMsgs[j]) == MessageToAbsBytesBounded(&msgs[j]))
	for i := 0; i < pkts; i++ {
		currentPlace, currentState = processMessage(ingressID, rd, d, &msgs[i] , origPacket, spkt, buffer, scmpErr, absMsgs[i], currentPlace, currentState)
  	}
	fold msgs.Mem()
	return currentPlace, currentState
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
// (tlino) We cannot prove termination of this method, since d.processPkt might not terminate
requires token(t) && P(t, s)
requires inFact(absMsg) in s
requires p.Mem()
requires GetAbsMessagePayload(absMsg) == MessageToAbsBytesBounded(p)
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil && d.svc != nil
requires ingressID >= 0
preserves acc(rd.Mem(), _)
preserves forall j int :: 0 <= j && j < len(origPacket) ==> acc(&origPacket[j])
preserves cap(origPacket) == bufSize && len(origPacket) == bufSize
preserves isZeroSCION(spkt)
preserves acc(scmpErr)
preserves buffer.Mem()
ensures p.Mem()
ensures token(t1) && P(t1, s1)
ensures s subset s1
func processMessage(ingressID uint16, rd BatchConn, d *DataPlane, p *ipv4.Message, origPacket []byte, spkt slayers.SCION, 
	buffer gopacket.SerializeBuffer, scmpErr *scmpError, ghost absMsg AbsMessage, ghost t Place, ghost s mset[Fact]) (ghost t1 Place, ghost s1 mset[Fact]) {
	unfold p.Mem()
	assert forall j int :: 0 <= j && j < p.N ==> &origPacket[j] == &(origPacket[:p.N])[j]
	// (tlino) use local originPacket subslice
	// origPacket = origPacket[:p.N]
	localOrigPacket := origPacket[:p.N]

	// TODO(karampok). Use meta for sanity checks. // (tlino) original scion comment
	
	// (tlino) added parentheses to make it parse
	// p.Buffers[0] = p.Buffers[0][:p.N]
	(p.Buffers)[0] = ((p.Buffers)[0])[:p.N]
	// (tlino) use gobra's copy function
	// copy(origPacket[:p.N], p.Buffers[0])
	verifyutils.OutlineMemorySafeCopy(localOrigPacket, (p.Buffers)[0])
	rawPkt := (p.Buffers)[0]
	ghost absRawPkt := ToAbsBytes(rawPkt)
	assert absRawPkt == GetAbsMessagePayload(absMsg)

	// input metric
	// (tlino) use getters to avoid unfolding
	// inputLabels := interfaceToMetricLabels(result.EgressID, d.localIA, d.neighborIAs)
	inputLabels := interfaceToMetricLabels(ingressID, d.GetLocalAI(), d.GetNeighborIAs())
	updateInputMetrics(d, inputLabels, p.N)

	fold verifyutils.BytesAcc((p.Buffers)[0])
	fold verifyutils.BytesAcc(localOrigPacket)

	// (tlino) use lemma to relate BytesAcc and quantified AbsBytes abstraction functions
	ghost _ := relateByteAccess(rawPkt, absRawPkt) 
	assert ToAbsBytes2(rawPkt) == GetAbsMessagePayload(absMsg)

	// (tlino) use local variables
	// result, err := d.processPkt(ingressID, p.Buffers[0], p.Addr, spkt, origPacket,
	//	buffer)
	var foo AbsIA
	result, err, absPR, t2, s2 := d.processPkt(ingressID, rawPkt, p.Addr, spkt, localOrigPacket,
		buffer, absMsg, foo, t, s)

	assert result.Mem()

	// (tlino) we use this ghost variable to know which branch was taken.
	// (tlino) this is needed to apply the correct magic wand.
	ghost var switchCase uint8
	ghost var errorIsNil uint8 = 1
	ghost var errorIsSCMP uint8 = 2
	// (tlino) added this variable to make magic wand work
	localAddr := p.Addr

	switch {
	case err == nil:
		assert result.Mem() --* verifyutils.BytesAcc(rawPkt)
		ghost switchCase = errorIsNil
	case errors.As(err, scmpErr):
		// (tlino) Since this is an SCMP packet, we know that result is not empty (i.e. isEmptyPR(result) == false).
		// (Each SCMP packet that is returned by processPkt contains an OutPkt field that is not nil)
		// (tlino) At this moment we have to use here an assume,
		// (tlino) since in the processPkt method we cannot use a postconditon like: errors.As(err, scmpErr) ==> !isEmptyPR(result)
		assume isEmptyPR(result) == false
		if !scmpErr.TypeCode.InfoMsg() {
			// (tlino) log not yet supported
			// log.Debug("SCMP", "err", scmpErr, "dst_addr", p.Addr)
		}
		// SCMP go back the way they came. // (tlino) original scion comemnt
		// (tlino) move update of result to updateProcessResult method
		// (tlino) the update gives back a magic wand, since p.Addr.Mem() musst be given back to p
		// result.OutAddr = p.Addr
		// result.OutConn = rd
		result = result.updateProcessResult(localAddr, rd)
		assert result.Mem() --* acc(localAddr.Mem(), 1/1000)
		ghost switchCase = errorIsSCMP
	default:
		// (tlino) log not yet supported
		// log.Debug("Error processing packet", "err", err)

		// (tlino) outline metric update to function
		// d.Metrics.DroppedPacketsTotal.With(inputLabels).Inc()
		updateDroppedPackets(d, inputLabels)

		// (tlino) This method used to be part of a loop. We replace continue by return.
		// continue
		unfold verifyutils.BytesAcc(localOrigPacket)
		unfold verifyutils.BytesAcc((p.Buffers)[0])
		fold p.Mem()
		return t2, s2
	}
	assert switchCase == errorIsNil || switchCase == errorIsSCMP

	// (tlino) outlined code block to its own method
	t3, s3 := processMessageHelper(d, result, absPR, t2, s2)

	ghost if switchCase == errorIsNil {
		apply result.Mem() --* verifyutils.BytesAcc(rawPkt)
	} else if switchCase == errorIsSCMP {
		apply result.Mem() --* acc(localAddr.Mem(), 1/1000)
	}

	unfold verifyutils.BytesAcc(localOrigPacket)
	unfold verifyutils.BytesAcc((p.Buffers)[0])
	fold p.Mem()
	return t3, s3
}

// (tlino) Verified
// (tlino) added helper function
requires pr.Mem()
requires acc(addr.Mem(), 1/1000)
requires acc(rd.Mem(), _)
ensures res.Mem()
ensures res.Mem() --* acc(addr.Mem(), 1/1000)
decreases
func (pr processResult) updateProcessResult(addr net.Addr, rd BatchConn) (res processResult) {
	unfold pr.Mem()
	pr.AddrSrc = AddrFromMessage
	pr.OutAddr = addr
	pr.OutConn = rd
	fold pr.Mem()
	res = pr

	package res.Mem() --* acc(addr.Mem(), 1/1000) {
		unfold pr.Mem()
	}
}

// (tlino) Verified
// (tlino) added helper function to simplify verification
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
preserves acc(inputLabels, _)
decreases
func updateInputMetrics(d *DataPlane, inputLabels prometheus.Labels, totalInputBytes int) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	// (tlino) use getter to avoid unfolding d.Metrics.Mem()
	// d.Metrics.InputPacketsTotal.With(inputLabels).Inc()
	// d.Metrics.InputBytesTotal.With(inputLabels).Add(float64(p.N))
	((d.Metrics.GetInputPacketsTotal()).With(inputLabels)).Inc()
	((d.Metrics.GetInputBytesTotal()).With(inputLabels)).Add(float64(totalInputBytes))
}

// (tlino) Verified
// (tlino) added helper function to simplify verification
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
preserves acc(inputLabels, _)
decreases
func updateDroppedPackets(d *DataPlane, inputLabels prometheus.Labels) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	((d.Metrics.GetDroppedPacketsTotal()).With(inputLabels)).Inc()
}

// (tlino) Verified
// (tlino) added helper function to simplify verification
requires token(t) && P(t, s)
requires !isEmptyPR(result) ==> processedPktFact(absPR) in s
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
preserves result.Mem()
ensures token(t1) && P(t1, s1)
ensures s subset s1
decreases
func processMessageHelper(d *DataPlane, result processResult, ghost absPR AbsProcessResult, ghost t Place, ghost s mset[Fact]) (ghost t1 Place, ghost s1 mset[Fact]) {
	if result.OutConn == nil { // e.g. BFD case no message is forwarded
		// (tlino) This helper function used to be a part of a loop,
		// (tlino) since the continue isn't supported we use a return statement
		// continue
		assert P(t, s)
		return t, s
	}
	assert isEmptyPR(result) == false
	// (tlino) original code, adapted code is below
	// _, err = result.OutConn.WriteBatch(underlayconn.Messages([]ipv4.Message{{
	// 	Buffers: [][]byte{result.OutPkt},
	// 	Addr:    result.OutAddr,
	// }}))

	// (tlino) use ghost function to get access to result.OutConn, result.OutAddr, and result.OutPkt
	ghost resultCase := result.getOutAddrAndOutPkt()

	pld := result.OutPkt
	address := result.OutAddr
	
	ghost if resultCase == MsgWithDataPlaneAdd {
		assert (result.OutPkt != nil ==> acc(verifyutils.BytesAcc(result.OutPkt), 1/1000)) --* result.Mem()
	} else if resultCase == MsgWithMessageAdd {
		assert ((result.OutAddr != nil ==> acc(result.OutAddr.Mem(), 1/1000)) && (result.OutPkt != nil ==> acc(verifyutils.BytesAcc(result.OutPkt), 1/1000))) --* result.Mem()
	} else if resultCase == MsgWithBytePacketAdd {
		assert ((result.OutAddr != nil ==> acc(result.OutAddr.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(result.OutPkt), 1/1000)) --* result.Mem()
	} else {
		assert (result.OutPkt != nil ==> acc(verifyutils.BytesAcc(result.OutPkt), 1/1000)) --* result.Mem()
	}

	// (tlino) moved message creation to outlined function
	messages := createMessages(pld, address, resultCase)

	// (tlino) apply internal packPkt event
	unfold P(t, s)
	unfold P_packPkt(t, s)
	ghost absMessages := unfolding acc(messages.MemSend(), 1/1000) in ToAbsMessage_MemSend(&messages[0])
	assert packPkt_p(t, absPR, absMessages)
	ghost s2 := s union mset[Fact]{outFact(absMessages)}
	ghost t2 := get_packPkt_t1(t, absPR, absMessages)
	ghost packPkt_f(t, absPR, absMessages)
	assert token(t2)
	assert P(t2, s2)

	unfold P(t2, s2)
	unfold P_writeBatch(t2, s2)
	assert outFact(absMessages) in s2
	_, err, t1 := result.OutConn.WriteBatch(messages, t2, absMessages)

	// (tlino) ghost code to get back access to result.Mem()
	ghost if resultCase == MsgWithDataPlaneAdd {
		assert acc(messages.MemSend(), 1/1000) --* (pld != nil ==> acc(verifyutils.BytesAcc(pld), 1/1000))
		apply acc(messages.MemSend(), 1/1000) --* (pld != nil ==> acc(verifyutils.BytesAcc(pld), 1/1000))
		apply (result.OutPkt != nil ==> acc(verifyutils.BytesAcc(result.OutPkt), 1/1000)) --* result.Mem()
	} else if resultCase == MsgWithMessageAdd {
		assert acc(messages.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && (pld != nil ==> acc(verifyutils.BytesAcc(pld), 1/1000)))
		apply acc(messages.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && (pld != nil ==> acc(verifyutils.BytesAcc(pld), 1/1000)))
		apply ((result.OutAddr != nil ==> acc(result.OutAddr.Mem(), 1/1000)) && (result.OutPkt != nil ==> acc(verifyutils.BytesAcc(result.OutPkt), 1/1000))) --* result.Mem()
	} else if resultCase == MsgWithBytePacketAdd {
		assert acc(messages.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(pld), 1/1000))
		apply acc(messages.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(pld), 1/1000))
		apply ((result.OutAddr != nil ==> acc(result.OutAddr.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(result.OutPkt), 1/1000)) --* result.Mem()
	} else {
		assert acc(messages.MemSend(), 1/1000) --* (pld != nil ==> acc(verifyutils.BytesAcc(pld), 1/1000))
		apply acc(messages.MemSend(), 1/1000) --* (pld != nil ==> acc(verifyutils.BytesAcc(pld), 1/1000))
		apply (result.OutPkt != nil ==> acc(verifyutils.BytesAcc(result.OutPkt), 1/1000)) --* result.Mem()
	}
	
	assert result.Mem()
	if err != nil {
		// (tlino) log not supported yet
		// log.Debug("Error writing packet", "err", err)
		// error metric // (tlino) original scion comment
		// (tlino) This method used to be part of a loop. We replace continue by return.
		// continue
		fold P_writeBatch(t1, s2)
		fold P(t1, s2)
		assert P(t1, s2)
		return t1, s2
	}

	ghost s1 = s2

	// ok metric
	// (tlino) use getters to simplify verification
	// outputLabels := interfaceToMetricLabels(result.EgressID, d.localIA, d.neighborIAs)
	// d.Metrics.OutputPacketsTotal.With(outputLabels).Inc()
	// d.Metrics.OutputBytesTotal.With(outputLabels).Add(float64(len(result.OutPkt)))
	outputLabels := interfaceToMetricLabels(result.GetEgressID(), d.GetLocalAI(), d.GetNeighborIAs())
	unfold acc(DataPlaneMutexInvariant(d), _)
	((d.Metrics.GetOutputPacketsTotal()).With(outputLabels)).Inc()
	((d.Metrics.GetOutputBytesTotal()).With(outputLabels)).Add(float64(result.GetOutPktLen()))
	assert P(t1, s1)
	return t1, s1
}

// (tlino) added type
type MessageCase uint8

// (tlino) The messageCase represents the four different cases we can have.
// (tlino) case 1: address comes from the dataplane, thus it has wildcard permission. The payload may be nil.
// (tlino) case 2: address comes from an ipv4.Message, thus it has a concrete permission amount of 1/1000. The payload may be nil.
// (tlino) case 3: address is aliased with payload. Both have a permission amount of 1/1000. This is fine since Messages with the MemSend() predicate
// (tlino) are read-only.
// (tlino) case 4: address is nil. In this case we can only deduce that payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000) holds.
const (
	MsgWithDataPlaneAdd MessageCase = 1
	MsgWithMessageAdd MessageCase = 2
	MsgWithBytePacketAdd MessageCase = 3
	MsgWithNoAdd MessageCase = 4
)

// (tlino) Verified
// (tlino) added helper function to simplify verification
requires 1 <= msgCase && msgCase <= 4
requires msgCase == MsgWithDataPlaneAdd ==> (address != nil ==> acc(address.Mem(), _)) && (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000))
requires msgCase == MsgWithMessageAdd ==> (address != nil ==> acc(address.Mem(), 1/1000)) && (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000))
requires msgCase == MsgWithBytePacketAdd ==> (address != nil ==> acc(address.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(payload), 1/1000)
requires msgCase == MsgWithNoAdd ==> address == nil && (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000))
ensures acc(msgs.MemSend(), 1/1000)
ensures len(msgs) == 1
ensures msgCase == MsgWithDataPlaneAdd ==> acc(msgs.MemSend(), 1/1000) --* (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000))
ensures msgCase == MsgWithMessageAdd ==> acc(msgs.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000)))
ensures msgCase == MsgWithBytePacketAdd ==> acc(msgs.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(payload), 1/1000))
ensures msgCase == MsgWithNoAdd ==> acc(msgs.MemSend(), 1/1000) --* (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000))
decreases
func createMessages(payload []byte, address net.Addr, ghost msgCase MessageCase) (msgs underlayconn.Messages) {
	msgs := make(underlayconn.Messages, 1)
	msgs[0].Buffers = make([][]byte, 1)
	(msgs[0].Buffers)[0] = payload
	if payload != nil {
		unfold acc(verifyutils.BytesAcc(payload), 1/1000)
	}
	msgs[0].Addr = address

	ghost if msgCase == MsgWithDataPlaneAdd {
		msgs[0].WildcardAddressAcc = true
		fold acc((&msgs[0]).MemSend(), 1/1000)
		fold acc(msgs.MemSend(), 1/1000)
		package acc(msgs.MemSend(), 1/1000) --* (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000)) {
			unfold acc(msgs.MemSend(), 1/1000)
			unfold acc((&msgs[0]).MemSend(), 1/1000)
			fold acc(verifyutils.BytesAcc(payload), 1/1000)
		}
	} else {
		msgs[0].WildcardAddressAcc = false
		fold acc((&msgs[0]).MemSend(), 1/1000)
		fold acc(msgs.MemSend(), 1/1000)
		switch msgCase {
			case MsgWithMessageAdd:
				package acc(msgs.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000))) {
					unfold acc(msgs.MemSend(), 1/1000)
					unfold acc((&msgs[0]).MemSend(), 1/1000)
					fold acc(verifyutils.BytesAcc(payload), 1/1000)
				}
			case MsgWithBytePacketAdd:
				package acc(msgs.MemSend(), 1/1000) --* ((address != nil ==> acc(address.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(payload), 1/1000)) {
					unfold acc(msgs.MemSend(), 1/1000)
					unfold acc((&msgs[0]).MemSend(), 1/1000)
					fold acc(verifyutils.BytesAcc(payload), 1/1000)
				}
			case MsgWithNoAdd:
				package acc(msgs.MemSend(), 1/1000) --* (payload != nil ==> acc(verifyutils.BytesAcc(payload), 1/1000)) {
					unfold acc(msgs.MemSend(), 1/1000)
					unfold acc((&msgs[0]).MemSend(), 1/1000)
					fold acc(verifyutils.BytesAcc(payload), 1/1000)
				}
		}
	}
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
requires 0 <= pkts && pkts <= len(msgs)
preserves msgs.Mem()
decreases
func resetReadClosureBuffers(msgs underlayconn.Messages, pkts int) {
	unfold msgs.Mem()

	// Reset buffers to original capacity.
	// (tlino) range no supported by Gobra
	// for _, p := range msgs[:pkts] {
	// 	p.Buffers[0] = p.Buffers[0][:bufSize]
	// }

	invariant 0 <= i && i <= pkts
	invariant forall j int :: 0 <= j && j < len(msgs) ==> (&msgs[j]).Mem()
	decreases pkts - i
	for i := 0; i < pkts; i++ {
		unfold (&msgs[i]).Mem()
		(msgs[i].Buffers)[0] = ((msgs[i].Buffers)[0])[:bufSize]
		fold (&msgs[i]).Mem()
	}
	fold msgs.Mem()
}

// (tlino) Verified
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
decreases
func (d *DataPlane) initMetrics() {
	labels := interfaceToMetricLabels(0, d.GetLocalAI(), d.GetNeighborIAs())
	unfold acc(DataPlaneMutexInvariant(d), _)
	// (tlino) use getters to simplify verification, need to use float64 cast since gobra
	// (tlino) cannot cast a numeric argument to float64
	// d.Metrics.InputBytesTotal.With(labels).Add(0)
	// d.Metrics.InputPacketsTotal.With(labels).Add(0)
	// d.Metrics.OutputBytesTotal.With(labels).Add(0)
	// d.Metrics.OutputPacketsTotal.With(labels).Add(0)
	// d.Metrics.DroppedPacketsTotal.With(labels).Add(0)
	((d.Metrics.GetInputBytesTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetInputPacketsTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetOutputBytesTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetOutputPacketsTotal()).With(labels)).Add(float64(0))
	((d.Metrics.GetDroppedPacketsTotal()).With(labels)).Add(float64(0))

	// (tlino) range is not supported yet by gobra, iterate over all keys instead
	// (tlino) adapted code is below
	// for id := range d.neighborIAs {
	// 	if _, notOwned := d.internalNextHops[id]; notOwned {
	// 		continue
	// 	}
	// 	labels = interfaceToMetricLabels(id, d.localIA, d.neighborIAs)
	// 	d.Metrics.InputBytesTotal.With(labels).Add(0)
	// 	d.Metrics.InputPacketsTotal.With(labels).Add(0)
	// 	d.Metrics.OutputBytesTotal.With(labels).Add(0)
	// 	d.Metrics.OutputPacketsTotal.With(labels).Add(0)
	// 	d.Metrics.DroppedPacketsTotal.With(labels).Add(0)
	// }

	mapKeyUpperBound := 65536

	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant unfolding acc(DataPlaneMutexInvariant(d), _) in d.Metrics != nil
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		unfold acc(DataPlaneMutexInvariant(d), _)
		key := uint16(k)
		_ , found := (d.neighborIAs)[key]
		if found {
			if _, notOwned := d.GetInternalNextHop(key); !notOwned {
				labels = interfaceToMetricLabels(key, d.GetLocalAI(), d.GetNeighborIAs())
				// (tlino) use getters to simplify verification, need to use float64 cast since gobra
				// (tlino) cannot cast a numeric argument to float64
				((d.Metrics.GetInputBytesTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetInputPacketsTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetOutputBytesTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetOutputPacketsTotal()).With(labels)).Add(float64(0))
				((d.Metrics.GetDroppedPacketsTotal()).With(labels)).Add(float64(0))
			}
		}
	}
}

// (tlino) added type
type AddrSource uint8

// (tlino) when a processResult is generated the address can have 3 different sources.
// we need this case distinction to correctly reasen about the permission amounts that are
// required for the OutAddr field in processResult.
// case AddrFromDataplane: the address comes from the dataplane
// case AddrFromMessage: the address comes from the address field in the ipv4.Message
// case AddrFromPacketBytes: the address is aliased with the byte field (OutPkt).
const (
	AddrFromDataplane AddrSource = 1
	AddrFromMessage AddrSource = 2
	AddrFromPacketBytes AddrSource = 3
)

// (tlino) added ghost field AddrSrc, since the OutAddr is eigher given by the router (AddrFromDataplane)
// (tlino) or it is given by the ipv4.Message (AddrFromMessage) or it is aliased to OutPkt.
// (tlino) If OutAddr is aliased to OutPkt, then we have AddrSrc != AddrFromDataplane && AddrSrc != AddrFromMessage,
// (tlino) and we cannot deduce the OutAddr.Mem() predicate directly.
type processResult struct {
	EgressID uint16
	OutConn  BatchConn
	OutAddr  net.Addr
	OutPkt   []byte
	// ghost
	AddrSrc AddrSource
}

// (tlino) This predicate only requires permission to pr.OutAddr, when pr.OutAddr comes from
// (tlino) a lookup in the Dataplane or if pr.OutAddr comes from an ipv4.Message.
// (tlino) When pr.OutAddr is aliased to pr.OutPkt then we keep only access to pr.OutPkt.
pred (pr processResult) Mem() {
	(pr.EgressID >= 0) &&
	(pr.OutConn != nil ==> acc(pr.OutConn.Mem(), _)) &&
	(pr.AddrSrc == AddrFromDataplane && pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), _)) &&
	(pr.AddrSrc == AddrFromMessage && pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) &&
	(pr.AddrSrc == AddrFromPacketBytes ==> pr.OutPkt != nil) &&
	((pr.AddrSrc != AddrFromDataplane && pr.AddrSrc != AddrFromMessage && pr.AddrSrc != AddrFromPacketBytes) ==> pr.OutAddr == nil) &&
	(pr.OutPkt != nil ==> verifyutils.BytesAcc(pr.OutPkt))
}

// (tlino) added getter and setter methods to simplify verification
pure
requires acc(pr.Mem(), _)
ensures res == unfolding acc(pr.Mem(), _) in pr.EgressID
ensures res >= 0
decreases
func (pr processResult) GetEgressID() (res uint16) {
	return unfolding acc(pr.Mem(), _) in pr.EgressID
}

pure
requires acc(pr.Mem(), _)
ensures res == unfolding acc(pr.Mem(), _) in len(pr.OutPkt)
decreases
func (pr processResult) GetOutPktLen() (res int) {
	return unfolding acc(pr.Mem(), _) in len(pr.OutPkt)
}
// (tlino) end of getters and setters

// (tlino) added helper method to get read access to OutPkt and OutAddr
// (tlino) this method is only used when OutAddr is aliased to OutPkt
ghost
requires acc(pr.Mem(), 1/1000)
requires pr.AddrSrc == AddrFromPacketBytes
ensures pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)
ensures (pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) --* acc(pr.Mem(), 1/1000)
decreases _
func (pr processResult) getOutAddr()

// (tlino) Verified
// (tlino) Helper method to get access pr.OutConn.Mem(), pr.OutAddr.Mem(), pr.OutPkt.Mem()
// (tlino) This method returns different access permissions to the OutAddr and OutPkt fields.
// (tlino) In any case the caller musst be able to get permission to pr.Mem(). Thus, magic wands are used.
// (tlino) case MsgWithDataPlaneAdd: OutAddr comes from the dataplane, thus it has wildcard permission. The OutPkt may be nil
// (tlino) case MsgWithMessageAdd: OutAddr comes from an ipv4.Message, thus it has a concrete permission amount of 1/1000. The OutPkt may be nil.
// (tlino) case MsgWithBytePacketAdd: OutAddr is aliased with OutPkt. Inorder to perform the WriteBatch operation later, we musst give a permission amount of 1/1000 to both OutAddr and OutPkt.
// (tlino) This is no problem, since WriteBatch reads only the contents of processResult.
// (tlino) case MsgWithDataPlaneAdd: OutAddr is nil. In this case we can only deduce that pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000) holds
ghost
requires pr.Mem()
requires pr.OutConn != nil
ensures acc(pr.OutConn.Mem(), _)
ensures r == MsgWithDataPlaneAdd ==> (pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), _)) && (pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) && ((pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) --* pr.Mem())
ensures r == MsgWithMessageAdd ==> (pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) && (pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) && (((pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) && (pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000))) --* pr.Mem())
ensures r == MsgWithBytePacketAdd ==> (pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000) && (((pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) --* pr.Mem())
ensures r == MsgWithNoAdd ==> pr.OutAddr == nil && (pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) && ((pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) --* pr.Mem())
ensures r == MsgWithDataPlaneAdd || r == MsgWithMessageAdd || r == MsgWithBytePacketAdd || r == MsgWithNoAdd
decreases
func (pr processResult) getOutAddrAndOutPkt() (r MessageCase) {
	if pr.AddrSrc == AddrFromDataplane {
		unfold pr.Mem()
		package (pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) --* pr.Mem() {
			fold pr.Mem()
		}
		r = MsgWithDataPlaneAdd
	} else if pr.AddrSrc == AddrFromMessage {
		unfold pr.Mem()
		package ((pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) && (pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000))) --* pr.Mem() {
			fold pr.Mem()
		}
		r = MsgWithMessageAdd
	} else if pr.AddrSrc == AddrFromPacketBytes {
		pr.getOutAddr()
		unfold acc(pr.Mem(), 1/1000)
		package ((pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) && acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) --* pr.Mem() {
			apply (pr.OutAddr != nil ==> acc(pr.OutAddr.Mem(), 1/1000)) --* acc(pr.Mem(), 1/1000)
			fold acc(pr.Mem(), 1/1000)
		}
		r = MsgWithBytePacketAdd
	} else {
		unfold pr.Mem()
		package (pr.OutPkt != nil ==> acc(verifyutils.BytesAcc(pr.OutPkt), 1/1000)) --* pr.Mem() {
			fold pr.Mem()
		}
		r = MsgWithNoAdd
	}
}

// (tlino) We cannot prove termination of this function due to an issue in Gobra.
// (tlino) The issue occurs when we try to compare arrays with nil in pure functions
// (tlino) See Issue report for details: https://github.com/viperproject/gobra/issues/402
decreases _
pure func isZeroSCION(s slayers.SCION) bool {
	return s.EmbeddedBaseLayer.Contents == nil &&
		s.EmbeddedBaseLayer.Payload == nil &&
		s.Version == 0 &&
		s.TrafficClass == 0 &&
		s.FlowID == 0 &&
		s.NextHdr == 0 &&
		s.HdrLen == 0 &&
		s.PayloadLen == 0 &&
		s.PathType == 0 &&
		s.DstAddrType == 0 &&
		s.DstAddrLen == 0 &&
		s.SrcAddrType == 0 &&
		s.SrcAddrLen == 0 &&
		s.DstIA.I == 0 &&
		s.DstIA.A == 0 &&
		s.SrcIA.I == 0 &&
		s.SrcIA.A == 0 &&
		s.RawDstAddr == nil &&
		s.RawSrcAddr  == nil &&
		s.Path == nil
}

// (tlino) Verified
// (tlino) added helper method to construct magic wand in processPkt
ghost
requires scionLayer.Mem()
requires rawPkt == scionLayer.getRawPkt()
preserves pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
decreases
func processPktHelper(pr processResult, scionLayer *slayers.SCION, rawPkt []byte) {
	ghost scionLayer.getRawPktAccWithoutPreservePath(rawPkt)
	package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {}
}

// (tlino) Verified
// (tlino) added helper method
ghost
ensures res == (pr.EgressID == 0 && pr.OutConn == nil && pr.OutAddr == nil && pr.OutPkt == nil && pr.AddrSrc == 0)
decreases
pure func isEmptyPR(pr processResult) (res bool) {
	return pr.EgressID == 0 && pr.OutConn == nil && pr.OutAddr == nil && pr.OutPkt == nil && pr.AddrSrc == 0
}

// (tlino) Verified
// (tlino) We cannot prove termination of this method, since d.processSCION() and d.processOHP() might not terminate.
// (tliio) We would also like to have a postcondition like: errors.As(err, scmpErr) ==> !isEmptyPR(result)
// (tliio) this could then be used by the caller of processPkt to imply that an SCMP error never returns an empty processResult
// (tlino) See Issue report: https://github.com/jcp19/VerifiedSCION/issues/63
requires token(t0) && P(t0, s0)
requires inFact(absMsg) in s0
requires verifyutils.BytesAcc(rawPkt)
requires ToAbsBytes2(rawPkt) == GetAbsMessagePayload(absMsg)
requires acc(DataPlaneMutexInvariant(d), _)
requires localIAFact(localIA) in s0
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires ingressID >= 0
requires isZeroSCION(s)
preserves verifyutils.BytesAcc(origPacket)
preserves cap(rawPkt) == bufSize
preserves acc(srcAddr.Mem(), 1/1000)
preserves buffer.Mem()
ensures pr.Mem()
ensures errRet == nil ==> pr.Mem() --* verifyutils.BytesAcc(rawPkt)
ensures errRet != nil ==> verifyutils.BytesAcc(rawPkt)
ensures token(t1) && P(t1, s1)
ensures s0 subset s1
ensures !isEmptyPR(pr) ==> processedPktFact(absPR) in s1
func (d *DataPlane) processPkt(ingressID uint16, rawPkt []byte, srcAddr net.Addr, s slayers.SCION,
	origPacket []byte, buffer gopacket.SerializeBuffer, ghost absMsg AbsMessage, ghost localIA AbsIA, ghost t0 Place, ghost s0 mset[Fact]) (pr processResult, errRet error, ghost absPR AbsProcessResult, ghost t1 Place, ghost s1 mset[Fact]) {
	// (joao) `s` should always have the zero value of slayers.SCION;
	// (joao) in the code, we use `s` where an *slayers.SCION is expected. In Go, this modifies `s` but in Gobra, that idiom is still not supported;
	// (joao) we use the following transformation - we check that s is always the zero value and we introduce a new shared variable `sNew` of type slayers.SCION{}
	//        that gets mutated
	sNew := &slayers.SCION{}

	df := gopacket.NilDecodeFeedback{}
	fold df.Mem()
	ghost absData := ToAbsBytes2(rawPkt)
	// (joao) Adapted to conform to changes in gopacket and sNew
	// if err := s.DecodeFromBytes(rawPkt, gopacket.NilDecodeFeedback); err != nil {
	if err := sNew.DecodeFromBytes(rawPkt, df); err != nil {
		// (tlino) original code, adapted code is below 
		// return processResult{}, err

		pr, errRet =  processResult{}, err
		ghost t1, s1 = t0, s0
		assert P(t1, s1)

		fold pr.Mem()
		return
	}
	ghost _ := relateDataToSCION(rawPkt, sNew, absData)

	// (tlino) apply internal decodePkt event
	unfold P(t0, s0)
	unfold P_decodePkt(t0, s0)
	ghost absSCION := ToAbsSCION(sNew)
	assert decodePkt_p(t0, absMsg, absSCION)
	ghost s2 := s0 union mset[Fact]{decodedPktFact(absSCION)}
	ghost t2 := get_decodePkt_t1(t0, absMsg, absSCION)
	ghost decodePkt_f(t0, absMsg, absSCION)
	assert token(t2)
	assert P(t2, s2)
	
	// (joao) already lost access to rawPkt here
	if err := buffer.Clear(); err != nil {
		// (tlino) original code, adapted code is below 
		// return processResult{}, serrors.WrapStr("Failed to clear buffer", err)

		pr, errRet = processResult{}, serrors.WrapStr("Failed to clear buffer", err)
		ghost t1, s1 = t2, s2
		assert P(t1, s1)

		fold pr.Mem()
		ghost sNew.getRawPktAccWithoutPreservePath(rawPkt)
		return
	}

	// (tlino) use sNew.getPathType() instead of s
	// switch s.PathType {
	switch sNew.getPathType() {
	case slayers.PathTypeEmpty:
		// (tlino) use sNew instead of s and use getters
		// if s.NextHdr == common.L4BFD {
		if sNew.getNextHdr() == common.L4BFD {
			// (tlino) original code, adapted code is below
			// return processResult{}, d.processIntraBFD(srcAddr, s.Payload)
			unfold sNew.Mem()
			pr = processResult{}
			errRet, t1, s1 = d.processIntraBFD(srcAddr, sNew.EmbeddedBaseLayer.Payload, absSCION, t2, s2)
			fold sNew.Mem()
			fold pr.Mem()
			ghost if errRet == nil {
				processPktHelper(pr, sNew, rawPkt)
			} else {
				sNew.getRawPktAccWithoutPreservePath(rawPkt)
			}

			assert P(t1, s1)
			return 
		}
		// (tlino) original code, adapted code is below
		// return processResult{}, serrors.WithCtx(unsupportedPathTypeNextHeader,
		// 	"type", s.PathType, "header", s.NextHdr)
		
		pr, errRet = processResult{}, serrors.WithCtx(unsupportedPathTypeNextHeader(),
		 	"type", sNew.getPathType(), "header", sNew.getNextHdr())
		fold pr.Mem()
		ghost sNew.getRawPktAccWithoutPreservePath(rawPkt)
		ghost t1, s1 = t2, s2
		assert P(t1, s1)
		return 
	case slayers.PathTypeOneHop:
		// (tlino) use sNew instead of s and use getters
		// if s.NextHdr == common.L4BFD {
		if sNew.getNextHdr() == common.L4BFD {
			unfold sNew.Mem()
			// (tlino) use sNew instead of s
			// ohp, ok := s.Path.(*onehop.Path)
			ohp, ok := (sNew.Path).(*onehop.Path)
			fold sNew.Mem()
			if !ok {
				// (tlino) original code, adapted code is below
				// return processResult{}, malformedPath
				pr, errRet = processResult{}, malformedPath()
				fold pr.Mem()
				ghost sNew.getRawPktAccWithoutPreservePath(rawPkt)
				ghost t1, s1 = t2, s2
				assert P(t1, s1)
				return
			}
			
			// (tlino) original code, adapted code is below
			// return processResult{}, d.processInterBFD(ingressID, ohp, s.Payload)
			unfold sNew.Mem()
			pr = processResult{}
			errRet, t1, s1  = d.processInterBFD(ingressID, ohp, sNew.EmbeddedBaseLayer.Payload, absSCION, t2, s2)
			fold sNew.Mem()
			fold pr.Mem()
			ghost if errRet == nil {
				processPktHelper(pr, sNew, rawPkt)
			} else {
				sNew.getRawPktAccWithoutPreservePath(rawPkt)
			}

			assert P(t1, s1)
			return
		}
		// (tlino) original code, adapted code is below
		// return d.processOHP(ingressID, rawPkt, s, buffer)

		pr, errRet = d.processOHP(ingressID, rawPkt, sNew, buffer)
		
		// (tlino) apply internal processOHP event, if pr is not empty
		ghost if (!isEmptyPR(pr)) {
			unfold P(t2, s2)
			unfold P_processOHP(t2, s2)
			ghost absPR = ToAbsProcessResult(pr)
			assert processOHP_p(t2, absSCION, absPR)
			ghost s1 = s2 union mset[Fact]{processedPktFact(absPR)}
			ghost t1 = get_processOHP_t1(t2, absSCION, absPR)
			ghost processOHP_f(t2, absSCION, absPR)
			assert token(t1)
			assert P(t1, s1)
		} else {
			ghost t1, s1 = t2, s2
		}
		return
	case slayers.PathTypeSCION:
		// (tlino) original code, adapted code is below 
		// return d.processSCION(ingressID, rawPkt, s, origPacket, buffer)

		pr, errRet = d.processSCION(ingressID, rawPkt, sNew, origPacket, buffer, absSCION, localIA, s2)

		// (tlino) apply internal processSCION event, if pr is not empty
		ghost if (!isEmptyPR(pr)) {
			unfold P(t2, s2)
			unfold P_processSCION(t2, s2)
			ghost absPR = ToAbsProcessResult(pr)
			assert processSCION_p(t2, absSCION, absPR, localIA)
			ghost s1 = s2 union mset[Fact]{processedPktFact(absPR)}
			ghost t1 = get_processSCION_t1(t2, absSCION, absPR, localIA)
			ghost processSCION_f(t2, absSCION, absPR, localIA)
			assert token(t1)
			assert P(t1, s1)
		} else {
			ghost t1, s1 = t2, s2
		}
		return
	default:
		// (tlino) original code, adapted code is below 
		// return processResult{}, serrors.WithCtx(unsupportedPathType, "type", s.PathType)

		pr, errRet = processResult{}, serrors.WithCtx(unsupportedPathType(), "type", sNew.getPathType())
		fold pr.Mem()
		ghost sNew.getRawPktAccWithoutPreservePath(rawPkt)
		ghost t1, s1 = t2, s2
		assert P(t1, s1)
		return
 	}
}

// (tlino) Verified
// (tlino) added method
requires b.MemWithOutSlices()
requires absBFD == ToAbsBFD(b)
requires token(t) && sendInterBFD_p(t, absBFD)
requires acc(sess.Mem(), _)
ensures token(t1) && t1 == old(get_sendInterBFD_t1(t, absBFD))
decreases
func sendInterBFD(sess bfdSession, b *layers.BFD, ghost absBFD AbsBFD, ghost t Place) (ghost t1 Place) {
	ghost translateBFDMemPred(b)
	sess.Messages() <- b
	ghost t1 = sendInterBFD_f(t, absBFD)
}

// (tlino) Verified
// (joao) `oh` is not used anywhere in the function
requires token(t) && P(t, s)
requires decodedPktFact(absScion) in s
requires acc(DataPlaneMutexInvariant(d), _)
preserves verifyutils.BytesAcc(data)
ensures token(t1) && P(t1, s1)
ensures s subset s1
decreases
func (d *DataPlane) processInterBFD(ingressID uint16, oh *onehop.Path, data []byte, ghost absScion AbsSCION, ghost t Place, ghost s mset[Fact]) (err error, ghost t1 Place, ghost s1 mset[Fact]) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BfdSessionsAcc(d.bfdSessions), _)
	if len(d.bfdSessions) == 0 {
		// (joao) no globals
		// return noBFDSessionConfigured
		return noBFDSessionConfigured(), t, s
	}

	p := &layers.BFD{}
	// (joao) TODO: gopacket.NilDecodeFeedback is a var in gopacket but Luca implemented as a type (should be changed).
	//              Code adapted below.
	//if err := p.DecodeFromBytes(data, gopacket.NilDecodeFeedback); err != nil {
	//	return err
	//}
	tmp := gopacket.NilDecodeFeedback{}
	fold tmp.Mem()
	unfold verifyutils.BytesAcc(data)
	if err := p.DecodeFromBytes(data, tmp); err != nil {
		fold verifyutils.BytesAcc(data)
		return err, t, s
	}

	// (tlino) apply internal decodeInterBFD event
	unfold P(t, s)
	unfold P_decodeInterBFD(t, s)
	ghost absBFD := ToAbsBFD(p)
	assert decodeInterBFD_p(t, absScion, absBFD)
	ghost s2 := s union mset[Fact]{decodedInterBFDFact(absBFD)}
	ghost t2 := get_decodeInterBFD_t1(t, absScion, absBFD)
	ghost decodeInterBFD_f(t, absScion, absBFD)
	assert token(t2)
	assert P(t2, s2)

	fold verifyutils.BytesAcc(data)

	// (joao) add parentheses surrounding `d.bfdSessions`
	if v, ok := (d.bfdSessions)[ingressID]; ok {
		// (tlino) original code
		// v.Messages() <- p
		// return nil, t2, s2

		// (tlino) perform sendInterBFD event
		unfold P(t2, s2)
		unfold P_sendInterBFD(t2, s2)
		t3 := sendInterBFD(v, p, absBFD, t2)
		assert token(t3)
		assert P(t3, s2)
		return nil, t3, s2
	}

	// (joao) no globals
	// return noBFDSessionFound
	return noBFDSessionFound(), t2, s2
}

ghost
requires b.MemWithOutSlices()
ensures  (*layers.BFD).MemWithOutSlices!<_!>(b)
decreases
func translateBFDMemPred(b *layers.BFD) {
	unfold (*layers.BFD).MemWithOutSlices(b)
	fold (*layers.BFD).MemWithOutSlices!<_!>(b)
}

// (tlino) Verified
// (tlino) added method
requires b.MemWithOutSlices()
requires absBFD == ToAbsBFD(b)
requires token(t) && sendIntraBFD_p(t, absBFD)
requires acc(sess.Mem(), _)
ensures token(t1) && t1 == old(get_sendIntraBFD_t1(t, absBFD))
decreases
func sendIntraBFD(sess bfdSession, b *layers.BFD, ghost absBFD AbsBFD, ghost t Place) (ghost t1 Place) {
	ghost translateBFDMemPred(b)
	sess.Messages() <- b
	ghost t1 = sendIntraBFD_f(t, absBFD)
}

// (tlino) Verified
requires token(t) && P(t, s)
requires decodedPktFact(absScion) in s
requires acc(DataPlaneMutexInvariant(d), _)
preserves acc(src.Mem(), 1/1000)
preserves verifyutils.BytesAcc(data)
ensures token(t1) && P(t1, s1)
ensures s subset s1
decreases
func (d *DataPlane) processIntraBFD(src net.Addr, data []byte, ghost absScion AbsSCION, ghost t Place, ghost s mset[Fact]) (err error, ghost t1 Place, ghost s1 mset[Fact]) {
	unfold acc(DataPlaneMutexInvariant(d), _)
	unfold acc(BfdSessionsAcc(d.bfdSessions), _)
	if len(d.bfdSessions) == 0 {
		// (tlino) golbals not supported
		// return noBFDSessionConfigured
		return noBFDSessionConfigured(), t, s
	}
	p := &layers.BFD{}

	// (tlino) TODO: gopacket.NilDecodeFeedback is a var in gopacket but Luca implemented as a type (should be changed).
	//              Code adapted below.
	// if err := p.DecodeFromBytes(data, gopacket.NilDecodeFeedback); err != nil {
	// 	return err
	// }

	tmp := gopacket.NilDecodeFeedback{}
	fold tmp.Mem()
	unfold verifyutils.BytesAcc(data)
	if err := p.DecodeFromBytes(data, tmp); err != nil {
		fold verifyutils.BytesAcc(data)
		return err, t, s
	}

	// (tlino) apply internal decodeIntraBFD event
	unfold P(t, s)
	unfold P_decodeIntraBFD(t, s)
	ghost absBFD := ToAbsBFD(p)
	assert decodeIntraBFD_p(t, absScion, absBFD)
	ghost s2 := s union mset[Fact]{decodedIntraBFDFact(absBFD)}
	ghost t2 := get_decodeIntraBFD_t1(t, absScion, absBFD)
	ghost decodeIntraBFD_f(t, absScion, absBFD)
	assert token(t2)
	assert P(t2, s2)

	fold verifyutils.BytesAcc(data)

	ifID := uint16(0)
	srcUDPAddr, ok := src.(*net.UDPAddr)
	if !ok {
		// (joao) No support for fmt
		// return serrors.New("type assertion failure", "from", fmt.Sprintf("%v(%T)", src, src),
		//	"expected", "*net.IPAddr")
		return serrors.New("error"), t2, s2 // (joao) TODO: remove after adding support for fmt
	}

	// (tlino) range not supported yet.
	// (tlino) Thus, we iterate over all possible keys (keyspace: 0,1,2,...,2^16 -1)
	// (tlino) adapted code is below
	// for k, v := range (d.internalNextHops) {
		// remoteUDPAddr, ok := v.(*net.UDPAddr)
		// if !ok {
		// 	return serrors.New("type assertion failure", "from",
		// 		fmt.Sprintf("%v(%T)", remoteUDPAddr, remoteUDPAddr), "expected", "*net.UDPAddr")
		// }
		// if bytes.Equal(remoteUDPAddr.IP, srcUDPAddr.IP) && remoteUDPAddr.Port == srcUDPAddr.Port {
		// 	ifID = k
		// 	continue
		// }
	// }
	mapKeyUpperBound := 65536

	invariant 0 <= k && k <= mapKeyUpperBound
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant acc(srcUDPAddr.Mem(), 1/1000)
	decreases mapKeyUpperBound - k
	for k := 0; k < mapKeyUpperBound; k++ {
		key := uint16(k)
		v, found := d.GetInternalNextHop(key)
		if found {
			remoteUDPAddr, ok := v.(*net.UDPAddr)
			if !ok {
				// (tlino) No support for fmt
				// return serrors.New("type assertion failure", "from",
				// 	fmt.Sprintf("%v(%T)", remoteUDPAddr, remoteUDPAddr), "expected", "*net.UDPAddr")
				return serrors.New("error"), t2, s2
			}
			unfold acc(remoteUDPAddr.Mem(), _)
			unfold acc(srcUDPAddr.Mem(), 1/1000)
			if bytes.Equal(remoteUDPAddr.IP, srcUDPAddr.IP) && remoteUDPAddr.Port == srcUDPAddr.Port {
				ifID = key
			}
			fold acc(srcUDPAddr.Mem(), 1/1000)
		}
	}

 	// (tlino) added parantheses to make it parse
 	// if v, ok := d.bfdSessions[ifID]; ok {
	if v, ok := (d.bfdSessions)[ifID]; ok {
		// (tlino) original code
		// v.Messages() <- p
		// return nil

		// (tlino) perform sendIntraBFD event
		unfold P(t2, s2)
		unfold P_sendIntraBFD(t2, s2)
		t3 := sendIntraBFD(v, p, absBFD, t2)
		assert token(t3)
		assert P(t3, s2)
		return nil, t3, s2
	}

	// (tlino) globals not supported
	// return noBFDSessionFound
	return noBFDSessionFound(), t2, s2
}

// (tlino) Verified
// (tlino) We cannot prove termination of this method, since p.process() might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires s != nil && s.Mem() && s.getRawPkt() == rawPkt
requires localIAFact(localIA) in s0
preserves verifyutils.BytesAcc(origPacket)
preserves cap(rawPkt) == bufSize
preserves buffer.Mem()
ensures pr.Mem()
ensures err == nil ==> pr.Mem() --* verifyutils.BytesAcc(rawPkt)
ensures err != nil ==> verifyutils.BytesAcc(rawPkt)
ensures ( (localIA == GetAbsSCIONDstIA(absSCION)) && (GetAbsRawPathCurrHF(GetAbsSCIONRawPath(absSCION)) + 1 == GetAbsRawPathNumHops(GetAbsSCIONRawPath(absSCION))) ) ==> GetAbsProcessResult(ToAbsProcessResult(pr)) == 0
// (joao) s is now a *slayers.SCION
// func (d *DataPlane) processSCION(ingressID uint16, rawPkt []byte, s slayers.SCION,
func (d *DataPlane) processSCION(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	origPacket []byte, buffer gopacket.SerializeBuffer, ghost absSCION AbsSCION, ghost localIA AbsIA ,ghost s0 mset[Fact]) (pr processResult, err error) {

	// (joao) added `&` before `scionPacketProcessor` to make this type check
	p := &scionPacketProcessor{
		d:          d,
		ingressID:  ingressID,
		rawPkt:     rawPkt,
		scionLayer: s,
		origPacket: origPacket,
		buffer:     buffer,
	}
	// (tlino) use ghost argument to relate the argument of processSCION to process
	// return p.process()
	foo, bar, baz := p.process(rawPkt, absSCION, localIA, s0)
	return foo, bar
}

type scionPacketProcessor struct {
	// d is a reference to the dataplane instance that initiated this processor.
	d *DataPlane
	// ingressID is the interface ID this packet came in, determined from the
	// socket.
	ingressID uint16
	// rawPkt is the raw packet, it is updated during processing to contain the
	// message to send out.
	rawPkt []byte
	// scionLayer is the SCION gopacket layer.
	// (joao) adapted to make this type check in Gobra
	// scionLayer slayers.SCION
	scionLayer *slayers.SCION
	// origPacket is the raw original packet, must not be modified.
	origPacket []byte
	// buffer is the buffer that can be used to serialize gopacket layers.
	buffer gopacket.SerializeBuffer

	// path is the raw SCION path. Will be set during processing.
	path *scion.Raw
	// hopField is the current hopField field, is updated during processing.
	hopField *path.HopField
	// infoField is the current infoField field, is updated during processing.
	infoField *path.InfoField
	// segmentChange indicates if the path segment was changed during processing.
	segmentChange bool
}

pred (p *scionPacketProcessor) Mem() {
	acc(&p.d, _) &&
	acc(&p.ingressID, 1/4) &&
	acc(&p.rawPkt, 1/4) &&
	acc(&p.scionLayer, 1/4) &&
	acc(&p.origPacket, 1/4) &&
	acc(&p.buffer, 1/4) &&
	acc(&p.path) &&
	acc(&p.hopField) &&
	acc(&p.infoField) &&
	acc(&p.segmentChange) &&
	acc(DataPlaneMutexInvariant(p.d), _) &&
	(unfolding acc(DataPlaneMutexInvariant(p.d), _) in p.d.svc != nil) &&
	verifyutils.BytesAcc(p.origPacket) &&
	acc(p.infoField) &&
	path.HopFieldInv(p.hopField) &&
	p.buffer.Mem() &&
	p.scionLayer != nil && p.scionLayer.Mem() &&
	cap(p.rawPkt) == bufSize &&
	p.path != nil && p.path == p.scionLayer.getRawScionPath() &&
 	p.rawPkt == p.scionLayer.getRawPkt()
}

// (tlino) Verified
// TODO: next. "slayers.UDP", "slayers.HopByHopExtn", slayers.EndToEndExtn, *SCION <: DecodingLayer
requires scmpH.Mem() && scmpP.Mem()
preserves p.Mem()
ensures pr.Mem()
ensures errRet != nil
decreases
func (p *scionPacketProcessor) packSCMP(scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer,
	cause error) (pr processResult, errRet error) {
	unfold p.Mem()
	// parse everything to see if the original packet was an SCMP error.
	var (
		scionLayer slayers.SCION
		// (joao) not supported yet
		// udpLayer   slayers.UDP
		// hbhExtn    slayers.HopByHopExtn
		// e2eExtn    slayers.EndToEndExtn
		scmpLayer  slayers.SCMP
	)
	// (joao) currently not supported, rewritten below
	// parser := gopacket.NewDecodingLayerParser(
	//	slayers.LayerTypeSCION, &scionLayer, &udpLayer, &hbhExtn, &e2eExtn, &scmpLayer,
	// )
	parser := gopacket.NewDecodingLayerParser(slayers.LayerTypeSCION())

	decoded@ := make([]gopacket.LayerType, 5)
	assert forall i int :: 0 <= i && i < len(decoded) ==> acc(&decoded[i])
	assert len(decoded) == 5
	if err := parser.DecodeLayers(p.origPacket, &decoded); err != nil {
		if _, ok := err.(gopacket.UnsupportedLayerType); !ok {
			assert len(decoded) == 5
			assert forall j int :: 0 <= j && j < len(decoded) ==> acc(&decoded[j])
			fold p.Mem()
			pr, errRet = processResult{}, serrors.WrapStr("decoding packet", err)
			fold pr.Mem()
			return 
		}
		assert len(decoded) == 5
		assert forall j int :: 0 <= j && j < len(decoded) ==> acc(&decoded[j])
	}
	assert forall i int :: 0 <= i && i < len(decoded) ==> acc(&decoded[i])
	assert len(decoded) == 5
	assert acc(&(decoded[len(decoded)-1]))
	// in reply to an SCMP error do nothing:
	// if decoded[len(decoded)-1] == slayers.LayerTypeSCMP && !scmpLayer.TypeCode.InfoMsg() {
	if decoded[len(decoded)-1] == slayers.LayerTypeSCMP() && !scmpLayer.TypeCode.InfoMsg() {
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("SCMP error for SCMP error pkt -> DROP", cause)
		fold pr.Mem()
		return 
	}

	// the quoted packet is the packet in its current state
	// (tlino) use getter to reduce verification overhead, see adapted code below
	// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	rp := p.rawPkt
	scionL := p.scionLayer
	ghost scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	// (tlino) use getter for currINF to reduce verification overhead
	// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {
	if err := p.path.SetInfoField(p.infoField, int( unfolding p.path.Mem() in scion.getCurrINF(&(p.path.Base)))); err != nil {
		// (tlino) get back access to scionLayer and fold scionPacketProcessor
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("update info field", err)
		fold pr.Mem()
		return 
	}

	// (tlino) use getter for currHF to reduce verification overhead
	// if err := p.path.SetHopField(p.hopField, int(p.path.PathMeta.CurrHF)); err != nil {
	if err := p.path.SetHopField(p.hopField, int( unfolding p.path.Mem() in scion.getCurrHF(&(p.path.Base)))); err != nil {
		// (tlino) get back access to scionLayer and fold scionPacketProcessor
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("update hop field", err)
		fold pr.Mem()
		return 
	}

	// (tlino) get back access to scionLayer
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())

	if err := p.buffer.Clear(); err != nil {
		fold p.Mem()
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}

	if err := p.scionLayer.SerializeTo(p.buffer, gopacket.SerializeOptions{}); err != nil {
		fold p.Mem()
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}
	// quoteLen is used to limit the size of the quote buffer, the final quote
	// length is calculated inside the scmpPacker.
	quoteLen := len(p.origPacket)
	if quoteLen > slayers.MaxSCMPPacketLen {
		quoteLen = slayers.MaxSCMPPacketLen
	}
	quote := make([]byte, quoteLen)
	// (tlino) use varable b to make magic wands work. Magic wands don't work directly on p.buffer
	b := p.buffer
	updated := b.Bytes()
	assert verifyutils.BytesAcc(updated) --* b.Mem()
	unfold verifyutils.BytesAcc(updated)

	// (tlino) use Gobra's copy function
	// copy(quote[:len(updated)], updated)
	// (tlino) the updated byte representation of the header fields cannot be longer then the length of the quote
	assume len(updated) <= len(quote)
	assert forall i int :: 0 <= i && i < len(quote) ==> acc(&quote[i])
	assert forall i int :: 0 <= i && i < len(updated) ==> acc(&updated[i], 1/100000)
	assert forall i int :: 0 <= i && i < len(updated) ==> &(quote[:len(updated)])[i] == &quote[i]
	assert forall i int :: 0 <= i && i < len(updated) ==> acc(&(quote[:len(updated)])[i])
	
	verifyutils.OutlineMemorySafeCopy(quote[:len(updated)], updated)

	// (tlino) use Gobra's copy function
	// copy(quote[len(updated):], p.origPacket[len(updated):quoteLen])
	unfold verifyutils.BytesAcc(p.origPacket)
	assert forall i int :: 0 <= i && i < (len(quote) - len(updated)) ==> &(quote[len(updated):])[i] == &quote[i + len(updated)]
	assert forall i int :: 0 <= i && i < (len(quote) - len(updated)) ==> acc(&(quote[len(updated):])[i])
	assert forall i int :: 0 <= i && i < len(p.origPacket) ==>  acc(&(p.origPacket)[i], 1/100000)
	assert forall i int :: 0 <= i && i < (quoteLen - len(updated)) ==> &((p.origPacket)[len(updated):quoteLen])[i] == &(p.origPacket)[i + len(updated)]
	assert forall i int :: 0 <= i && i < (quoteLen - len(updated)) ==> acc(&((p.origPacket)[len(updated):quoteLen])[i],  1/100000)
	verifyutils.OutlineMemorySafeCopy(quote[len(updated):], (p.origPacket)[len(updated):quoteLen])

	fold verifyutils.BytesAcc(updated)
	apply verifyutils.BytesAcc(updated) --* b.Mem()
	fold verifyutils.BytesAcc(p.origPacket)
	pr, errRet := packSCMP2(p.d, quote, p.origPacket, p.ingressID, p.scionLayer, b, scmpH, scmpP, cause)
	fold p.Mem()
}

// (tlino) Verified
// (tlino) outlined part of packSCMP
requires acc(DataPlaneMutexInvariant(d), _)
requires forall i int :: 0 <= i && i < len(quote) ==> acc(&quote[i])
requires scmpH.Mem() && scmpP.Mem()
preserves scionLayer.Mem() && buffer.Mem() 
preserves verifyutils.BytesAcc(origPacket)
ensures scionLayer.getRawScionPath() == old(scionLayer.getRawScionPath())
ensures scionLayer.getRawPkt() == old(scionLayer.getRawPkt())
ensures pr.Mem()
ensures err != nil
decreases
func packSCMP2(d *DataPlane, quote []byte, origPacket []byte, ingressID uint16, scionLayer *slayers.SCION, 
	buffer gopacket.SerializeBuffer, scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer, cause error) (pr processResult, err error) {
	
	// (tlino) use getter to simplify verification 
	// _, external := p.d.external[p.ingressID]
	_, external := d.GetExternalBatchConn(ingressID)

	// (tlino) original code, adapted code is below
	// rawSCMP, err := scmpPacker{
	// 	internalIP: p.d.internalIP,
	// 	localIA:    p.d.localIA,
	// 	origPacket: p.origPacket,
	// 	ingressID:  p.ingressID,
	// 	scionL:     &p.scionLayer,
	// 	buffer:     p.buffer,
	// 	quote:      quote,
	// }.prepareSCMP(
	// 	scmpH,
	// 	scmpP,
	// 	external,
	// 	cause,
	// )

	fold verifyutils.BytesAcc(quote)
	unfold acc(DataPlaneMutexInvariant(d), _)

	scmp := scmpPacker{
		internalIP: d.internalIP,
		localIA:    d.localIA,
		origPacket: origPacket,
		ingressID:  ingressID,
		scionL:     scionLayer,
		buffer:     buffer,
		quote:      quote,
	}

	rawSCMP, err := scmp.prepareSCMP(
		scmpH,
		scmpP,
		external,
		cause,
	)
	pr, err = processResult{OutPkt: rawSCMP}, err
	fold pr.Mem()
}

// (tlino) Verified
requires acc(&p.d, _) && acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4) && acc(&p.origPacket, 1/4)
requires acc(&p.buffer, 1/4) && acc(&p.path) && acc(&p.hopField) && acc(&p.infoField) && acc(&p.segmentChange)
requires p.scionLayer != nil && (p.scionLayer).Mem() && (p.buffer).Mem() && verifyutils.BytesAcc(p.origPacket)
requires (cap(p.rawPkt) == bufSize) && p.rawPkt == p.scionLayer.getRawPkt()
requires acc(DataPlaneMutexInvariant(p.d), _)
requires unfolding acc(DataPlaneMutexInvariant(p.d), _) in p.d.svc != nil
ensures errRet != nil ==> acc(&p.d, _) && acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4) && acc(&p.origPacket, 1/4)
ensures errRet != nil ==> acc(&p.buffer, 1/4) && acc(&p.path) && acc(&p.hopField) && acc(&p.infoField) && acc(&p.segmentChange)
ensures errRet != nil ==> (p.scionLayer).Mem() && (p.buffer).Mem() && verifyutils.BytesAcc(p.origPacket)
ensures errRet != nil ==> (cap(p.rawPkt) == bufSize) && p.rawPkt == p.scionLayer.getRawPkt()
ensures errRet == nil ==> p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) parsePath() (pr processResult, errRet error) {
	var ok bool
	unfold p.scionLayer.Mem()
	assert p.scionLayer.Path != nil
	p.path, ok = (p.scionLayer.Path).(*scion.Raw)
	if !ok {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) gobra doesn't support globals yet
		// return processResult{}, malformedPath
		fold p.scionLayer.Mem()
		pr, errRet = processResult{}, malformedPath()
		fold pr.Mem()
		return 
	}
	fold p.scionLayer.Mem()
	assert p.path == p.scionLayer.getRawScionPath()
	var err error

	// (tlino) we know that this holds, since (SCION).DecodeFromBytes has already decoded the path.
	// (tlino) a decoded path is always not nil and in this function of dynamic type *scion.Raw.
	// (tlino) however, (p.scionLayer.Path).(*scion.Raw) cannot deduce that p.path != nil.
	assume p.path != nil

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	scionL := p.scionLayer
	rp := p.rawPkt
	ghost scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	p.hopField, err = p.path.GetCurrentHopField()
	if err != nil {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) get back access to p.scionLayer
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	p.infoField, err = p.path.GetCurrentInfoField()
	if err != nil {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) get back access to p.scionLayer
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	// (tlino) get back access to p.scionLayer
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	fold p.Mem()
	if r, err := p.validateHopExpiry(); err != nil {
		unfold p.Mem()
		return r, err
	}
	if r, err := p.validateIngressID(); err != nil {
		unfold p.Mem()
		return r, err
	}
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateHopExpiry() (pr processResult, errRet error) {
	// (joao) Add to separate this in two lines
	// expiration := util.SecsToTime(p.infoField.Timestamp).
	//	Add(path.ExpTimeToDuration(p.hopField.ExpTime))
	unfold  p.Mem()
	tmp := util.SecsToTime(p.infoField.Timestamp)
	expiration := tmp.Add(path.ExpTimeToDuration(unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ExpTime))
	expired := expiration.Before(time.Now())
	if !expired {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	} 
	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
	// 		slayers.SCMPCodePathExpired),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
	// 	serrors.New("expired hop", "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
	// 		"curr_inf", p.path.PathMeta.CurrINF, "curr_hf", p.path.PathMeta.CurrHF),
	// )
	fold p.Mem()
	scmpH := &slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
		slayers.SCMPCodePathExpired)}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
	fold scmpP.Mem()
	unfold p.Mem()

	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	ghost sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	e := serrors.New("expired hop", "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
		"curr_inf", p.path.GetCurrINF(), "curr_hf", p.path.GetCurrHF())
	
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	fold p.Mem()
	return p.packSCMP(scmpH, scmpP, e)
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateIngressID() (pr processResult, errRet error) {
	unfold p.Mem()
	pktIngressID := unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ConsIngress
	errCode := slayers.SCMPCodeUnknownHopFieldIngress
	if !p.infoField.ConsDir {
		pktIngressID = unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ConsEgress
		errCode = slayers.SCMPCodeUnknownHopFieldEgress
	}
	if p.ingressID != 0 && p.ingressID != pktIngressID {
		// (tlino) original code, adapted code is below
		// return p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
		// 	},
		// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
		// 	serrors.New("ingress interface invalid",
		// 		"pkt_ingress", pktIngressID, "router_ingress", p.ingressID),
		// )
		fold p.Mem()
		scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
			}
		fold scmpH.Mem()
		scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
		fold scmpP.Mem()
		e := serrors.New("ingress interface invalid",
		 		"pkt_ingress", pktIngressID, "router_ingress", (unfolding acc(p.Mem(), 1/1000) in p.ingressID))
		return p.packSCMP(scmpH, scmpP, e)
	}
	fold p.Mem()
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateEgressID() (pr processResult, errRet error) {
	pktEgressID := p.egressInterface()
	unfold p.Mem()
	// (tlino) add parantheses to make it parse
	// _, ih := p.d.internalNextHops[pktEgressID]
	// _, eh := p.d.external[pktEgressID]
	_, ih := p.d.GetInternalNextHop(pktEgressID)
	_, eh := p.d.GetExternalBatchConn(pktEgressID)
	if !ih && !eh {
		errCode := slayers.SCMPCodeUnknownHopFieldEgress
		if !p.infoField.ConsDir {
			errCode = slayers.SCMPCodeUnknownHopFieldIngress
		}
		// (tlino) original code, adapted code is below
		// return p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
		// 	},
		// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
		// 	cannotRoute,
		// )

		scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
			}
		fold scmpH.Mem()
		fold p.Mem()
		scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
		fold scmpP.Mem()
		e := cannotRoute()
		return p.packSCMP(scmpH, scmpP, e)
	}

	if !p.segmentChange {
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		fold p.Mem()
		return 
	}
	// Check that the interface pair is valid on a segment switch. // (tlino) original scion comment
	// Having a segment change received from the internal interface is never valid. // (tlino) original scion comment
	// (tlino) use getter to simplify verification
	// ingress, egress := p.d.linkTypes[p.ingressID], p.d.linkTypes[pktEgressID]
	ingress, egress := p.d.GetLinkType(p.ingressID), p.d.GetLinkType(pktEgressID)
	fold p.Mem()
	switch {
	case ingress == topology.Core && egress == topology.Child:
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	case ingress == topology.Child && egress == topology.Core:
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	case ingress == topology.Child && egress == topology.Child:
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	default:
		// (tlino) original code, adapted code is below
		// return p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(
		// 			slayers.SCMPTypeParameterProblem,
		// 			slayers.SCMPCodeInvalidSegmentChange,
		// 		),
		// 	},
		// 	&slayers.SCMPParameterProblem{Pointer: p.currentInfoPointer()},
		// 	serrors.WithCtx(cannotRoute, "ingress_id", p.ingressID, "ingress_type", ingress,
		// 		"egress_id", pktEgressID, "egress_type", egress))
		scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(
					slayers.SCMPTypeParameterProblem,
					slayers.SCMPCodeInvalidSegmentChange,
				),
			}
		fold scmpH.Mem()
		scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentInfoPointer()}
		fold scmpP.Mem()
		e := serrors.WithCtx(cannotRoute(), "ingress_id", unfolding acc(p.Mem(), 1/1000) in p.ingressID, "ingress_type", ingress,
		 		"egress_id", pktEgressID, "egress_type", egress)
		return p.packSCMP(scmpH, scmpP, e)
	}
}

// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) updateNonConsDirIngressSegID() (err error) {
	// against construction dir the ingress router updates the SegID, ifID == 0
	// means this comes from this AS itself, so nothing has to be done.
	// TODO(lukedirtwalker): For packets destined to peer links this shouldn't
	// be updated.
	unfold p.Mem()
	if !p.infoField.ConsDir && p.ingressID != 0 {
		unfold path.HopFieldInv(p.hopField)
		p.infoField.UpdateSegID(p.hopField.Mac)
		fold path.HopFieldInv(p.hopField)

		// get access to path, use new variables to make Gobra work
		assert p.scionLayer != nil
		assert p.path != nil
		sl := p.scionLayer
		pp := p.path
		rawPkt := p.rawPkt
		ghost sl.getPathAcc(pp, rawPkt)
		assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
		assert pp.Mem()

		if err := p.path.SetInfoField(p.infoField, int( unfolding p.path.Mem() in scion.getCurrINF(&(p.path.Base)))); err != nil {
			apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
			fold p.Mem()
			return serrors.WrapStr("update info field", err)
		}
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
		if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
			fold p.Mem()
			return err
		}
	}
	fold p.Mem()
	return nil
}
 
// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) currentInfoPointer() uint16 {
	// (tlino) needs to use getPathAcc to obtain access to p.path
	// return uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() +
	// 	scion.MetaLen + path.InfoLen*int(p.path.PathMeta.CurrINF))
	unfold p.Mem()
	
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	ghost sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	currINF := uint16(p.path.GetCurrINF())
	infoLen := uint16(path.InfoLen)
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	offset := uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() + scion.MetaLen)
	pointer := offset + infoLen * currINF
	fold p.Mem()
	return pointer
}

// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) currentHopPointer() uint16 {
	// (tlino) needs to use getPathAcc to obtain access to p.path
	// return  uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() +
	// 	scion.MetaLen + path.InfoLen*p.path.NumINF + path.HopLen*int(p.path.PathMeta.CurrHF))
	unfold p.Mem()
	
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	ghost sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()
	
	numInf := uint16(p.path.GetNumINF())
	currHF := uint16(p.path.GetCurrHF())
	infoLen := uint16(path.InfoLen)
	hopLen := uint16(path.HopLen)
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	offset := uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() + scion.MetaLen)
	pointer := offset + infoLen * numInf + hopLen * currHF
	fold p.Mem()
	return pointer
}

// (tlino) not verified yet
// (joao) currently not supported
preserves p.Mem()
ensures pr.Mem()
decreases _
func (p *scionPacketProcessor) verifyCurrentMAC() (pr processResult, err error) //{
// 	if err := path.VerifyMAC(p.d.macFactory(), p.infoField, p.hopField); err != nil {
// 		return p.packSCMP(
// 			&slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
// 				slayers.SCMPCodeInvalidHopFieldMAC),
// 			},
// 			&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
// 			serrors.WithCtx(err, "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
// 				"curr_inf", p.path.PathMeta.CurrINF, "curr_hf", p.path.PathMeta.CurrHF,
// 				"seg_id", p.infoField.SegID),
// 		)
// 	}
// 	return processResult{}, nil
// }

// (tlino) Verified
// (tlino) TODO: catch other errors of resolveLocalDst than noSVCBackend
// (tlino) for now we assume this method catches all possible errors from resolveLocalDst
// (tlino) we cannot prove termination of this method since p.d.resolveLocalDst() might not terminate
preserves p.Mem()
ensures pr.Mem()
func (p *scionPacketProcessor) resolveInbound() (address net.Addr, pr processResult, errRet error) {
	unfold p.Mem()
	sl := p.scionLayer
	a, err := p.d.resolveLocalDst(sl)
	switch {
	// (tlino) globals not supported
	// case errors.Is(err, noSVCBackend):
	case errors.Is(err, noSVCBackend()):
		// (tlino) original code, adapted code is below
		// r, err := p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeDestinationUnreachable,
		// 			slayers.SCMPCodeNoRoute),
		// 	},
		// 	&slayers.SCMPDestinationUnreachable{}, err)
		// return nil, r, err
		scmpH := &slayers.SCMP{
			TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeDestinationUnreachable,
				slayers.SCMPCodeNoRoute),
		}
		fold scmpH.Mem()
		scmpP := &slayers.SCMPDestinationUnreachable{}
		fold scmpP.Mem()
		e := err
		fold p.Mem()
		address = nil
		pr, errRet = p.packSCMP(scmpH, scmpP, e)
	default:
		// (tlino) original code, adpated code is below
		// return a, processResult{}, nil
		fold p.Mem()
		address, pr, errRet = a, processResult{}, nil
		fold pr.Mem()
	}
}

// (tlino) Verified
preserves p.Mem()
decreases
func (p *scionPacketProcessor) processEgress() error {
	// we are the egress router and if we go in construction direction we
	// need to update the SegID.

	unfold p.Mem()

	// (tlino) get access to p.path
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	ghost sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	if p.infoField.ConsDir {
		unfold path.HopFieldInv(p.hopField)
		p.infoField.UpdateSegID(p.hopField.Mac)
		fold path.HopFieldInv(p.hopField)

		// (tlino) use helper function to access CurrINF
		// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {
		if err := p.path.SetInfoField(p.infoField, int(p.path.GetCurrINF())); err != nil {
			// TODO parameter problem invalid path
			apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
			fold p.Mem()
			return serrors.WrapStr("update info field", err)
		}
	}

	if err := p.path.IncPath(); err != nil {
		// TODO parameter problem invalid path
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		fold p.Mem()
		return serrors.WrapStr("incrementing path", err)
	}
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
		fold p.Mem()
		return err
	}
	fold p.Mem()
	return nil
}

// (tlino) Verified
requires p.Mem()
ensures errRet == nil ==> p.Mem()
ensures errRet != nil ==> acc(&p.d, _) && acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4)
ensures errRet != nil ==> acc(&p.origPacket, 1/4) && acc(&p.buffer, 1/4) && acc(&p.path) && acc(&p.hopField)
ensures errRet != nil ==> acc(&p.infoField) && acc(&p.segmentChange)
ensures errRet != nil ==> acc(DataPlaneMutexInvariant(p.d), _) && verifyutils.BytesAcc(p.origPacket)
ensures errRet != nil ==> p.buffer.Mem() && p.scionLayer.Mem() && cap(p.rawPkt) == bufSize
ensures errRet != nil ==> p.path != nil && p.scionLayer != nil && p.path == p.scionLayer.getRawScionPath()
ensures errRet != nil ==> p.rawPkt == p.scionLayer.getRawPkt()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) doXover() (pr processResult, errRet error) {
	unfold p.Mem()
	p.segmentChange = true

	// (tlino) get access to p.path
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	ghost sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	if err := p.path.IncPath(); err != nil {
		// TODO parameter problem invalid path // (tlino) original scion comment
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		pr, errRet = processResult{}, serrors.WrapStr("incrementing path", err)
		fold pr.Mem()
		return
	}
	var err error
	if p.hopField, err = p.path.GetCurrentHopField(); err != nil {
		// TODO parameter problem invalid path // (tlino) original scion comment
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}
	if p.infoField, err = p.path.GetCurrentInfoField(); err != nil {
		// TODO parameter problem invalid path // (tlino) original scion comment
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	// (tlino) get back access to scionLayer
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}
	fold p.Mem()
	if r, err := p.validateHopExpiry(); err != nil {
		pr, errRet = r, err
		unfold p.Mem()
		return 
	}
	// verify the new block
	if r, err := p.verifyCurrentMAC(); err != nil {
		pr, errRet = r, serrors.WithCtx(err, "info", "after xover")
		unfold p.Mem()
		return 
	}
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return
}

// (tlino) Verified
preserves acc(p.Mem(), 1/10)
ensures res >= 0
decreases
func (p *scionPacketProcessor) egressInterface() (res uint16) {
	unfold acc(p.Mem(), 1/10)
	if p.infoField.ConsDir {
		res = unfolding acc(path.HopFieldInv(p.hopField), 1/100) in p.hopField.ConsEgress
		fold acc(p.Mem(), 1/10)
		return
	}
	res = unfolding acc(path.HopFieldInv(p.hopField), 1/100) in p.hopField.ConsIngress
	fold acc(p.Mem(), 1/10)
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateEgressUp() (pr processResult, errRet error) {
	egressID := p.egressInterface()
	unfold p.Mem()
	// (tlino) use getter function to avoid unfold
	// if v, ok := p.d.bfdSessions[egressID]; ok {
	if v, ok := p.d.GetBfdSession(egressID); ok {
		assert acc(v.Mem(), _)
		if !v.IsUp() {
			scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeExternalInterfaceDown, 0),
			}
			var scmpP gopacket.SerializableLayer = &slayers.SCMPExternalInterfaceDown{
				// (tlino) use getter function to avoid unfold
				// IA:   p.d.localIA,
				IA:   p.d.GetLocalAI(),
				IfID: uint64(egressID),
			}
			// (tlino) use getter function to avoid unfold
			// if _, external := p.d.external[egressID]; !external {
			if _, external := p.d.GetExternalBatchConn(egressID); !external {
				scmpH.TypeCode =
					slayers.CreateSCMPTypeCode(slayers.SCMPTypeInternalConnectivityDown, 0)
				scmpP = &slayers.SCMPInternalConnectivityDown{
					// (tlino) use getter function to avoid unfold
					// IA:      p.d.localIA,
					IA:      p.d.GetLocalAI(),
					Ingress: uint64(p.ingressID),
					Egress:  uint64(egressID),
				}
			}
			fold scmpH.Mem()
			fold scmpP.Mem()
			fold p.Mem()
			pr, errRet =  p.packSCMP(scmpH, scmpP, serrors.New("bfd session down"))
			return
		}
	}
	fold p.Mem()
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleIngressRouterAlert() (pr processResult, errRet error) {
	unfold p.Mem()
	if p.ingressID == 0 {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	unfold path.HopFieldInv(p.hopField)
	ingressAlert := (!p.infoField.ConsDir && p.hopField.EgressRouterAlert) ||
		(p.infoField.ConsDir && p.hopField.IngressRouterAlert)
	if !ingressAlert {
		fold path.HopFieldInv(p.hopField)
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	p.hopField.IngressRouterAlert = false
	fold path.HopFieldInv(p.hopField)
	ingressID := p.ingressID
	fold p.Mem()
	// (tlino) use new variable for argument
	// return p.handleSCMPTraceRouteRequest(p.ingressID)
	return p.handleSCMPTraceRouteRequest(ingressID)
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleEgressRouterAlert() (pr processResult, errRet error) {
	unfold p.Mem()
	unfold path.HopFieldInv(p.hopField)
	egressAlert := (p.infoField.ConsDir && p.hopField.EgressRouterAlert) ||
		(!p.infoField.ConsDir && p.hopField.IngressRouterAlert)
	fold path.HopFieldInv(p.hopField)
	fold p.Mem()
	if !egressAlert {
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	egressID := p.egressInterface()
	unfold p.Mem()
	unfold path.HopFieldInv(p.hopField)
	// (tlino) use getter to simplify verification
	// if _, ok := (p.d.external)[egressID]; !ok {
	if _, ok := p.d.GetExternalBatchConn(egressID); !ok {
		fold path.HopFieldInv(p.hopField)
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	p.hopField.EgressRouterAlert = false
	fold path.HopFieldInv(p.hopField)
	fold p.Mem()
	return p.handleSCMPTraceRouteRequest(egressID)
}

// (tlino) Verified
// (tlino) p.scionLayer.Payload is subsliced in scmpH and scmpP
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleSCMPTraceRouteRequest(
	interfaceID uint16) (pr processResult, errRet error) {
	// (tlino) use pointer type
	// var scmpH slayers.SCMP
	var scmpH *slayers.SCMP = &slayers.SCMP{}
	unfold p.Mem()

	// (tlino) get access to payload, use new variables to make it work
	sl := p.scionLayer
	rp := p.rawPkt
	pp := p.path
	pl := p.scionLayer.LayerPayload()
	ghost sl.getLayerPayloadAcc(pl, pp, rp)
	assert verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
	assert verifyutils.BytesAcc(pl)

	// (tlino) access Payload over EmbeddedBaseLayer, since Gobra has no support for embedded fields.
	// (tlino) use gopacket.NilDecodeFeedback{} instead of var gopacket.NilDecodeFeedback.
	// if err := scmpH.DecodeFromBytes(p.scionLayer.Payload, gopacket.NilDecodeFeedback); err != nil {
	df := gopacket.NilDecodeFeedback{}
	fold df.Mem()
	if err := scmpH.DecodeFromBytes(pl, df); err != nil {
		// (tlino) log not supported yet
		// log.Debug("Parsing SCMP header of router alert", "err", err)

		// get back access to scionLayer
		apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
		fold p.Mem()

		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	}
	
	// (tlino) use getter for TypeCode to speed up verification
	// if scmpH.TypeCode != slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteRequest, 0) {
	if scmpH.GetTypeCode() != slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteRequest, 0) {
		// (tlino) log not supported yet
		// log.Debug("Packet with router alert, but not traceroute request",
		// 	"type_code", scmpH.TypeCode)

		// (tlino) get back access to payload from scmpH
		ghost scmpH.getRawPktAcc(pl)
		assert verifyutils.BytesAcc(pl) --* scmpH.MemAfterDecode()
		assert verifyutils.BytesAcc(pl)
		// (tlino) get back access to scionLayer
		apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
		fold p.Mem()

		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	}

	// (tlino) get access to scmpH.Payload, use new variables to make it work
	scmpHPayload := scmpH.GetPayload()
	ghost scmpH.getPayloadAcc(scmpHPayload, pl)
	assert verifyutils.BytesAcc(scmpHPayload) --* (scmpH.MemAfterDecode() && scmpHPayload == scmpH.GetPayload() && pl == scmpH.GetRawPkt())
	assert verifyutils.BytesAcc(scmpHPayload)

	// (tlino) use pointer type 
	// var scmpP slayers.SCMPTraceroute
	var scmpP *slayers.SCMPTraceroute = &slayers.SCMPTraceroute{}
	// (tlino) use gopacket.NilDecodeFeedback{} instead of var gopacket.NilDecodeFeedback
	// if err := scmpP.DecodeFromBytes(scmpH.Payload, gopacket.NilDecodeFeedback); err != nil {
	df2 := gopacket.NilDecodeFeedback{}
	fold df2.Mem()
	if err := scmpP.DecodeFromBytes(scmpHPayload, df2); err != nil {
		// (tlino) log not supported yet
		// log.Debug("Parsing SCMPTraceroute", "err", err)

		// get back access to scmpH
		apply verifyutils.BytesAcc(scmpHPayload) --* (scmpH.MemAfterDecode() && scmpHPayload == scmpH.GetPayload() && pl == scmpH.GetRawPkt())
		// (tlino) get back access to payload from scmpH
		ghost scmpH.getRawPktAcc(pl)
		assert verifyutils.BytesAcc(pl) --* scmpH.MemAfterDecode()
		assert verifyutils.BytesAcc(pl)
		// (tlino) get back access to scionLayer
		apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())
		fold p.Mem()

		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	}
	// (tlino) get values from scmpP
	scmpPIdent := scmpP.GetIdentifier()
	scmpPSeq := scmpP.GetSequence()

	// (tlino) get back acces to scmpHPayload
	ghost scmpP.GetRawPktAcc(scmpHPayload)
	assert verifyutils.BytesAcc(scmpHPayload) --* (scmpP.Mem() && scmpHPayload == scmpP.GetRawPkt())
	assert verifyutils.BytesAcc(scmpHPayload)
	// (tlino) get back acces to scmpH
	apply verifyutils.BytesAcc(scmpHPayload) --* (scmpH.MemAfterDecode() && scmpHPayload == scmpH.GetPayload() && pl == scmpH.GetRawPkt())
	// (tlino) get back access to scionLayer.Payload
	ghost scmpH.getRawPktAcc(pl)
	assert verifyutils.BytesAcc(pl) --* scmpH.MemAfterDecode()
	assert verifyutils.BytesAcc(pl)
	// (tlino) get back access to scionLayer
	apply verifyutils.BytesAcc(pl) --* (sl.Mem() && pl == sl.LayerPayload() && rp == sl.getRawPkt() && pp == sl.getRawScionPath())


	// // (tlino) original code, outlined to function
	// // scmpH = slayers.SCMP{
	// // 	TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteReply, 0),
	// // }
	// // scmpP = slayers.SCMPTraceroute{
	// // 	Identifier: scmpP.Identifier,
	// // 	Sequence:   scmpP.Sequence,
	// // 	IA:         p.d.localIA,
	// // 	Interface:  uint64(interfaceID),
	// // }
	// // return p.packSCMP(&scmpH, &scmpP, nil)

	fold p.Mem()
	return p.handleSCMPTraceRouteRequest2(interfaceID, scmpPIdent, scmpPSeq)
}

// (tlino) Verified
// (tlino) added method to simplify verification
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) handleSCMPTraceRouteRequest2(interfaceID uint16, scmpPIdent uint16, 
	scmpPSeq uint16) (pr processResult, errRet error) {

	scmpH := &slayers.SCMP{
		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteReply, 0),
	}
	fold scmpH.Mem()

	unfold p.Mem()
	scmpP := &slayers.SCMPTraceroute{
		Identifier: scmpPIdent,
		Sequence:   scmpPSeq,
		// (tlino) use getter to simplify verification
		// IA:         p.d.localIA,
		IA:         p.d.GetLocalAI(),
		Interface:  uint64(interfaceID),
	}
	fold p.Mem()
	fold scmpP.Mem()
	return p.packSCMP(scmpH, scmpP, nil)
}

// (tlino) Verified
preserves p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validatePktLen() (pr processResult, errRet error) {
	unfold p.Mem()
	// (joao) adapted to avoid unfolding predicates
	// if int(p.scionLayer.PayloadLen) == len(p.scionLayer.Payload) {
	if int(p.scionLayer.getPayloadLen()) == len(p.scionLayer.LayerPayload()) {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{
	// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
	// 			slayers.SCMPCodeInvalidPacketSize),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: 0},
	// 	serrors.New("bad packet size",
	// 		"header", p.scionLayer.PayloadLen, "actual", len(p.scionLayer.Payload)),
	// )

	scmpH := &slayers.SCMP{
			TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
			slayers.SCMPCodeInvalidPacketSize),
		}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: 0}
	fold scmpP.Mem()
	e := serrors.New("bad packet size", 
		"header", p.scionLayer.getPayloadLen(), "actual", len(p.scionLayer.LayerPayload()))
	
	fold p.Mem()
	return p.packSCMP(scmpH, scmpP, e)
}

type ResultCase uint

const (
	InBound ResultCase = 1
	Transit ResultCase = 2
	TransitFromOtherBR ResultCase = 3
)

// (tlino) Verified
// (tlino) This method needs an alias to rawPkt as ghost argument, such that it can relate
// (tlino) pr.Mem() --* verifyutils.BytesAcc(rawPktAlias) to pr.Mem() --* verifyutils.BytesAcc(p.rawPkt)
// (tlino) We cannot prove termination of this method, since p.resolveInbound() might not terminate
requires localIAFact(locIA) in s
requires acc(&p.d, _) && acc(&p.ingressID, 1/2) && acc(&p.rawPkt, 1/2) && acc(&p.scionLayer, 1/2)
requires acc(&p.origPacket, 1/2) && acc(&p.buffer, 1/2) && acc(&p.path) && acc(&p.hopField)
requires acc(&p.infoField) && acc(&p.segmentChange)
requires acc(DataPlaneMutexInvariant(p.d), _)
requires unfolding acc(DataPlaneMutexInvariant(p.d), _) in p.d.svc != nil
requires verifyutils.BytesAcc(p.origPacket)
requires cap(p.rawPkt) == bufSize
requires (p.buffer).Mem()
requires p.scionLayer != nil && (p.scionLayer).Mem() && (p.scionLayer).getRawPkt() == p.rawPkt
requires rawPktAlias == p.rawPkt
ensures acc(&p.d, _) && acc(&p.ingressID, 1/2) && acc(&p.rawPkt, 1/2) && acc(&p.scionLayer, 1/2)
ensures acc(&p.origPacket, 1/2) && acc(&p.buffer, 1/2) && acc(&p.path) && acc(&p.hopField)
ensures acc(&p.infoField) && acc(&p.segmentChange)
ensures verifyutils.BytesAcc(p.origPacket)
ensures (p.buffer).Mem()
ensures pr.Mem()
ensures errProcess == nil ==> pr.Mem() --* verifyutils.BytesAcc(rawPktAlias)
ensures errProcess != nil ==> verifyutils.BytesAcc(rawPktAlias)
// MyLocalIA(localIA) in state && GetCurrentHop(absPackage)+1 == GetLastHop(absPackage) && localIA == GetDstIA(absPackage)
ensures ( (resultCase == InBound) && (locIA == GetAbsSCIONDstIA(absSCION)) && ((GetAbsRawPathCurrHF(GetAbsSCIONRawPath(absSCION)) + 1) == GetAbsRawPathNumHops(GetAbsSCIONRawPath(absSCION))) ) ==> (GetAbsProcessResult(ToAbsProcessResult(pr)) == 0)
func (p *scionPacketProcessor) process(ghost rawPktAlias []byte, ghost absSCION AbsSCION, ghost locIA AbsIA, ghost s mset[Fact]) (pr processResult, errProcess error, ghost resultCase ResultCase) {
	if r, err := p.parsePath(); err != nil {
		pr, errProcess := r, err
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}

	// (tlino) keep read access to fields, they aren't modified
	assert acc(&p.ingressID, 1/4) && acc(&p.rawPkt, 1/4) && acc(&p.scionLayer, 1/4) && acc(&p.origPacket, 1/4) && acc(&p.buffer, 1/4)

	if r, err := p.validatePktLen(); err != nil {
		// (tlino) original code, adapted code is below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}

	if err := p.updateNonConsDirIngressSegID(); err != nil {
		// (tlino) original code, adapted code is below
		// return processResult{}, err

		unfold p.Mem()
		pr, errProcess = processResult{}, err
		fold pr.Mem()
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}
	
	if r, err := p.verifyCurrentMAC(); err != nil {
		// (tlino) original code, adapted code is below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}
	
	if r, err := p.handleIngressRouterAlert(); err != nil {
		// (tlino) original code, adapted code is below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}
	
	// (tlino) added code, get some values
	unfold p.Mem()
	dstIA := p.scionLayer.getDstIA()
	localIA := p.d.GetLocalAI()

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	rp := p.rawPkt
	scionL := p.scionLayer
	ghost scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	currHF := pp.GetCurrHF()
	numHops := pp.GetNumHops()

	// Inbound: pkts destined to the local IA.
	// (tlino) use getters above to avoid unfoldings
	// if p.scionLayer.DstIA.Equal(p.d.localIA) && int(p.path.PathMeta.CurrHF)+1 == p.path.NumHops {
	if dstIA.Equal(localIA) && int(currHF)+1 == numHops {
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		a, r, err := p.resolveInbound()
		if err != nil {
			// (tlino) original code, adapted code below
			// return r, err

			unfold p.Mem()
			pr, errProcess = r, err
			ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
			return pr, errProcess, 0
		}
		// (tlino) original code, adapted code below
		// return processResult{OutConn: p.d.internal, OutAddr: a, OutPkt: p.rawPkt}, nil
		unfold p.Mem()

		// get access to rawPkt, use new variables to make Gobra work
		assert p.scionLayer.Mem()
		sl := p.scionLayer
		rp := p.rawPkt
		ghost sl.getRawPktAccWithoutPreservePath(rp)
		assert verifyutils.BytesAcc(rp)

		pr, errProcess = processResult{OutConn: p.d.getInternal(), OutAddr: a, OutPkt: p.rawPkt, AddrSrc: AddrFromPacketBytes}, nil
		fold pr.Mem()
		assert pr.Mem()

		package pr.Mem() --* (verifyutils.BytesAcc(rp)) {
			unfold pr.Mem()
		}

		assert pr.Mem() --* (verifyutils.BytesAcc(rp))
		// (tlino) use lemma methods to relate abstract types
		ghost _ := relateDstIAToLocalIA(dstIA, localIA, locIA, absSCION)
		assert locIA == GetAbsSCIONDstIA(absSCION)
		ghost _ := relateLastHopToNumHops(currHF, numHops, absSCION)
		assert (GetAbsRawPathCurrHF(GetAbsSCIONRawPath(absSCION)) + 1) == GetAbsRawPathNumHops(GetAbsSCIONRawPath(absSCION))
		ghost _ := relateEgressID(pr)
		assert 0 == GetAbsProcessResult(ToAbsProcessResult(pr))
		assert ( (locIA == GetAbsSCIONDstIA(absSCION)) && ((GetAbsRawPathCurrHF(GetAbsSCIONRawPath(absSCION)) + 1) == GetAbsRawPathNumHops(GetAbsSCIONRawPath(absSCION))) ) ==> (GetAbsProcessResult(ToAbsProcessResult(pr)) == 0)
		return pr, errProcess, InBound
	}

	// Outbound: pkts leaving the local IA.
	// BRTransit: pkts leaving from the same BR different interface.

	// (tlino) check acces to p.path
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	isXover := p.path.IsXover()
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	fold p.Mem()

	// (tlino) use variable instead of p.path.IsXover()
	// if p.path.IsXover() {
	if isXover {
		if r, err := p.doXover(); err != nil {
			// (tlino) original code, adapted code below
			// return r, err

			pr, errProcess = r, err
			ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
			return pr, errProcess, 0
		}
	}
	
	if r, err := p.validateEgressID(); err != nil {
		// (tlino) original code, adapted code below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		assert pr.Mem()
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}
	
	// handle egress router alert before we check if it's up because we want to
	// send the reply anyway, so that trace route can pinpoint the exact link
	// that failed.
	if r, err := p.handleEgressRouterAlert(); err != nil {
		// (tlino) original code, adapted code below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}
	if r, err := p.validateEgressUp(); err != nil {
		// (tlino) original code, adapted code below
		// return r, err

		unfold p.Mem()
		pr, errProcess = r, err
		ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
		return pr, errProcess, 0
	}
	egressID := p.egressInterface()

	// (tlino) use getter to simplify verification
	// if c, ok := p.d.external[egressID]; ok {
	if c, ok := p.d.GetExternalBatchConn(egressID); ok {
		if err := p.processEgress(); err != nil {
			// (tlino) original code,  adapted code below
			// return processResult{}, err

			unfold p.Mem()
			pr, errProcess = processResult{}, err
			fold pr.Mem()
			ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
			return pr, errProcess, 0
		}
		// (tlino) original code, adapted code is below
		// return processResult{EgressID: egressID, OutConn: c, OutPkt: p.rawPkt}, nil

		unfold p.Mem()

		// get access to rawPkt, use new variables to make Gobra work
		assert p.scionLayer.Mem()
		sl := p.scionLayer
		rp := p.rawPkt
		ghost sl.getRawPktAccWithoutPreservePath(rp)
		assert verifyutils.BytesAcc(rp)
		
		assert acc(c.Mem(), _)

		pr, errProcess = processResult{EgressID: egressID, OutConn: c, OutPkt: p.rawPkt}, nil
		fold pr.Mem()
		assert pr.Mem()

		package pr.Mem() --* (verifyutils.BytesAcc(rp)) {
			unfold pr.Mem()
		}

		assert pr.Mem() --* (verifyutils.BytesAcc(rp))
		return pr, errProcess, 0
	}
	
	// ASTransit: pkts leaving from another AS BR.

	// (tlino) use getter to simplify verification
	// if a, ok := p.d.internalNextHops[egressID]; ok {
	if a, ok := p.d.GetInternalNextHop(egressID); ok {
		// (tlino) original code, adapted code is below
		// return processResult{OutConn: p.d.internal, OutAddr: a, OutPkt: p.rawPkt}, nil

		unfold p.Mem()

		// get access to rawPkt, use new variables to make Gobra work
		assert p.scionLayer.Mem()
		sl := p.scionLayer
		rp := p.rawPkt
		ghost sl.getRawPktAccWithoutPreservePath(rp)
		assert verifyutils.BytesAcc(rp)

		pr, errProcess = processResult{OutConn: p.d.getInternal(), OutAddr: a, OutPkt: p.rawPkt, AddrSrc: AddrFromDataplane}, nil
		fold pr.Mem()
		assert pr.Mem()

		package pr.Mem() --* (verifyutils.BytesAcc(rp)) {
			unfold pr.Mem()
		}

		assert pr.Mem() --* (verifyutils.BytesAcc(rp))
		return pr, errProcess, 0
	}

	assert p.Mem()

	errCode := slayers.SCMPCodeUnknownHopFieldEgress
	consDir := unfolding acc(p.Mem(), 1/1000) in p.infoField.ConsDir
	// (tlino) use variable for ConsDir, simplifies verification
	// if !p.infoField.ConsDir {
	if !consDir {
		errCode = slayers.SCMPCodeUnknownHopFieldIngress
	}

	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{
	// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
	// 	cannotRoute,
	// )
	scmpH := &slayers.SCMP{
		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
	}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
	fold scmpP.Mem()
	e := cannotRoute()
	pr, errProcess = p.packSCMP(scmpH, scmpP, e)

	assert pr.Mem()
	unfold p.Mem()
	ghost p.scionLayer.getRawPktAccWithoutPreservePath(p.rawPkt)
	return pr, errProcess, 0
}

// (tlino) Specified
// (tlino) added helper function to simulate the result of a MAC computation
requires acc(DataPlaneMutexInvariant(d), _)
preserves acc(p.Mem(), 1/1000)
ensures len(res) == path.MacLen
ensures forall i int :: 0 <= i && i < len(res) ==> acc(&res[i])
decreases _
func (d *DataPlane) getDummyMac(p *onehop.Path) (res []byte)

// (tlino) Verified
// (tlino) we cannot prove termination of this method, since processOHP2 might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires ingressID >= 0
requires s.Mem() && s.getRawPkt() == rawPkt
preserves buffer.Mem()
preserves cap(rawPkt) == bufSize
ensures pr.Mem()
ensures errRet == nil ==> pr.Mem() --* verifyutils.BytesAcc(rawPkt)
ensures errRet != nil ==> verifyutils.BytesAcc(rawPkt)
// (tlino) s is now a *slayers.SCION
// func (d *DataPlane) processOHP(ingressID uint16, rawPkt []byte, s slayers.SCION,
//	buffer gopacket.SerializeBuffer) (processResult, error) {
func (d *DataPlane) processOHP(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	buffer gopacket.SerializeBuffer) (pr processResult, errRet error) {
		
	// (tlino) add path variable
	unfold s.Mem()
	p, ok := (s.Path).(*onehop.Path)
	if !ok {
		// TODO parameter problem -> invalid path // (tlino) original scion comment
		// (tlino) globals not supported
		// return processResult{}, malformedPath
		pr, errRet = processResult{}, malformedPath()
		fold pr.Mem()
		fold s.Mem()
		ghost s.getRawPktAccWithoutPreservePath(rawPkt)
		return 
	}
	// (tlino) the deserializer enforces that p != nil holds
	// (tlino) however, gobra cannot deduce that after
	// (tlino) asserting the dynamic type ((s.Path).(*onehop.Path))
	assume p != nil
	assert p.Mem()
	
	// (tlino) use getter to simplify verification
	// if !p.Info.ConsDir {
	if !p.GetConsDir() {
		// TODO parameter problem -> invalid path // (tlino) original scion comment
		
		// (tlino) globals not supported
		// return processResult{}, serrors.WrapStr(
		// 	"OneHop path in reverse construction direction is not allowed",
		// 	malformedPath, "srcIA", s.SrcIA, "dstIA", s.DstIA)

		pr, errRet = processResult{}, serrors.WrapStr(
			"OneHop path in reverse construction direction is not allowed",
			malformedPath(), "srcIA", s.SrcIA, "dstIA", s.DstIA)
		fold pr.Mem()
		fold s.Mem()
		ghost s.getRawPktAccWithoutPreservePath(rawPkt)
		return 
	}
	
	// (tlino) use getter to simplify verification
	// if !d.localIA.Equal(s.DstIA) && !d.localIA.Equal(s.SrcIA) {
	if !(d.GetLocalAI()).Equal(s.DstIA) && !(d.GetLocalAI()).Equal(s.SrcIA) {
		// TODO parameter problem -> invalid path // (tlino) original scion comment
		
		// (tlino) globals not supported
		// return processResult{}, serrors.WrapStr("OneHop neither destined or originating from IA",
		// 	cannotRoute, "localIA", d.localIA, "srcIA", s.SrcIA, "dstIA", s.DstIA)

		pr, errRet = processResult{}, serrors.WrapStr("OneHop neither destined or originating from IA",
			cannotRoute(), "localIA", d.GetLocalAI(), "srcIA", s.SrcIA, "dstIA", s.DstIA)

		fold pr.Mem()
		fold s.Mem()
		ghost s.getRawPktAccWithoutPreservePath(rawPkt)
		return 
	}

	// OHP leaving our IA

	// (tlino) use getter to simplify verification
	// if d.localIA.Equal(s.SrcIA) {
	if (d.GetLocalAI()).Equal(s.SrcIA) {
		// (tlino) function pointers (macFactory) aren't supported yet
		// if err := path.VerifyMAC(d.macFactory(), &p.Info, &p.FirstHop); err != nil {
		// 	// TODO parameter problem -> invalid MAC // (tlino) original scion comment
		// 	return processResult{}, serrors.WithCtx(err, "type", "ohp")
		// }

		// (tlino) use update function to avoid unfolding p
		// p.Info.UpdateSegID(p.FirstHop.Mac)
		p.InfoUpdateSegID()

		fold s.Mem()
		assert p == s.getOHPPath()
		if err := updateSCIONLayer(rawPkt, s, buffer); err != nil {
			// (tlino) original code, adapted code is below
			// return processResult{}, err
			pr, errRet = processResult{}, err
			fold pr.Mem()
			ghost s.getRawPktAccWithoutPreservePath(rawPkt)
			return 
		}

		// (tlino) added code to get back relation between p and s.Path
		assert p != nil && p == s.getOHPPath()
		unfold s.Mem()
		assert p.Mem()

		// OHP should always be directed to the correct BR. // (tlino) original scion comment
		// (tlino) use getter to simplify verification
		// if c, ok := d.external[p.FirstHop.ConsEgress]; ok {
		fristHopConsEgress := p.GetFristHopConsEgress()
		if c, ok := d.GetExternalBatchConn(fristHopConsEgress); ok {
			// buffer should already be correct // (tlino) original scion comment

			// (tlino) get access to rawPkt
			fold s.Mem()
			ghost s.getRawPktAccWithoutPreservePath(rawPkt)
			assert verifyutils.BytesAcc(rawPkt)

			// (tlino) use getter to simplify verification
			// return processResult{EgressID: p.FirstHop.ConsEgress, OutConn: c, OutPkt: rawPkt}, nil
			assert acc(c.Mem(), _)
			pr, errRet = processResult{EgressID: fristHopConsEgress, OutConn: c, OutPkt: rawPkt}, nil
			fold pr.Mem()
			package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {
				unfold pr.Mem()
			}
			return 
		}
		
		// TODO parameter problem invalid interface // (tlino) original scion comment
		// (tlino) use getter to simplify verification
		// return processResult{}, serrors.WithCtx(cannotRoute, "type", "ohp",
		// 	"egress", p.FirstHop.ConsEgress, "consDir", p.Info.ConsDir)

		pr, errRet = processResult{}, serrors.WithCtx(cannotRoute(), "type", "ohp",
			"egress", p.GetFristHopConsEgress(), "consDir", p.GetConsDir())

		fold pr.Mem()
		fold s.Mem()
		ghost s.getRawPktAccWithoutPreservePath(rawPkt)
		return 
	}

	// (tlino) outlined the rest of the method
	fold s.Mem()
	pr, errRet = d.processOHP2(ingressID, rawPkt, s, buffer, p)
	return
}

// (tlino) Verified
// (tlino) added method to simplify verification
// (tlino) we cannot prove termination of this method, since d.resolveLocalDst() might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
requires ingressID >= 0
requires s.Mem() && s.getRawPkt() == rawPkt
requires p != nil && p == s.getOHPPath() 
preserves buffer.Mem()
preserves cap(rawPkt) == bufSize
ensures pr.Mem()
ensures errRet == nil ==> pr.Mem() --* verifyutils.BytesAcc(rawPkt)
ensures errRet != nil ==> verifyutils.BytesAcc(rawPkt)
func (d *DataPlane) processOHP2(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	buffer gopacket.SerializeBuffer, p *onehop.Path) (pr processResult, errRet error) {

	// (tlino) get access to p.Mem()
	unfold s.Mem()
	assert p.Mem()

	// (tlino) use setter function to avoid unfolding p
	// (tlino) macFactory isn't supported, usse dummy MAC instead
	// (tlino) the dummyMac function has slithly different arguments then the
	// (tlino) real one, but it also requieres read permission to p
	// OHP entering our IA
	// p.SecondHop = path.HopField{
	// 	ConsIngress: ingressID,
	// 	ExpTime:     p.FirstHop.ExpTime,
	// }
	// p.SecondHop.Mac = path.MAC(d.macFactory(), &p.Info, &p.SecondHop)
	secondHop := path.HopField{
		ConsIngress: ingressID,
		ExpTime:     p.GetFirstHopExpTime(),
	}
	secondHop.Mac = d.getDummyMac(p)
	p.SetSecondHop(secondHop)

	fold s.Mem()
	if err := updateSCIONLayer(rawPkt, s, buffer); err != nil {
		// (tlino) original code, adapted code is below
		// return processResult{}, err
		pr, errRet = processResult{}, err
		fold pr.Mem()
		ghost s.getRawPktAccWithoutPreservePath(rawPkt)
		return 
	}
	
	a, err := d.resolveLocalDst(s)
	if err != nil {
		// (tlino) original code, adapted code is below
		// return processResult{}, err
		pr, errRet = processResult{}, err
		fold pr.Mem()
		ghost s.getRawPktAccWithoutPreservePath(rawPkt)
		return
	}
	// (tlino) original code, adapted code is below
	// return processResult{OutConn: d.internal, OutAddr: a, OutPkt: rawPkt}, nil
	// (tlino) get access to rawPkt
	ghost s.getRawPktAccWithoutPreservePath(rawPkt)
	assert verifyutils.BytesAcc(rawPkt)
	unfold acc(DataPlaneMutexInvariant(d), _)
	pr, errRet = processResult{OutConn: d.getInternal(), OutAddr: a, OutPkt: rawPkt, AddrSrc: AddrFromPacketBytes}, nil
	fold pr.Mem()
	package pr.Mem() --* verifyutils.BytesAcc(rawPkt) {
		unfold pr.Mem()
	}
	return
}

// (tlino) Verified
// (tlino) res contains a subslice of s.rawPkt
// (tlino) This method doesn't establish res.Mem(), since the caller embedds res
// (tlino) in a processResult together with the rawPkt.
// (tlino) we cannot prove termination of this method, since  d.svc.Any() might not terminate
requires acc(DataPlaneMutexInvariant(d), _)
requires unfolding acc(DataPlaneMutexInvariant(d), _) in d.svc != nil
preserves acc(s.Mem(), 1/100)
// (tlino) use *slayers.SCION instead of slayers.SCION
// func (d *DataPlane) resolveLocalDst(s slayers.SCION) (net.Addr, error)
func (d *DataPlane) resolveLocalDst(s *slayers.SCION) (res net.Addr, errRet error) {
	// (joao) DstAddr expects a *SCION, not a SCION. Gobra does not support this
	dst, err := s.DstAddr()
	if err != nil {
		// TODO parameter problem. // (joao) this is an original comment from SCION
		return nil, invalidDstAddr()
	}
	assert acc(dst.Mem(), 1/200)
	if v, ok := dst.(addr.HostSVC); ok {
		// For map lookup use the Base address, i.e. strip the multi cast // (tlino) original scion comment
		// information, because we only register base addresses in the map. // (tlino) original scion comment
		unfold acc(DataPlaneMutexInvariant(d), _)
		ghost s.AddReadDstAddr(dst)
		a, ok := d.svc.Any(v.Base())
		if !ok {
			// (tlino) globals are not supported
			// return nil, noSVCBackend
			return nil, noSVCBackend()
		}
		return a, nil
	}
	res = addEndhostPort(dst)
	ghost s.AddReadDstAddr(dst)
	return res, nil
}

// (tlino) Verified
// (tlino) This method may not establish ret.Mem()
preserves acc(dst.Mem(), 1/200)
decreases
func addEndhostPort(dst net.Addr) (ret net.Addr) {
	if ip, ok := dst.(*net.IPAddr); ok {
		unfold acc(ip.Mem(), 1/200)
		ret := &net.UDPAddr{IP: ip.IP, Port: topology.EndhostPort}
		fold acc(ip.Mem(), 1/200)
		return ret
	}
	ret := dst
	return dst
}

// (tlino) Verified
preserves s.Mem() && buffer.Mem()
preserves rawPkt == s.getRawPkt()
ensures s.getRawPkt() == old(s.getRawPkt()) && s.getRawScionPath() == old(s.getRawScionPath()) && s.getOHPPath() == old(s.getOHPPath())
decreases
// (tlino) use *slayers.SCION instead of slayers.SCION
// func updateSCIONLayer(rawPkt []byte, s slayers.SCION, buffer gopacket.SerializeBuffer) error {
func updateSCIONLayer(rawPkt []byte, s *slayers.SCION, buffer gopacket.SerializeBuffer) (err error) {
	if err := buffer.Clear(); err != nil {
		return err
	}
	if err := s.SerializeTo(buffer, gopacket.SerializeOptions{}); err != nil {
		return err
	}
	// TODO(lukedirtwalker): We should add a method to the scion layers
	// which can write into the existing buffer, see also the discussion in
	// https://fsnets.slack.com/archives/C8ADBBG0J/p1592805884250700
	
	// (tlino) obtain access to rawPkt
	ghost s.getRawPktAcc(rawPkt)
	assert verifyutils.BytesAcc(rawPkt) --* (s.Mem() && rawPkt == s.getRawPkt() && s.getRawScionPath() == old(s.getRawScionPath()) && s.getOHPPath() == old(s.getOHPPath()))
	unfold verifyutils.BytesAcc(rawPkt)

	rawContents := buffer.Bytes()
	assert verifyutils.BytesAcc(rawContents) --* buffer.Mem()
	unfold verifyutils.BytesAcc(rawContents)
	// (tlino) use Gobra's copy
	// copy(rawPkt[:len(rawContents)], rawContents)

	// rawContents cannot have a higher length than rawPkt, since it only contains the SCION fields without the payload
	assume len(rawContents) <= len(rawPkt)
	assert forall i int :: { rawContents[i] } (0 <= i && i < len(rawContents)) ==> acc(&rawContents[i], 1/100000)
	assert forall i int :: { rawPkt[i] } (0 <= i && i < len(rawPkt)) ==> acc(&rawPkt[i])
	assert forall i int :: 0 <= i && i < len(rawContents) ==> &(rawPkt[:len(rawContents)])[i] == &rawPkt[i]
	assert forall i int :: 0 <= i && i < len(rawContents) ==> acc(&(rawPkt[:len(rawContents)])[i])

	verifyutils.OutlineMemorySafeCopy(rawPkt[:len(rawContents)], rawContents)

	fold verifyutils.BytesAcc(rawPkt)
	apply verifyutils.BytesAcc(rawPkt) --* (s.Mem() && rawPkt == s.getRawPkt() && s.getRawScionPath() == old(s.getRawScionPath()) && s.getOHPPath() == old(s.getOHPPath()))

	fold verifyutils.BytesAcc(rawContents)
	apply verifyutils.BytesAcc(rawContents) --* buffer.Mem()

	return nil
}

// (tlino) This type is used in the BFD protocol implementation.
// (tlino) The BFD session as an independant component.
// (tlino) At the moment we only verify the dataplane.
type bfdSend struct {
	conn             BatchConn
	srcAddr, dstAddr *net.UDPAddr
	srcIA, dstIA     addr.IA
//	macFactory       func() hash.Hash
	ifID             uint16
}

// (tlino) Function used in the BFD protocol implementation.
//pure func (b *bfdSend) String() string {
//	return b.srcAddr.String()
//}

// (tlino) Function used in the BFD protocol implementation.
//func (b *bfdSend) Send(bfd *layers.BFD) error {
//	scn := &slayers.SCION{
//		Version:      0,
//		TrafficClass: 0xb8,
//		FlowID:       0xdead,
//		NextHdr:      common.L4BFD,
//		SrcIA:        b.srcIA,
//		DstIA:        b.dstIA,
//	}
//
//	if err := scn.SetSrcAddr(&net.IPAddr{IP: b.srcAddr.IP}); err != nil {
//		return err
//	}
//	if err := scn.SetDstAddr(&net.IPAddr{IP: b.dstAddr.IP}); err != nil {
//		return err
//	}
//
//	if b.ifID == 0 {
//		scn.PathType = slayers.PathTypeEmpty
//		scn.Path = &empty.Path{}
//	} else {
//		ohp := &onehop.Path{
//			Info: path.InfoField{
//				ConsDir: true,
//				// Subtract 10 seconds to deal with possible clock drift.
//				Timestamp: uint32(time.Now().Unix() - 10),
//			},
//			FirstHop: path.HopField{
//				ConsEgress: b.ifID,
//				ExpTime:    hopFieldDefaultExpTime,
//			},
//		}
//		ohp.FirstHop.Mac = path.MAC(b.macFactory(), &ohp.Info, &ohp.FirstHop)
//		scn.PathType = slayers.PathTypeOneHop
//		scn.Path = ohp
//	}
//
//	buffer := gopacket.NewSerializeBuffer()
//	err := gopacket.SerializeLayers(buffer, gopacket.SerializeOptions{FixLengths: true},
//		scn, bfd)
//	if err != nil {
//		return err
//	}
//	msg := ipv4.Message{}
//	msg.Buffers = make([][]byte, 1)
//	raw := buffer.Bytes()
//	msg.Buffers[0] = make([]byte, len(raw))
//	copy(msg.Buffers[0], raw)
//	msg.N = len(raw)
//	msg.Addr = b.dstAddr
//	_, err = b.conn.WriteBatch(underlayconn.Messages{msg})
//	return err
//}

// (tlino) This interface is never used
//type pathUpdater interface {
//	update(p *scion.Raw) error
//}

type scmpPacker struct {
	internalIP net.IP
	localIA    addr.IA
	origPacket []byte
	ingressID  uint16

	scionL *slayers.SCION
	buffer gopacket.SerializeBuffer
	quote  []byte
}

// (tlino) For the moment we don't verify this method, since it is hard to verify,
// (tlino) and it's implementation significantly changed in the mean time in the original scion repo.
// (tlino) Unfortunatly, we cannot just easy merge the most current implementation in our VerifiedScion code base,
// (tlino) since this would require to adapt other structs and methods too.
requires scmpH.Mem() && scmpP.Mem()
preserves s.scionL.Mem() && s.buffer.Mem()
preserves verifyutils.BytesAcc(s.origPacket)
ensures s.scionL == old(s.scionL)
ensures s.scionL.getRawScionPath() == old(s.scionL.getRawScionPath())
ensures s.scionL.getRawPkt() == old(s.scionL.getRawPkt())
ensures b != nil ==> verifyutils.BytesAcc(b)
ensures e != nil
decreases _
func (s scmpPacker) prepareSCMP(scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer, 
	incPath bool, cause error) (b []byte, e error) //{

// 	// We use the original packet but put the already updated path, because usually a router will
// 	// not keep a copy of the original/unmodified packet around.
// 	pathRaw := s.scionL.Path.(*scion.Raw).Raw

// 	if err := s.scionL.DecodeFromBytes(s.origPacket, gopacket.NilDecodeFeedback); err != nil {
// 		panic(err)
// 	}
// 	path := s.scionL.Path.(*scion.Raw)

// 	path.Raw = pathRaw
// 	decPath, err := path.ToDecoded()
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "decoding raw path")
// 	}
// 	s.scionL.Path = decPath
// 	if err := decPath.Reverse(); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "reversing path for SCMP")
// 	}
// 	if incPath || decPath.IsXover() {
// 		infoField := decPath.InfoFields[decPath.PathMeta.CurrINF]
// 		if infoField.ConsDir {
// 			hopField := decPath.HopFields[decPath.PathMeta.CurrHF]
// 			infoField.UpdateSegID(hopField.Mac)
// 		}
// 		if err := decPath.IncPath(); err != nil {
// 			return nil, serrors.Wrap(cannotRoute, err, "details", "incrementing path for SCMP")
// 		}
// 	}

// 	s.scionL.DstIA = s.scionL.SrcIA
// 	s.scionL.SrcIA = s.localIA
// 	srcA, err := s.scionL.SrcAddr()
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "extracting src addr")
// 	}
// 	if err := s.scionL.SetDstAddr(srcA); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "setting dest addr")
// 	}
// 	if err := s.scionL.SetSrcAddr(&net.IPAddr{IP: s.internalIP}); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "setting src addr")
// 	}
// 	s.scionL.NextHdr = common.L4SCMP

// 	scmpH.SetNetworkLayerForChecksum(s.scionL)

// 	if err := s.buffer.Clear(); err != nil {
// 		return nil, err
// 	}

// 	sopts := gopacket.SerializeOptions{
// 		ComputeChecksums: true,
// 		FixLengths:       true,
// 	}
// 	scmpLayers := []gopacket.SerializableLayer{s.scionL, scmpH, scmpP}
// 	if cause != nil {
// 		// add quote for errors.
// 		hdrLen := slayers.CmnHdrLen + s.scionL.AddrHdrLen() + s.scionL.Path.Len()
// 		switch scmpH.TypeCode.Type() {
// 		case slayers.SCMPTypeExternalInterfaceDown:
// 			hdrLen += 20
// 		case slayers.SCMPTypeInternalConnectivityDown:
// 			hdrLen += 28
// 		default:
// 			hdrLen += 8
// 		}
// 		maxQuoteLen := slayers.MaxSCMPPacketLen - hdrLen
// 		if len(s.quote) > maxQuoteLen {
// 			s.quote = s.quote[:maxQuoteLen]
// 		}
// 		scmpLayers = append(scmpLayers, gopacket.Payload(s.quote))
// 	}
// 	err = gopacket.SerializeLayers(s.buffer, sopts, scmpLayers...)
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "serializing SCMP message")
// 	}
// 	return s.buffer.Bytes(), scmpError{TypeCode: scmpH.TypeCode, Cause: cause}	
// }

// (tlino) This type is never used
type segIDUpdater struct{}

// (tlino) This function is never used
//func (segIDUpdater) update(p *scion.Raw) error {
//	cHF, err := p.GetCurrentHopField()
//	if err != nil {
//		return err
//	}
//	cIF, err := p.GetCurrentInfoField()
//	if err != nil {
//		return err
//	}
//	cIF.UpdateSegID(cHF.Mac)
//	return nil
//}

// (tlino) This type is never used
type pathIncrementer struct{}

// (tlino) This function is never used
//func (pathIncrementer) update(p *scion.Raw) error {
//	return p.IncPath()
//}

// (tlino) Verified
requires neighbors != nil ==> acc(neighbors, _)
requires id >= 0
ensures acc(res)
decreases
func interfaceToMetricLabels(id uint16, localIA addr.IA,
	neighbors map[uint16]addr.IA) (res prometheus.Labels) {

	if id == 0 {
		return prometheus.Labels{
			"isd_as":          localIA.String(),
			"interface":       "internal",
			"neighbor_isd_as": localIA.String(),
		}
	}
	return prometheus.Labels{
		"isd_as":          localIA.String(),
		"interface":       strconv.FormatUint(uint64(id), 10),
		"neighbor_isd_as": neighbors[id].String(),
	}
}

// (tlino) Verified
ensures acc(res)
decreases
func serviceMetricLabels(localIA addr.IA, svc addr.HostSVC) (res prometheus.Labels) {
	return prometheus.Labels{
		"isd_as":  localIA.String(),
		"service": svc.BaseString(),
	}
}