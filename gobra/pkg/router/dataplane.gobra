// Copyright 2020 Anapaya Systems
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package router

import (
	// "bytes"
	// "crypto/rand"
	// "errors"
	// "fmt"
	// "hash"
	// "math/big"
	"net"
	"strconv"
	"sync"
	"time"

	// "github.com/google/gopacket"
	"gobra/dependencies/gopacket"
	// "github.com/google/gopacket/layers"
	"gobra/dependencies/gopacket/layers"
	// "github.com/prometheus/client_golang/prometheus"
	// "golang.org/x/net/ipv4"

	// "github.com/scionproto/scion/go/lib/addr"
	"gobra/lib/addr"
	// "github.com/scionproto/scion/go/lib/common"
	"gobra/lib/common"
	// "github.com/scionproto/scion/go/lib/log"
	// "github.com/scionproto/scion/go/lib/metrics"
	// "github.com/scionproto/scion/go/lib/scrypto"
	// "github.com/scionproto/scion/go/lib/serrors"
	"gobra/lib/serrors"
	// "github.com/scionproto/scion/go/lib/slayers"
	"gobra/lib/slayers"
	// "github.com/scionproto/scion/go/lib/slayers/path"
	"gobra/lib/slayers/path"
	// "github.com/scionproto/scion/go/lib/slayers/path/empty"
	"gobra/lib/slayers/path/empty"
	// "github.com/scionproto/scion/go/lib/slayers/path/onehop"
	"gobra/lib/slayers/path/onehop"
	// "github.com/scionproto/scion/go/lib/slayers/path/scion"
	"gobra/lib/slayers/path/scion"
	// "github.com/scionproto/scion/go/lib/topology"
	"gobra/lib/topology"
	// "github.com/scionproto/scion/go/lib/underlay/conn"
	"gobra/lib/underlay/conn"
	// underlayconn "github.com/scionproto/scion/go/lib/underlay/conn"
	underlayconn "gobra/lib/underlay/conn"
	// "github.com/scionproto/scion/go/lib/util"
	"gobra/lib/util"
	// "github.com/scionproto/scion/go/pkg/router/bfd"
	"gobra/pkg/router/bfd"
	// "github.com/scionproto/scion/go/pkg/router/control"
	"gobra/pkg/router/control"

	"gobra/verifyutils"
)

const (
	// Number of packets to read in a single ReadBatch call.
	inputBatchCnt = 64

	// TODO(karampok). Investigate whether that value should be higher.  In
	// theory, PayloadLen in SCION header is 16 bits long, supporting a maximum
	// payload size of 64KB. At the moment we are limited by Ethernet size
	// usually ~1500B, but 9000B to support jumbo frames.
	bufSize = 9000

	// hopFieldDefaultExpTime is the default validity of the hop field
	// and 63 is equivalent to 6h.
	hopFieldDefaultExpTime = 63
)

type bfdSession interface {
	pred Mem()

	requires Mem()
	Run() (err error)

	requires acc(Mem(), _)
	ensures  acc(c.SendChannel(), _) && c.SendGivenPerm() == (*layers.BFD).Mem!<_!>;
	decreases
	Messages() (c chan<- *layers.BFD)

	requires acc(Mem(), 1/1000)
	decreases
	IsUp() bool
}

// BatchConn is a connection that supports batch reads and writes.
type BatchConn interface {
	pred Mem()

	preserves Mem()
	preserves msgs.Mem()
	preserves forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
	ensures err == nil ==> 0 <= n && n <= len(msgs) && n <= len(metas)
	ReadBatch(msgs underlayconn.Messages, metas []underlayconn.ReadMeta) (n int, err error)

	preserves Mem()
	preserves acc(msgs.Mem(), 1/1000)
	ensures err == nil ==> 0 <= n && n <= len(msgs)
	WriteBatch(msgs underlayconn.Messages) (n int, err error)

	requires Mem()
	Close() error
}

// DataPlane contains a SCION Border Router's forwarding logic. It reads packets
// from multiple sockets, performs routing, and sends them to their destinations
// (after updating the path, if that is needed).
//
// XXX(lukedirtwalker): this is still in development and not feature complete.
// Currently, only the following features are supported:
//  - initializing connections; MUST be done prior to calling Run
type DataPlane struct {
	external         map[uint16]BatchConn
	linkTypes        map[uint16]topology.LinkType
	neighborIAs      map[uint16]addr.IA
	internal         BatchConn
	internalIP       net.IP
	internalNextHops map[uint16]net.Addr
//	svc              *services
//	macFactory       func() hash.Hash
	bfdSessions      map[uint16]bfdSession
	localIA          addr.IA
	mtx              sync.Mutex
	running          bool
//	Metrics          *Metrics
}

pred DataPlaneMutexInvariant(d *DataPlane) {
	// access to mtx field ommited
	acc(&d.external) &&
	acc(&d.linkTypes) &&
	acc(&d.neighborIAs) &&
	acc(&d.internal) &&
	acc(&d.internalIP) &&
	acc(&d.internalNextHops) &&
	acc(&d.bfdSessions) &&
	acc(&d.localIA) &&
	acc(&d.running) &&
	(d.external != nil ==> acc(d.external)) &&
	(d.linkTypes != nil ==> acc(d.linkTypes)) &&
	(d.neighborIAs != nil ==> acc(d.neighborIAs)) &&
	(d.internalNextHops != nil ==> acc(d.internalNextHops)) &&
	(d.bfdSessions != nil ==> acc(d.bfdSessions)) &&
	(forall bfd bfdSession :: bfd in range(d.bfdSessions) ==> bfd.Mem())
}

ghost
ensures DataPlaneMutexInvariant(res)
decreases
func soundDataPlaneMutexInvariant() (res *DataPlane) {
	d@ := DataPlane{}
	res = &d
	fold DataPlaneMutexInvariant(res)
}

//var (
//	alreadySet                    = serrors.New("already set")
//	cannotRoute                   = serrors.New("cannot route, dropping pkt")
//	emptyValue                    = serrors.New("empty value")
//	malformedPath                 = serrors.New("malformed path content")
//	modifyExisting                = serrors.New("modifying a running dataplane is not allowed")
//	noSVCBackend                  = serrors.New("cannot find internal IP for the SVC")
//	unsupportedPathType           = serrors.New("unsupported path type")
//	unsupportedPathTypeNextHeader = serrors.New("unsupported combination")
//	noBFDSessionFound             = serrors.New("no BFD sessions was found")
//	noBFDSessionConfigured        = serrors.New("no BFD sessions have been configured")
//	errBFDDisabled                = serrors.New("BFD is disabled")
//)

/** Globals **/
// (joao): begin alternative to final global variables defined in the previous var block
ensures e != nil
decreases
func alreadySet() (e error) { return serrors.New("already set") }

ensures e != nil
decreases
func cannotRoute() (e error) { return serrors.New("cannot route, dropping pkt") }

ensures e != nil
decreases
func emptyValue() (e error) { return serrors.New("empty value") }

ensures e != nil
decreases
func malformedPath() (e error) { return serrors.New("malformed path content") }

ensures e != nil
decreases
func modifyExisting() (e error) { return serrors.New("modifying a running dataplane is not allowed") }

ensures e != nil
decreases
func noSVCBackend() (e error) { return serrors.New("cannot find internal IP for the SVC") }

ensures e != nil
decreases
func unsupportedPathType() (e error) { return serrors.New("unsupported path type") }

ensures e != nil
decreases
func unsupportedPathTypeNextHeader() (e error) { return serrors.New("unsupported combination") }

ensures e != nil
decreases
func noBFDSessionFound() (e error) { return serrors.New("no BFD sessions was found") }

ensures e != nil
decreases
func noBFDSessionConfigured() (e error) { return serrors.New("no BFD sessions have been configured") }

ensures e != nil
decreases
func errBFDDisabled() (e error) { return serrors.New("BFD is disabled") }
/** End of Globals **/

type scmpError struct {
	TypeCode slayers.SCMPTypeCode
	Cause    error
}

decreases
func (e scmpError) Error() string {
	return (serrors.New("scmp", "typecode", e.TypeCode, "cause", e.Cause)).Error()
}

// (joao) Verified
// SetIA sets the local IA for the dataplane.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) SetIA(ia addr.IA) error {
	d.mtx.Lock()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if ia.IsZero() {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	if !d.localIA.IsZero() {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return alreadySet
		return alreadySet()
	}
	d.localIA = ia
	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Partially Verified
// SetKey sets the key used for MAC verification. The key provided here should
// already be derived as in scrypto.HFMacFactory.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) SetKey(key []byte) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if len(key) == 0 {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) macFactory still not supported
	// if d.macFactory != nil {
	// 	return alreadySet
	// }
	// // First check for MAC creation errors.
	// if _, err := scrypto.InitMac(key); err != nil {
	// 	return err
	// }
	// d.macFactory = func() hash.Hash {
	// 	mac, _ := scrypto.InitMac(key)
	// return mac
	// }

	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddInternalInterface sets the interface the data-plane will use to
// send/receive traffic in the local AS. This can only be called once; future
// calls will return an error. This can only be called on a not yet running
// dataplane.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) AddInternalInterface(conn BatchConn, ip net.IP) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	if d.internal != nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return alreadySet
		return alreadySet()
	}
	d.internal = conn
	d.internalIP = ip
	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddExternalInterface adds the inter AS connection for the given interface ID.
// If a connection for the given ID is already set this method will return an
// error. This can only be called on a not yet running dataplane.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) AddExternalInterface(ifID uint16, conn BatchConn) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) no support for defer
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code:
	// if _, exists := d.external[ifID]; exists {
	// 		return serrors.WithCtx(alreadySet, "ifID", ifID)
	if _, exists := (d.external)[ifID]; exists {
		// (joao) no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.external == nil {
		d.external = make(map[uint16]BatchConn)
	}
	// (joao) add parentheses surrounding `d.external` to make it parse
 	(d.external)[ifID] = conn
	// (joao) no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddNeighborIA adds the neighboring IA for a given interface ID. If an IA for
// the given ID is already set, this method will return an error. This can only
// be called on a yet running dataplane.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) AddNeighborIA(ifID uint16, remote addr.IA) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// (joao) defer not supported
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return modifyExisting
		return modifyExisting()
	}
	if remote.IsZero() {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// (joao) no support for global variables
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code (changed below):
	// if _, exists := d.neighborIAs[ifID]; exists {
	// 	return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	if _, exists := (d.neighborIAs)[ifID]; exists {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.neighborIAs == nil {
		d.neighborIAs = make(map[uint16]addr.IA)
	}
	// (joao) add parentheses surrounding `d.neighborIAs` to make it parse
	(d.neighborIAs)[ifID] = remote
	// (joao) Unlock explictly added, no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Verified
// AddLinkType adds the link type for a given interface ID. If a link type for
// the given ID is already set, this method will return an error. This can only
// be called on a not yet running dataplane.
requires DataPlaneMutexInvariant(d)
ensures DataPlaneMutexInvariant(d)
func (d *DataPlane) AddLinkType(ifID uint16, linkTo topology.LinkType) error {
	// (joao) original code (changed below):
	// if _, exists := d.linkTypes[ifID]; exists {
	// 	return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	unfold DataPlaneMutexInvariant(d)
	if _, exists := (d.linkTypes)[ifID]; exists {
		fold DataPlaneMutexInvariant(d)
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.linkTypes == nil {
		d.linkTypes = make(map[uint16]topology.LinkType)
	}
	// (joao) added parentheses around d.linkTypes to make it parse
	(d.linkTypes)[ifID] = linkTo
	fold DataPlaneMutexInvariant(d)
	return nil
}

// (joao) Partially Verified
// AddExternalInterfaceBFD adds the inter AS connection BFD session.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) AddExternalInterfaceBFD(ifID uint16, conn BatchConn,
	src, dst control.LinkEnd, cfg control.BFD) error {
	d.mtx.Lock()
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}
	if conn == nil {
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	// var m bfd.Metrics
	// if d.Metrics != nil {
	// 	labels := []string{
	//		"interface", fmt.Sprint(ifID),
	//		"isd_as", d.localIA.String(),
	//		"neighbor_isd_as", dst.IA.String(),
	// 	}
	//	m = bfd.Metrics{
	//		Up: metrics.NewPromGauge(d.Metrics.InterfaceUp).
	//			With(labels...),
	//		StateChanges: metrics.NewPromCounter(d.Metrics.BFDInterfaceStateChanges).
	//			With(labels...),
	//		PacketsSent: metrics.NewPromCounter(d.Metrics.BFDPacketsSent).
	//			With(labels...),
	//		PacketsReceived: metrics.NewPromCounter(d.Metrics.BFDPacketsReceived).
	//			With(labels...),
	//	}
	// }
	s := &bfdSend{
		conn:       conn,
		// srcAddr:    src.Addr,
		// dstAddr:    dst.Addr,
		srcIA:      src.IA,
		dstIA:      dst.IA,
		ifID:       ifID,
		// macFactory: d.macFactory,
	}
	// (joao) rewrote to unfold before returning. Original code:
	// return d.addBFDController(ifID, s, cfg, m)
	// changed code:
	fold DataPlaneMutexInvariant(d)
	res := d.addBFDController(ifID, s, cfg /*, m */)
	unfold DataPlaneMutexInvariant(d)
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return res
}

// (joao) Partially Verified
// TODO: specify `rand`
requires DataPlaneMutexInvariant(d)
ensures DataPlaneMutexInvariant(d)
func (d *DataPlane) addBFDController(ifID uint16, s *bfdSend, cfg control.BFD,
	/* metrics bfd.Metrics */) error {
	unfold DataPlaneMutexInvariant(d)
	if cfg.Disable {
		fold DataPlaneMutexInvariant(d)
		// return errBFDDisabled
		return errBFDDisabled()
	}
	if d.bfdSessions == nil {
		d.bfdSessions = make(map[uint16]bfdSession)
	}

	// // Generate random discriminator. It can't be zero.
	// discInt, err := rand.Int(rand.Reader, big.NewInt(0xfffffffe))
	// if err != nil {
	// 	return err
	// }
	// disc := layers.BFDDiscriminator(uint32(discInt.Uint64()) + 1)
	// d.bfdSessions[ifID] = &bfd.Session{
	// 	Sender:                s,
	// 	DetectMult:            layers.BFDDetectMultiplier(cfg.DetectMult),
	// 	Logger:                log.New("component", "BFD"),
	// 	DesiredMinTxInterval:  cfg.DesiredMinTxInterval,
	// 	RequiredMinRxInterval: cfg.RequiredMinRxInterval,
	// 	LocalDiscriminator:    disc,
	// 	ReceiveQueueSize:      10,
	// 	Metrics:               metrics,
	// }
	fold DataPlaneMutexInvariant(d)
	return nil
}

// (joao) Partially Verified
// AddSvc adds the address for the given service. This can be called multiple
// times for the same service, with the address added to the list of addresses
// that provide the service.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) AddSvc(svc addr.HostSVC, a *net.UDPAddr) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// defer d.mtx.Unlock()
	if a == nil {
		// return emptyValue
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return emptyValue()
	}
	// if d.svc == nil {
	// 	d.svc = newServices()
	// }
	// d.svc.AddSvc(svc, a)
	// if d.Metrics != nil {
	// 	labels := serviceMetricLabels(d.localIA, svc)
	// 	d.Metrics.ServiceInstanceChanges.With(labels).Add(1)
	// 	d.Metrics.ServiceInstanceCount.With(labels).Add(1)
	// }
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Partially Verified
// DelSvc deletes the address for the given service.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) DelSvc(svc addr.HostSVC, a *net.UDPAddr) error {
	d.mtx.Lock()
	// defer d.mtx.Unlock()
	if a == nil {
		// return emptyValue
		return emptyValue()
	}
	// if d.svc == nil {
	// 	return nil
	// }
	// d.svc.DelSvc(svc, a)
	// if d.Metrics != nil {
	// 	labels := serviceMetricLabels(d.localIA, svc)
	// 	d.Metrics.ServiceInstanceChanges.With(labels).Add(1)
	// 	d.Metrics.ServiceInstanceCount.With(labels).Add(-1)
	// }
	return nil
}

// (joao) Verified
// AddNextHop sets the next hop address for the given interface ID. If the
// interface ID already has an address associated this operation fails. This can
// only be called on a not yet running dataplane.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) AddNextHop(ifID uint16, a net.Addr) error {
	d.mtx.Lock()
	// (joao) defer not supported
	// defer d.mtx.Unlock()
	unfold DataPlaneMutexInvariant!<d!>()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}
	if a == nil {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}
	// (joao) original code (changed below):
	// if _, exists := d.internalNextHops[ifID]; exists {
	//	 return serrors.WithCtx(alreadySet, "ifID", ifID)
	// }
	if _, exists := (d.internalNextHops)[ifID]; exists {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		return serrors.WithCtx(alreadySet(), "ifID", ifID)
	}
	if d.internalNextHops == nil {
		d.internalNextHops = make(map[uint16]net.Addr)
	}
	// d.internalNextHops[ifID] = a
	(d.internalNextHops)[ifID] = a
	// (joao) Unlock explictly added, no support for defer
	fold DataPlaneMutexInvariant!<d!>()
	d.mtx.Unlock()
	return nil
}

// (joao) Partially Verified
// AddNextHopBFD adds the BFD session for the next hop address.
// If the remote ifID belongs to an existing address, the existing
// BFD session will be re-used.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
ensures acc(&d.mtx, _) && d.mtx.LockP()
func (d *DataPlane) AddNextHopBFD(ifID uint16, src, dst *net.UDPAddr, cfg control.BFD,
	sibling string) error {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	// defer d.mtx.Unlock()
	if d.running {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return modifyExisting
		return modifyExisting()
	}

	if dst == nil {
		// (joao) Unlock explictly added, no support for defer
		fold DataPlaneMutexInvariant!<d!>()
		d.mtx.Unlock()
		// return emptyValue
		return emptyValue()
	}

	assume false
	// (joao) the following code is still not supported
	/*
	for k, v := range d.internalNextHops {
		if v.String() == dst.String() {
			if c, ok := d.bfdSessions[k]; ok {
				d.bfdSessions[ifID] = c
				return nil
			}
		}
	}
	var m bfd.Metrics
	if d.Metrics != nil {
		labels := []string{"isd_as", d.localIA.String(), "sibling", sibling}
		m = bfd.Metrics{
			Up: metrics.NewPromGauge(d.Metrics.SiblingReachable).
				With(labels...),
			StateChanges: metrics.NewPromCounter(d.Metrics.SiblingBFDStateChanges).
				With(labels...),
			PacketsSent: metrics.NewPromCounter(d.Metrics.SiblingBFDPacketsSent).
				With(labels...),
			PacketsReceived: metrics.NewPromCounter(d.Metrics.SiblingBFDPacketsReceived).
				With(labels...),
		}
	}
	s := &bfdSend{
		conn:       d.internal,
		srcAddr:    src,
		dstAddr:    dst,
		srcIA:      d.localIA,
		dstIA:      d.localIA,
		ifID:       0,
		macFactory: d.macFactory,
	}
	return d.addBFDController(ifID, s, cfg, m)
	*/
}

// Run starts running the dataplane. Note that configuration is not possible
// after calling this method.
requires acc(&d.mtx, _) && d.mtx.LockP()
requires d.mtx.LockInv() == DataPlaneMutexInvariant!<d!>;
func (d *DataPlane) Run() error /* {
	d.mtx.Lock()
	unfold DataPlaneMutexInvariant!<d!>()
	d.running = true

	d.initMetrics()

	// (joao) At this point, there used to be a closure definition, saved in a variable called "read"

	for k, v := range d.bfdSessions {
		go func(ifID uint16, c bfdSession) {
			defer log.HandlePanic()
			if err := c.Run(); err != nil && err != bfd.AlreadyRunning {
				log.Error("BFD session failed to start", "ifID", ifID, "err", err)
			}
		}(k, v)
	}
	for ifID, v := range d.external {
		go func(i uint16, c BatchConn) {
			defer log.HandlePanic()
			read(i, c)
		}(ifID, v)
	}
	go func(c BatchConn) {
		defer log.HandlePanic()
		read(0, c)
	}(d.internal)
	
 	// (joao) This unlock here is problematic: it gives back access to the lock invariant, and thus, it should not
	//        be able to check the value of d.running. Instead, every thread running the closure should have a wildcard permission to
	//        the lock invariant.
	d.mtx.Unlock()
	for d.running {
		time.Sleep(time.Second)
	}
	return nil
}
*/

// (tlino) Verified
// (joao) Closure extracted from the body of the Run function
requires rd.Mem()
requires acc(DataPlaneMutexInvariant(d), _)
func RunReadClosure(ingressID uint16, rd BatchConn, d *DataPlane) {
	// (tlino) outlined code to separate function
	msgs, metas := initReadClosureBuffer()

	// (tlino) use pointer
	// var scmpErr scmpError
	scmpErr := &scmpError{}
	spkt := slayers.SCION{}
	buffer := gopacket.NewSerializeBuffer()
	origPacket := make([]byte, bufSize)

	// (tlino) change structure of loop
	// for d.running {
	
	// (tlino) added variable 
	isRunning := unfolding acc(DataPlaneMutexInvariant(d), _) in d.running

	invariant forall j int :: 0 <= j && j < len(metas) ==> (&metas[j]).Mem()
	invariant acc(DataPlaneMutexInvariant(d), _)
	invariant rd.Mem()
	invariant msgs.Mem()
	invariant acc(scmpErr)
	invariant isZeroSCION(spkt)
	invariant buffer.Mem()
	invariant forall j int :: 0 <= j && j < len(origPacket) ==> acc(&origPacket[j])
	for isRunning {
		pkts, err := rd.ReadBatch(msgs, metas)

		// (tlino) added
		isRunning = unfolding acc(DataPlaneMutexInvariant(d), _) in d.running

		// (tlino) continue not supported by gobra
		// adapted code is below
		// if err != nil {
		// 	log.Debug("Failed to read batch", "err", err)
		// 	// error metric
		// 	continue
		// }
		// if pkts == 0 {
		// 	continue
		// }

		if err != nil {
			// (tlino) log not supported yet
			// log.Debug("Failed to read batch", "err", err)
			// error metric
		} else if pkts > 0 {
			// (tlino) outlined code to separate function
			processBatch(ingressID, d, msgs, metas, pkts, origPacket, scmpErr, buffer, spkt)

			// (tlino) outlined code to separate function
			resetReadClosureBuffers(msgs, pkts)
		}
	}
}

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
ensures msgs.Mem()
ensures forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
func initReadClosureBuffer() (msgs underlayconn.Messages, metas []conn.ReadMeta) {
	msgs := conn.NewReadMessages(inputBatchCnt)
	unfold msgs.MemPartiallyInitialized()

	// (tlino) range not supported by Gobra
	// for _, msg := range msgs {
	// 		msg.Buffers[0] = make([]byte, bufSize)
	// }

	invariant 0 <= i && i <= len(msgs)
	invariant forall j int :: 0 <= j && j < i ==> (&msgs[j]).Mem()
	invariant forall j int :: i <= j && j < len(msgs) ==> (&msgs[j]).MemPartiallyInitialized()
	for i := 0; i < len(msgs); i++ {
		unfold (&msgs[i]).MemPartiallyInitialized()
		(msgs[i].Buffers)[0] = make([]byte, bufSize)
		fold (&msgs[i]).Mem()
	}
	fold msgs.Mem()

	metas := make([]conn.ReadMeta, inputBatchCnt)
	// (tlino) added loop to initialize metas
	invariant 0 <= i && i <= len(metas)
	invariant forall j int :: i <= j && j < len(metas) ==> acc(&metas[j]) && metas[j].Src == nil && metas[j].Local == nil
	invariant forall j int :: 0 <= j && j < i ==> (&metas[j]).Mem()
	for i := 0; i < len(metas); i++ {
		fold (&metas[i]).Mem()
	}
}

// (tlino) not verified yet
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
requires acc(DataPlaneMutexInvariant(d), _)
preserves msgs.Mem()
preserves forall i int :: 0 <= i && i < len(metas) ==> (&metas[i]).Mem()
requires 0 <= pkts && pkts <= len(msgs) && pkts <= len(metas)
preserves forall i int :: 0 <= i && i < len(origPacket) ==> acc(&origPacket[i])
preserves acc(scmpErr)
preserves buffer.Mem()
requires isZeroSCION(spkt)
ensures isZeroSCION(spkt)
func processBatch(ingressID uint16, d *DataPlane, msgs underlayconn.Messages, metas []underlayconn.ReadMeta, pkts int, 
	origPacket []byte, scmpErr *scmpError, buffer gopacket.SerializeBuffer, spkt slayers.SCION) //{
// 	unfold msgs.Mem()

// 	//(tlino) range not supported by Gobra
// 	// for _, p := range msgs[:pkts] {
// 	invariant 0 <= i && i <= pkts
// 	invariant forall j int :: 0 <= j && j < len(msgs) ==> (&msgs[j]).Mem()
// 	for i := 0; i < pkts; i++ {
// 		// added variable
// 		p := msgs[i]
// 		origPacket = origPacket[:p.N]
// 		// TODO(karampok). Use meta for sanity checks.

// 		// (tlino) added parentheses to make it parse
// 		// p.Buffers[0] = p.Buffers[0][:p.N]
// 		// copy(origPacket[:p.N], p.Buffers[0])

// 		unfold p.Mem()
// 		(p.Buffers)[0] = ((p.Buffers)[0])[:p.N]
// 		copy((origPacket)[:p.N], (p.Buffers)[0])
// 		fold p.Mem()

// 		// (tlino) ignore the logging stuff for now
// 		// input metric
// 		// inputLabels := interfaceToMetricLabels(ingressID, d.localIA, d.neighborIAs)
// 		// d.Metrics.InputPacketsTotal.With(inputLabels).Inc()
// 		// d.Metrics.InputBytesTotal.With(inputLabels).Add(float64(p.N))

// 		// (tlino) added parentheses to make it parse
// 		// result, err := d.processPkt(ingressID, (p.Buffers)[0], p.Addr, spkt, origPacket,
// 		//	buffer)

// 		result, err := d.processPkt(ingressID, (p.Buffers)[0], p.Addr, spkt, origPacket,
// 			buffer)

// 		switch {
// 		case err == nil:
// 		case errors.As(err, &scmpErr):
// 			if !scmpErr.TypeCode.InfoMsg() {
// 				log.Debug("SCMP", "err", scmpErr, "dst_addr", p.Addr)
// 			}
// 			// SCMP go back the way they came.
// 			result.OutAddr = p.Addr
// 			result.OutConn = rd
// 		default:
// 			log.Debug("Error processing packet", "err", err)

// 			// (tlino) ignore the logging stuff for now
// 			// d.Metrics.DroppedPacketsTotal.With(inputLabels).Inc()
// 			continue
// 		}
// 		if result.OutConn == nil { // e.g. BFD case no message is forwarded
// 			continue
// 		}
// 		_, err = result.OutConn.WriteBatch(underlayconn.Messages([]ipv4.Message{{
// 			Buffers: [][]byte{result.OutPkt},
// 			Addr:    result.OutAddr,
// 		}}))
// 		if err != nil {
// 			log.Debug("Error writing packet", "err", err)
// 			// error metric
// 			continue
// 		}

// 		// (tlino) ignore the logging stuff for now
// 		// ok metric
// 		// outputLabels := interfaceToMetricLabels(result.EgressID, d.localIA, d.neighborIAs)
// 		// d.Metrics.OutputPacketsTotal.With(outputLabels).Inc()
// 		// d.Metrics.OutputBytesTotal.With(outputLabels).Add(float64(len(result.OutPkt)))
// 	}
// }

// (tlino) Verified
// (tlino) added function to simplify verification
// (tlino) used to be part of the read closure
requires msgs.Mem()
requires 0 <= pkts && pkts <= len(msgs)
ensures msgs.Mem()
func resetReadClosureBuffers(msgs underlayconn.Messages, pkts int) {
	unfold msgs.Mem()

	// Reset buffers to original capacity.
	// (tlino) range no supported by Gobra
	// for _, p := range msgs[:pkts] {
	// 	p.Buffers[0] = p.Buffers[0][:bufSize]
	// }

	invariant 0 <= i && i <= pkts
	invariant forall j int :: 0 <= j && j < len(msgs) ==> (&msgs[j]).Mem()
	for i := 0; i < pkts; i++ {
		unfold (&msgs[i]).Mem()
		(msgs[i].Buffers)[0] = ((msgs[i].Buffers)[0])[:bufSize]
		fold (&msgs[i]).Mem()
	}
	fold msgs.Mem()
}


requires DataPlaneMutexInvariant(d)
ensures  DataPlaneMutexInvariant(d)
func (d *DataPlane) initMetrics() /* {
	labels := interfaceToMetricLabels(0, d.localIA, d.neighborIAs)
	d.Metrics.InputBytesTotal.With(labels).Add(0)
	d.Metrics.InputPacketsTotal.With(labels).Add(0)
	d.Metrics.OutputBytesTotal.With(labels).Add(0)
	d.Metrics.OutputPacketsTotal.With(labels).Add(0)
	d.Metrics.DroppedPacketsTotal.With(labels).Add(0)
	for id := range d.neighborIAs {
		if _, notOwned := d.internalNextHops[id]; notOwned {
			continue
		}
		labels = interfaceToMetricLabels(id, d.localIA, d.neighborIAs)
		d.Metrics.InputBytesTotal.With(labels).Add(0)
		d.Metrics.InputPacketsTotal.With(labels).Add(0)
		d.Metrics.OutputBytesTotal.With(labels).Add(0)
		d.Metrics.OutputPacketsTotal.With(labels).Add(0)
		d.Metrics.DroppedPacketsTotal.With(labels).Add(0)
	}
} */

type processResult struct {
	EgressID uint16
	OutConn  BatchConn
	OutAddr  net.Addr
	OutPkt   []byte
}

pred (pr processResult) Mem() {
	(pr.OutConn != nil ==> pr.OutConn.Mem()) &&
	(pr.OutAddr != nil ==> pr.OutAddr.Mem()) &&
	(pr.OutPkt != nil ==> verifyutils.BytesAcc(pr.OutPkt))
}

pure func isZeroSCION(s slayers.SCION) bool {
	return s.EmbeddedBaseLayer.Contents == nil &&
		s.EmbeddedBaseLayer.Payload == nil &&
		s.Version == 0 &&
		s.TrafficClass == 0 &&
		s.FlowID == 0 &&
		s.NextHdr == 0 &&
		s.HdrLen == 0 &&
		s.PayloadLen == 0 &&
		s.PathType == 0 &&
		s.DstAddrType == 0 &&
		s.DstAddrLen == 0 &&
		s.SrcAddrType == 0 &&
		s.SrcAddrLen == 0 &&
		s.DstIA.I == 0 &&
		s.DstIA.A == 0 &&
		s.SrcIA.I == 0 &&
		s.SrcIA.A == 0 &&
		s.RawDstAddr == nil &&
		s.RawSrcAddr  == nil &&
		s.Path == nil
}

// (tlino) TODO: reverify
requires acc(DataPlaneMutexInvariant(d), _)
requires isZeroSCION(s)
requires verifyutils.BytesAcc(rawPkt)
requires verifyutils.BytesAcc(origPacket)
requires cap(rawPkt) == bufSize
requires srcAddr.Mem()
requires buffer.Mem()
ensures isZeroSCION(s)
ensures verifyutils.BytesAcc(rawPkt)
ensures verifyutils.BytesAcc(origPacket)
ensures cap(rawPkt) == bufSize
ensures srcAddr.Mem()
ensures buffer.Mem()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
func (d *DataPlane) processPkt(ingressID uint16, rawPkt []byte, srcAddr net.Addr, s slayers.SCION,
	origPacket []byte, buffer gopacket.SerializeBuffer) (pr processResult, err error) //{
// 	// (joao) `s` should always have the zero value of slayers.SCION;
// 	// (joao) in the code, we use `s` where an *slayers.SCION is expected. In Go, this modifies `s` but in Gobra, that idiom is still not supported;
// 	// (joao) we use the following transformation - we check that s is always the zero value and we introduce a new shared variable `sNew` of type slayers.SCION{}
// 	//        that gets mutated
// 	sNew := &slayers.SCION{}

// 	fold (gopacket.NilDecodeFeedback{}).Mem()
// 	// (joao) Adapted to conform to changes in gopacket and sNew
// 	// if err := s.DecodeFromBytes(rawPkt, gopacket.NilDecodeFeedback); err != nil {
// 	if err := sNew.DecodeFromBytes(rawPkt, gopacket.NilDecodeFeedback{}); err != nil {
// 		return processResult{}, err
// 	}
	
// 	// (joao) already lost access to rawPkt here
// 	if err := buffer.Clear(); err != nil {
// 		return processResult{}, serrors.WrapStr("Failed to clear buffer", err)
// 	}

// 	// (tlino) use sNew.getPathType() instead of s
// 	// switch s.PathType {
	
// 	// assert false // doesn't verify
// 	switch sNew.getPathType() {
// 	case slayers.PathTypeEmpty:
// 		// (tlino) use sNew instead of s and use getters
// 		// if s.NextHdr == common.L4BFD {
// 		//	return processResult{}, d.processIntraBFD(srcAddr, s.Payload)
// 		// }
// 		if sNew.getNextHdr() == common.L4BFD {

// 			// add Here magic wand

// 			return processResult{}, d.processIntraBFD(srcAddr, sNew.Payload)
// 		}
// 		// (tlino) use sNew instead of s and use getters
// 		// return processResult{}, serrors.WithCtx(unsupportedPathTypeNextHeader,
// 		// 	"type", s.PathType, "header", s.NextHdr)
		
// 			// add Here magic wand

// 		return processResult{}, serrors.WithCtx(unsupportedPathTypeNextHeader(),
// 		 	"type", sNew.getPathType(), "header", sNew.getNextHdr())
// 	case slayers.PathTypeOneHop:
// 		// (tlino) use sNew instead of s and use getters
// 		// if s.NextHdr == common.L4BFD {
// 		if sNew.getNextHdr() == common.L4BFD {
// 			// (tlino) use sNew instead of s and use getters
// 			// ohp, ok := s.Path.(*onehop.Path)
// 			// if !ok {
// 			// 	return processResult{}, malformedPath
// 			// }
// 			// (tlino) use getter to return path and payload
// 			path, payload := sNew.GetPathAndPayload()
// 			// (tlino) use path instead of s.Path
// 			// ohp, ok := s.Path.(*onehop.Path)
// 			ohp, ok := path.(*onehop.Path)
// 			// (tlino) globals aren't supported yet
// 			// if !ok {
// 			// 	return processResult{}, malformedPath
// 			// }
// 			if !ok {
// 				return processResult{}, malformedPath()
// 			}
// 			// (tlino) use result from getter
// 			// return processResult{}, d.processInterBFD(ingressID, ohp, s.Payload)

// 			// add here magic wand

// 			return processResult{}, d.processInterBFD(ingressID, ohp, payload)
// 		}
// 		// (tlino) use sNew instead of s
// 		// return d.processOHP(ingressID, rawPkt, s, buffer)
// 		// assert forall i int :: 0 <= i && i < len(rawPkt) ==> acc(&rawPkt[i])

// 		// add here magic wand

// 		return d.processOHP(ingressID, rawPkt, sNew, buffer)
// 	case slayers.PathTypeSCION:
// 		assert acc(DataPlaneMutexInvariant(d), _)
// 		assert forall i int :: 0 <= i && i < len(origPacket) ==> acc(&origPacket[i])
// 		assert buffer.Mem()
// 		assert sNew.Mem()
// 		// return d.processSCION(ingressID, rawPkt, s, origPacket, buffer)
// 		// assert false //verified

// 		// add here magic wand

// 		return d.processSCION(ingressID, rawPkt, sNew, origPacket, buffer)
// 	default:
// 		// return processResult{}, serrors.WithCtx(unsupportedPathType, "type", s.PathType)

// 		// add here magic wand

// 		return processResult{}, serrors.WithCtx(unsupportedPathType(), "type", sNew.getPathType())
// 	}
// }

// (tlino) Verified
// (joao) `oh` is not used anywhere in the function
requires acc(DataPlaneMutexInvariant(d), _)
requires forall i int :: 0 <= i && i < len(data) ==> acc(&data[i])
decreases
func (d *DataPlane) processInterBFD(ingressID uint16, oh *onehop.Path, data []byte) error {
	unfold acc(DataPlaneMutexInvariant(d), _)
	if len(d.bfdSessions) == 0 {
		// (joao) no globals
		// return noBFDSessionConfigured
		return noBFDSessionConfigured()
	}

	p := &layers.BFD{}
	// (joao) TODO: gopacket.NilDecodeFeedback is a var in gopacket but Luca implemented as a type (should be changed).
	//              Code adapted below.
	//if err := p.DecodeFromBytes(data, gopacket.NilDecodeFeedback); err != nil {
	//	return err
	//}
	tmp := gopacket.NilDecodeFeedback{}
	fold tmp.Mem()
	if err := p.DecodeFromBytes(data, tmp); err != nil {
		return err
	}

	translateBFDMemPred(p)

	// (joao) add parentheses surrounding `d.bfdSessions`
	if v, ok := (d.bfdSessions)[ingressID]; ok {
		v.Messages() <- p
		return nil
	}

	// (joao) no globals
	// return noBFDSessionFound
	return noBFDSessionFound()
}

ghost
requires b.Mem()
ensures  (*layers.BFD).Mem!<_!>(b)
decreases
func translateBFDMemPred(b *layers.BFD) {
	unfold (*layers.BFD).Mem(b)
	fold (*layers.BFD).Mem!<_!>(b)
}

// (tlino) partially verified 
// depends on issue #341
preserves src.Mem()
requires forall i int :: 0 <= i && i < len(data) ==> acc(&data[i])
requires acc(DataPlaneMutexInvariant(d), _)
func (d *DataPlane) processIntraBFD(src net.Addr, data []byte) error {
	// (tlino) add unfolding
	// if len(d.bfdSessions) == 0 {
	// 	return noBFDSessionConfigured
	// }

	hasNoBFDSessions := unfolding acc(DataPlaneMutexInvariant(d), _) in len(d.bfdSessions) == 0
	if hasNoBFDSessions {
		// (tlino) golbals not supported
		// return noBFDSessionConfigured
		return noBFDSessionConfigured()
	}
	p := &layers.BFD{}

	// (tlino) TODO: gopacket.NilDecodeFeedback is a var in gopacket but Luca implemented as a type (should be changed).
	//              Code adapted below.
	// if err := p.DecodeFromBytes(data, gopacket.NilDecodeFeedback); err != nil {
	// 	return err
	// }

	tmp := gopacket.NilDecodeFeedback{}
	fold tmp.Mem()
	if err := p.DecodeFromBytes(data, tmp); err != nil {
		return err
	}

	translateBFDMemPred(p)

// 	ifID := uint16(0)
// 	srcUDPAddr, ok := src.(*net.UDPAddr)
// 	if !ok {
// 		// (joao) No support for fmt
// 		// return serrors.New("type assertion failure", "from", fmt.Sprintf("%v(%T)", src, src),
// 		//	"expected", "*net.IPAddr")
// 		return serrors.New("error") // (joao) TODO: remove after adding support for fmt
// 	}
// //
// //	for k, v := range d.internalNextHops {
// //		remoteUDPAddr, ok := v.(*net.UDPAddr)
// //		if !ok {
// //			return serrors.New("type assertion failure", "from",
// //				fmt.Sprintf("%v(%T)", remoteUDPAddr, remoteUDPAddr), "expected", "*net.UDPAddr")
// //		}
// //		if bytes.Equal(remoteUDPAddr.IP, srcUDPAddr.IP) && remoteUDPAddr.Port == srcUDPAddr.Port {
// //			ifID = k
// //			continue
// //		}
// //	}

// 	// (tlino) added unfolding
// 	// if v, ok := d.bfdSessions[ifID]; ok {
// 	// 	v.Messages() <- p
// 	// 	return nil
// 	// }

// 	unfold acc(DataPlaneMutexInvariant(d), _)
// 	if v, ok := (d.bfdSessions)[ifID]; ok {
// 		// v.Messages() <- p
// 		fold acc(DataPlaneMutexInvariant(d), _)
// 		return nil
// 	}
// 	fold acc(DataPlaneMutexInvariant(d), _)
// 	// (tlino) golbals not supported
// 	// return noBFDSessionFound
// 	return noBFDSessionFound()
}

// (tlino) TODO: reverify
requires acc(DataPlaneMutexInvariant(d), _)
requires verifyutils.BytesAcc(origPacket)
requires cap(rawPkt) == bufSize
requires buffer.Mem()
requires s.Mem() && s.getRawPkt() == rawPkt
ensures verifyutils.BytesAcc(origPacket)
ensures buffer.Mem()
ensures s.Mem()
// (joao) s is now a *slayers.SCION
// func (d *DataPlane) processSCION(ingressID uint16, rawPkt []byte, s slayers.SCION,
func (d *DataPlane) processSCION(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	origPacket []byte, buffer gopacket.SerializeBuffer) (pr processResult, err error) //{

// 	// (joao) added `&` before `scionPacketProcessor` to make this type check
// 	p := &scionPacketProcessor{
// 		d:          d,
// 		ingressID:  ingressID,
// 		rawPkt:     rawPkt,
// 		scionLayer: s,
// 		origPacket: origPacket,
// 		buffer:     buffer,
// 	}
// 	p.process()
// }

type scionPacketProcessor struct {
	// d is a reference to the dataplane instance that initiated this processor.
	d *DataPlane
	// ingressID is the interface ID this packet came in, determined from the
	// socket.
	ingressID uint16
	// rawPkt is the raw packet, it is updated during processing to contain the
	// message to send out.
	rawPkt []byte
	// scionLayer is the SCION gopacket layer.
	// (joao) adapted to make this type check in Gobra
	// scionLayer slayers.SCION
	scionLayer *slayers.SCION
	// origPacket is the raw original packet, must not be modified.
	origPacket []byte
	// buffer is the buffer that can be used to serialize gopacket layers.
	buffer gopacket.SerializeBuffer

	// path is the raw SCION path. Will be set during processing.
	path *scion.Raw
	// hopField is the current hopField field, is updated during processing.
	hopField *path.HopField
	// infoField is the current infoField field, is updated during processing.
	infoField *path.InfoField
	// segmentChange indicates if the path segment was changed during processing.
	segmentChange bool
}

pred (p *scionPacketProcessor) Mem() {
	acc(p) &&
	acc(DataPlaneMutexInvariant(p.d), _) &&
	verifyutils.BytesAcc(p.origPacket) &&
	acc(p.infoField) &&
	path.HopFieldInv(p.hopField) &&
	p.buffer.Mem() &&
	p.scionLayer != nil && p.scionLayer.Mem() &&
	cap(p.rawPkt) == bufSize &&
	p.path != nil && p.path == p.scionLayer.getRawScionPath() &&
 	p.rawPkt == p.scionLayer.getRawPkt()
}

requires p.Mem()
decreases
func (p *scionPacketProcessor) foo() {
	unfold p.Mem()
	fold p.Mem()
}

// (tlino) Verified
// TODO: next. "slayers.UDP", "slayers.HopByHopExtn", slayers.EndToEndExtn, *SCION <: DecodingLayer
requires p.Mem() && scmpH.Mem() && scmpP.Mem()
ensures p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) packSCMP(scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer,
	cause error) (pr processResult, errRet error) {
	unfold p.Mem()
	// parse everything to see if the original packet was an SCMP error.
	var (
		scionLayer slayers.SCION
		// (joao) not supported yet
		// udpLayer   slayers.UDP
		// hbhExtn    slayers.HopByHopExtn
		// e2eExtn    slayers.EndToEndExtn
		scmpLayer  slayers.SCMP
	)
	// (joao) currently not supported, rewritten below
	// parser := gopacket.NewDecodingLayerParser(
	//	slayers.LayerTypeSCION, &scionLayer, &udpLayer, &hbhExtn, &e2eExtn, &scmpLayer,
	// )
	parser := gopacket.NewDecodingLayerParser(slayers.LayerTypeSCION())

	decoded@ := make([]gopacket.LayerType, 5)
	assert forall i int :: 0 <= i && i < len(decoded) ==> acc(&decoded[i])
	assert len(decoded) == 5
	if err := parser.DecodeLayers(p.origPacket, &decoded); err != nil {
		if _, ok := err.(gopacket.UnsupportedLayerType); !ok {
			assert len(decoded) == 5
			assert forall j int :: 0 <= j && j < len(decoded) ==> acc(&decoded[j])
			fold p.Mem()
			pr, errRet = processResult{}, serrors.WrapStr("decoding packet", err)
			fold pr.Mem()
			return 
		}
		assert len(decoded) == 5
		assert forall j int :: 0 <= j && j < len(decoded) ==> acc(&decoded[j])
	}
	assert forall i int :: 0 <= i && i < len(decoded) ==> acc(&decoded[i])
	assert len(decoded) == 5
	assert acc(&(decoded[len(decoded)-1]))
	// in reply to an SCMP error do nothing:
	// if decoded[len(decoded)-1] == slayers.LayerTypeSCMP && !scmpLayer.TypeCode.InfoMsg() {
	if decoded[len(decoded)-1] == slayers.LayerTypeSCMP() && !scmpLayer.TypeCode.InfoMsg() {
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("SCMP error for SCMP error pkt -> DROP", cause)
		fold pr.Mem()
		return 
	}

	// the quoted packet is the packet in its current state
	// (tlino) use getter to reduce verification overhead, see adapted code below
	// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	rp := p.rawPkt
	scionL := p.scionLayer
	scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	// (tlino) use getter for currINF to reduce verification overhead
	// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {
	if err := p.path.SetInfoField(p.infoField, int( unfolding p.path.Mem() in scion.getCurrINF(&(p.path.Base)))); err != nil {
		// (tlino) get back access to scionLayer and fold scionPacketProcessor
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("update info field", err)
		fold pr.Mem()
		return 
	}

	// (tlino) use getter for currHF to reduce verification overhead
	// if err := p.path.SetHopField(p.hopField, int(p.path.PathMeta.CurrHF)); err != nil {
	if err := p.path.SetHopField(p.hopField, int( unfolding p.path.Mem() in scion.getCurrHF(&(p.path.Base)))); err != nil {
		// (tlino) get back access to scionLayer and fold scionPacketProcessor
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		fold p.Mem()
		pr, errRet = processResult{}, serrors.WrapStr("update hop field", err)
		fold pr.Mem()
		return 
	}

	// (tlino) get back access to scionLayer
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())

	if err := p.buffer.Clear(); err != nil {
		fold p.Mem()
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}

	if err := p.scionLayer.SerializeTo(p.buffer, gopacket.SerializeOptions{}); err != nil {
		fold p.Mem()
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return
	}
	// quoteLen is used to limit the size of the quote buffer, the final quote
	// length is calculated inside the scmpPacker.
	quoteLen := len(p.origPacket)
	if quoteLen > slayers.MaxSCMPPacketLen {
		quoteLen = slayers.MaxSCMPPacketLen
	}
	quote := make([]byte, quoteLen)
	// (tlino) use varable b to make magic wands work. Magic wands don't work directly on p.buffer
	b := p.buffer
	updated := b.Bytes()
	assert verifyutils.BytesAcc(updated) --* b.Mem()
	unfold verifyutils.BytesAcc(updated)

	// (tlino) use Gobra's copy function
	// copy(quote[:len(updated)], updated)
	assume len(updated) <= len(quote)
	assert forall i int :: 0 <= i && i < len(quote) ==> acc(&quote[i])
	assert forall i int :: 0 <= i && i < len(updated) ==> acc(&updated[i], 1/100000)
	assert forall i int :: 0 <= i && i < len(updated) ==> &(quote[:len(updated)])[i] == &quote[i]
	assert forall i int :: 0 <= i && i < len(updated) ==> acc(&(quote[:len(updated)])[i])
	
	verifyutils.OutlineMemorySafeCopy(quote[:len(updated)], updated)

	// (tlino) use Gobra's copy function
	// copy(quote[len(updated):], p.origPacket[len(updated):quoteLen])
	unfold verifyutils.BytesAcc(p.origPacket)
	assume quoteLen <= len(p.origPacket)
	assert forall i int :: 0 <= i && i < (len(quote) - len(updated)) ==> &(quote[len(updated):])[i] == &quote[i + len(updated)]
	assert forall i int :: 0 <= i && i < (len(quote) - len(updated)) ==> acc(&(quote[len(updated):])[i])
	assert forall i int :: 0 <= i && i < len(p.origPacket) ==>  acc(&(p.origPacket)[i], 1/100000)
	assert forall i int :: 0 <= i && i < (quoteLen - len(updated)) ==> &((p.origPacket)[len(updated):quoteLen])[i] == &(p.origPacket)[i + len(updated)]
	assert forall i int :: 0 <= i && i < (quoteLen - len(updated)) ==> acc(&((p.origPacket)[len(updated):quoteLen])[i],  1/100000)
	verifyutils.OutlineMemorySafeCopy(quote[len(updated):], (p.origPacket)[len(updated):quoteLen])

	fold verifyutils.BytesAcc(updated)
	apply verifyutils.BytesAcc(updated) --* b.Mem()
	fold verifyutils.BytesAcc(p.origPacket)
	pr, errRet := packSCMP2(p.d, quote, p.origPacket, p.ingressID, p.scionLayer, b, scmpH, scmpP, cause)
	fold p.Mem()
}

// (tlino) partially verified
// (tlino) outlined part of packSCMP
requires acc(DataPlaneMutexInvariant(d), _)
requires forall i int :: 0 <= i && i < len(quote) ==> acc(&quote[i])
requires verifyutils.BytesAcc(origPacket)
requires scionLayer.Mem() && buffer.Mem() && scmpH.Mem() && scmpP.Mem()
ensures scionLayer.Mem() && buffer.Mem()
ensures verifyutils.BytesAcc(origPacket)
ensures scionLayer.getRawScionPath() == old(scionLayer.getRawScionPath())
ensures scionLayer.getRawPkt() == old(scionLayer.getRawPkt())
ensures pr.Mem()
decreases _
func packSCMP2(d *DataPlane, quote []byte, origPacket []byte, ingressID uint16, scionLayer *slayers.SCION, 
	buffer gopacket.SerializeBuffer, scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer, cause error) (pr processResult, err error) //{
// 	unfold acc(DataPlaneMutexInvariant(d), _)
	
// 	// (tlino) added parantheses to make it parse
// 	// _, external := p.d.external[p.ingressID]
// 	_, external := (d.external)[ingressID]

// 	// (tlino) replace scmpPacker with *scmpPacker
// 	// (tlino) replace &p.scionLayer, with p.scionLayer
// 	// (tlino) replace scmp.prepareSCMP with (&scmp).prepareSCMP
// 	// rawSCMP, err := scmpPacker{
// 	// 	internalIP: p.d.internalIP,
// 	// 	localIA:    p.d.localIA,
// 	// 	origPacket: p.origPacket,
// 	// 	ingressID:  p.ingressID,
// 	// 	scionL:     &p.scionLayer,
// 	// 	buffer:     p.buffer,
// 	// 	quote:      quote,
// 	// }.prepareSCMP(
// 	// 	scmpH,
// 	// 	scmpP,
// 	// 	external,
// 	// 	cause,
// 	// )

// 	fold verifyutils.BytesAcc(origPacket)
// 	fold verifyutils.BytesAcc(quote)
// 	assert verifyutils.BytesAcc(origPacket)
// 	assert verifyutils.BytesAcc(quote)

// 	scmp := &scmpPacker{
// 		internalIP: d.internalIP,
// 		localIA:    d.localIA,
// 		origPacket: origPacket,
// 		ingressID:  ingressID,
// 		scionL:     scionLayer,
// 		buffer:     buffer,
// 		quote:      quote,
// 	}
// 	// fold scmp.Mem()

// 	// rawSCMP, err := scmp.prepareSCMP(
// 	// 	scmpH,
// 	// 	scmpP,
// 	// 	external,
// 	// 	cause,
// 	// )
	
// 	// return processResult{OutPkt: rawSCMP}, err
// }

// (tlino) Verified
requires acc(p) && p.scionLayer != nil && (p.scionLayer).Mem() && (p.buffer).Mem() && verifyutils.BytesAcc(p.origPacket)
requires (cap(p.rawPkt) == bufSize) && p.rawPkt == p.scionLayer.getRawPkt()
requires acc(DataPlaneMutexInvariant(p.d), _)
ensures errRet != nil ==> acc(p) && (p.scionLayer).Mem() && (p.buffer).Mem() && verifyutils.BytesAcc(p.origPacket)
ensures errRet != nil ==> (cap(p.rawPkt) == bufSize) && p.rawPkt == p.scionLayer.getRawPkt()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) parsePath() (pr processResult, errRet error) {
	var ok bool
	unfold p.scionLayer.Mem()
	assert p.scionLayer.Path != nil
	p.path, ok = (p.scionLayer.Path).(*scion.Raw)
	if !ok {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) gobra doesn't support globals yet
		// return processResult{}, malformedPath
		fold p.scionLayer.Mem()
		pr, errRet = processResult{}, malformedPath()
		fold pr.Mem()
		return 
	}
	fold p.scionLayer.Mem()
	assert p.path == p.scionLayer.getRawScionPath()
	var err error

	// (tlino) we know that this holds, since (SCION).DecodeFromBytes has already decoded the path.
	// (tlino) a decoded path is always not nil and in this function of dynamic type *scion.Raw.
	// (tlino) however, (p.scionLayer.Path).(*scion.Raw) cannot deduce that p.path != nil.
	assume p.path != nil

	// (tlino) get access to path. Use new local variables to make gobra work
	pp := p.path
	scionL := p.scionLayer
	rp := p.rawPkt
	scionL.getPathAcc(pp, rp)
	assert pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	assert pp.Mem()

	p.hopField, err = p.path.GetCurrentHopField()
	if err != nil {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) get back access to p.scionLayer
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	p.infoField, err = p.path.GetCurrentInfoField()
	if err != nil {
		// TODO(lukedirtwalker) parameter problem invalid path?
		// (tlino) get back access to p.scionLayer
		apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
		pr, errRet = processResult{}, err
		fold pr.Mem()
		return 
	}
	// (tlino) get back access to p.scionLayer
	apply pp.Mem() --* (scionL.Mem() && pp == scionL.getRawScionPath() && rp == scionL.getRawPkt())
	fold p.Mem()
	if r, err := p.validateHopExpiry(); err != nil {
		unfold p.Mem()
		return r, err
	}
	if r, err := p.validateIngressID(); err != nil {
		unfold p.Mem()
		return r, err
	}
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

// (tlino) Verified
requires p.Mem()
ensures p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateHopExpiry() (pr processResult, errRet error) {
	// (joao) Add to separate this in two lines
	// expiration := util.SecsToTime(p.infoField.Timestamp).
	//	Add(path.ExpTimeToDuration(p.hopField.ExpTime))
	unfold  p.Mem()
	tmp := util.SecsToTime(p.infoField.Timestamp)
	expiration := tmp.Add(path.ExpTimeToDuration(unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ExpTime))
	expired := expiration.Before(time.Now())
	if !expired {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return
	} 
	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
	// 		slayers.SCMPCodePathExpired),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
	// 	serrors.New("expired hop", "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
	// 		"curr_inf", p.path.PathMeta.CurrINF, "curr_hf", p.path.PathMeta.CurrHF),
	// )
	fold p.Mem()
	scmpH := &slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
		slayers.SCMPCodePathExpired)}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
	fold scmpP.Mem()
	unfold p.Mem()

	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	e := serrors.New("expired hop", "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
		"curr_inf", p.path.GetCurrINF(), "curr_hf", p.path.GetCurrHF())
	
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	fold p.Mem()
	return p.packSCMP(scmpH, scmpP, e)
}

// (tlino) Verified
requires p.Mem()
ensures p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validateIngressID() (pr processResult, errRet error) {
	unfold p.Mem()
	pktIngressID := unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ConsIngress
	errCode := slayers.SCMPCodeUnknownHopFieldIngress
	if !p.infoField.ConsDir {
		pktIngressID = unfolding acc(path.HopFieldInv(p.hopField), 1/1000) in p.hopField.ConsEgress
		errCode = slayers.SCMPCodeUnknownHopFieldEgress
	}
	if p.ingressID != 0 && p.ingressID != pktIngressID {
		// (tlino) original code, adapted code is below
		// return p.packSCMP(
		// 	&slayers.SCMP{
		// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
		// 	},
		// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
		// 	serrors.New("ingress interface invalid",
		// 		"pkt_ingress", pktIngressID, "router_ingress", p.ingressID),
		// )
		fold p.Mem()
		scmpH := &slayers.SCMP{
				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
			}
		fold scmpH.Mem()
		scmpP := &slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()}
		fold scmpP.Mem()
		e := serrors.New("ingress interface invalid",
		 		"pkt_ingress", pktIngressID, "router_ingress", (unfolding acc(p.Mem(), 1/1000) in p.ingressID))
		return p.packSCMP(scmpH, scmpP, e)
	}
	fold p.Mem()
	pr, errRet = processResult{}, nil
	fold pr.Mem()
	return 
}

func (p *scionPacketProcessor) validateEgressID() (processResult, error) /*{
//	pktEgressID := p.egressInterface()
//	_, ih := p.d.internalNextHops[pktEgressID]
//	_, eh := p.d.external[pktEgressID]
//	if !ih && !eh {
//		errCode := slayers.SCMPCodeUnknownHopFieldEgress
//		if !p.infoField.ConsDir {
//			errCode = slayers.SCMPCodeUnknownHopFieldIngress
//		}
//		return p.packSCMP(
//			&slayers.SCMP{
//				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
//			},
//			&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
//			cannotRoute,
//		)
//	}
//
//	if !p.segmentChange {
//		return processResult{}, nil
//	}
//	// Check that the interface pair is valid on a segment switch.
//	// Having a segment change received from the internal interface is never valid.
//	ingress, egress := p.d.linkTypes[p.ingressID], p.d.linkTypes[pktEgressID]
//	switch {
//	case ingress == topology.Core && egress == topology.Child:
//		return processResult{}, nil
//	case ingress == topology.Child && egress == topology.Core:
//		return processResult{}, nil
//	case ingress == topology.Child && egress == topology.Child:
//		return processResult{}, nil
//	default:
//		return p.packSCMP(
//			&slayers.SCMP{
//				TypeCode: slayers.CreateSCMPTypeCode(
//					slayers.SCMPTypeParameterProblem,
//					slayers.SCMPCodeInvalidSegmentChange,
//				),
//			},
//			&slayers.SCMPParameterProblem{Pointer: p.currentInfoPointer()},
//			serrors.WithCtx(cannotRoute, "ingress_id", p.ingressID, "ingress_type", ingress,
//				"egress_id", pktEgressID, "egress_type", egress))
//	}
}
*/

// (tlino) Verified
requires p.Mem()
ensures p.Mem()
decreases
func (p *scionPacketProcessor) updateNonConsDirIngressSegID() (err error) {
	// against construction dir the ingress router updates the SegID, ifID == 0
	// means this comes from this AS itself, so nothing has to be done.
	// TODO(lukedirtwalker): For packets destined to peer links this shouldn't
	// be updated.
	unfold p.Mem()
	if !p.infoField.ConsDir && p.ingressID != 0 {
		unfold path.HopFieldInv(p.hopField)
		p.infoField.UpdateSegID(p.hopField.Mac)
		fold path.HopFieldInv(p.hopField)

		// get access to path, use new variables to make Gobra work
		assert p.scionLayer != nil
		assert p.path != nil
		sl := p.scionLayer
		pp := p.path
		rawPkt := p.rawPkt
		sl.getPathAcc(pp, rawPkt)
		assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
		assert pp.Mem()

		if err := p.path.SetInfoField(p.infoField, int( unfolding p.path.Mem() in scion.getCurrINF(&(p.path.Base)))); err != nil {
			apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
			fold p.Mem()
			return serrors.WrapStr("update info field", err)
		}
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rawPkt == sl.getRawPkt())
		assert p.path == p.scionLayer.getRawScionPath()
		assert p.rawPkt == p.scionLayer.getRawPkt()
		if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
			fold p.Mem()
			return err
		}
	}
	fold p.Mem()
	return nil
}
 
// (tlino) Verified
requires p.Mem()
ensures p.Mem()
decreases
func (p *scionPacketProcessor) currentInfoPointer() uint16 {
	// (tlino) needs to use getPathAcc to obtain access to p.path
	// return uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() +
	// 	scion.MetaLen + path.InfoLen*int(p.path.PathMeta.CurrINF))
	unfold p.Mem()
	
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	currINF := uint16(p.path.GetCurrINF())
	infoLen := uint16(path.InfoLen)
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	offset := uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() + scion.MetaLen)
	pointer := offset + infoLen * currINF
	fold p.Mem()
	return pointer
}

// (tlino) Verified
requires p.Mem()
ensures p.Mem()
decreases
func (p *scionPacketProcessor) currentHopPointer() uint16 {
	// (tlino) needs to use getPathAcc to obtain access to p.path
	// return  uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() +
	// 	scion.MetaLen + path.InfoLen*p.path.NumINF + path.HopLen*int(p.path.PathMeta.CurrHF))
	unfold p.Mem()
	
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()
	
	numInf := uint16(p.path.GetNumINF())
	currHF := uint16(p.path.GetCurrHF())
	infoLen := uint16(path.InfoLen)
	hopLen := uint16(path.HopLen)
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	offset := uint16(slayers.CmnHdrLen + p.scionLayer.AddrHdrLen() + scion.MetaLen)
	pointer := offset + infoLen * numInf + hopLen * currHF
	fold p.Mem()
	return pointer
}

// (tlino) not verified yet
// (joao) currently not supported
requires acc(p) && acc(p.infoField) && path.HopFieldInv(p.hopField)
requires acc(DataPlaneMutexInvariant(p.d), _)
ensures acc(p) && acc(p.infoField) && path.HopFieldInv(p.hopField)
func (p *scionPacketProcessor) verifyCurrentMAC() (processResult, error) //{
// 	if err := path.VerifyMAC(p.d.macFactory(), p.infoField, p.hopField); err != nil {
// 		return p.packSCMP(
// 			&slayers.SCMP{TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
// 				slayers.SCMPCodeInvalidHopFieldMAC),
// 			},
// 			&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
// 			serrors.WithCtx(err, "cons_dir", p.infoField.ConsDir, "if_id", p.ingressID,
// 				"curr_inf", p.path.PathMeta.CurrINF, "curr_hf", p.path.PathMeta.CurrHF,
// 				"seg_id", p.infoField.SegID),
// 		)
// 	}
// 	return processResult{}, nil
// }

// (tlino) partially verified
// (tlino) TODO: catch other errors of resolveLocalDst than noSVCBackend
// (tlino) for now we assume this method catches all possible errors from resolveLocalDst
requires acc(&p.d)
requires acc(&p.scionLayer)
requires acc(p.scionLayer.Mem(), 1/100)
requires acc(DataPlaneMutexInvariant(p.d), _)
ensures acc(&p.d)
ensures acc(&p.scionLayer)
ensures acc(p.scionLayer.Mem(), 1/200)
ensures resolveLocalDstErr == nil && e == nil ==> acc(address.Mem(), _)
func (p *scionPacketProcessor) resolveInbound() (address net.Addr, pr processResult, e error, ghost resolveLocalDstErr error) {
	a, err := p.d.resolveLocalDst(p.scionLayer)
	resolveLocalDstErr := err
	switch {
	// case errors.Is(err, noSVCBackend):
	// 	r, err := p.packSCMP(
	// 		&slayers.SCMP{
	// 			TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeDestinationUnreachable,
	// 				slayers.SCMPCodeNoRoute),
	// 		},
	// 		&slayers.SCMPDestinationUnreachable{}, err)
	// 	return nil, r, err
	default:
		return a, processResult{}, nil, resolveLocalDstErr
	}
}

// (tlino) Verified
requires p.Mem()
ensures p.Mem()
decreases
func (p *scionPacketProcessor) processEgress() error {
	// we are the egress router and if we go in construction direction we
	// need to update the SegID.

	unfold p.Mem()

	// (tlino) get access to p.path
	sl := p.scionLayer
	pp := p.path
	rp := p.rawPkt
	sl.getPathAcc(pp, rp)
	assert pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	assert pp.Mem()

	if p.infoField.ConsDir {
		unfold path.HopFieldInv(p.hopField)
		p.infoField.UpdateSegID(p.hopField.Mac)
		fold path.HopFieldInv(p.hopField)

		// (tlino) use helper function to access CurrINF
		// if err := p.path.SetInfoField(p.infoField, int(p.path.PathMeta.CurrINF)); err != nil {
		if err := p.path.SetInfoField(p.infoField, int(p.path.GetCurrINF())); err != nil {
			// TODO parameter problem invalid path
			apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
			fold p.Mem()
			return serrors.WrapStr("update info field", err)
		}
	}

	if err := p.path.IncPath(); err != nil {
		// TODO parameter problem invalid path
		apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
		fold p.Mem()
		return serrors.WrapStr("incrementing path", err)
	}
	apply pp.Mem() --* (sl.Mem() && pp == sl.getRawScionPath() && rp == sl.getRawPkt())
	if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
		fold p.Mem()
		return err
	}
	fold p.Mem()
	return nil
}

func (p *scionPacketProcessor) doXover() (processResult, error) // {
//	p.segmentChange = true
//	if err := p.path.IncPath(); err != nil {
//		// TODO parameter problem invalid path
//		return processResult{}, serrors.WrapStr("incrementing path", err)
//	}
//	var err error
//	if p.hopField, err = p.path.GetCurrentHopField(); err != nil {
//		// TODO parameter problem invalid path
//		return processResult{}, err
//	}
//	if p.infoField, err = p.path.GetCurrentInfoField(); err != nil {
//		// TODO parameter problem invalid path
//		return processResult{}, err
//	}
//	if err := updateSCIONLayer(p.rawPkt, p.scionLayer, p.buffer); err != nil {
//		return processResult{}, err
//	}
//	if r, err := p.validateHopExpiry(); err != nil {
//		return r, err
//	}
//	// verify the new block
//	if r, err := p.verifyCurrentMAC(); err != nil {
//		return r, serrors.WithCtx(err, "info", "after xover")
//	}
//	return processResult{}, nil
//}

// (joao) being able to write sequences of pure statements inside
// pure functions would be helpful here
requires pm > 0
requires acc(&p.infoField, pm) && acc(&p.infoField.ConsDir, pm)
requires acc(&p.hopField, pm) && acc(&p.hopField.ConsIngress, pm)
requires p.infoField.ConsDir ==> acc(&p.hopField.ConsEgress, pm)
ensures acc(&p.infoField, pm) && acc(&p.infoField.ConsDir, pm)
ensures acc(&p.hopField, pm) && acc(&p.hopField.ConsIngress, pm)
ensures p.infoField.ConsDir ==> acc(&p.hopField.ConsEgress, pm)
func (p *scionPacketProcessor) egressInterface(ghost pm perm) uint16 {
	if p.infoField.ConsDir {
		return p.hopField.ConsEgress
	}
	return p.hopField.ConsIngress
}

func (p *scionPacketProcessor) validateEgressUp() (processResult, error) /*{
//	egressID := p.egressInterface()
//	if v, ok := p.d.bfdSessions[egressID]; ok {
//		if !v.IsUp() {
//			scmpH := &slayers.SCMP{
//				TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeExternalInterfaceDown, 0),
//			}
//			var scmpP gopacket.SerializableLayer = &slayers.SCMPExternalInterfaceDown{
//				IA:   p.d.localIA,
//				IfID: uint64(egressID),
//			}
//			if _, external := p.d.external[egressID]; !external {
//				scmpH.TypeCode =
//					slayers.CreateSCMPTypeCode(slayers.SCMPTypeInternalConnectivityDown, 0)
//				scmpP = &slayers.SCMPInternalConnectivityDown{
//					IA:      p.d.localIA,
//					Ingress: uint64(p.ingressID),
//					Egress:  uint64(egressID),
//				}
//			}
//			return p.packSCMP(scmpH, scmpP, serrors.New("bfd session down"))
//		}
//	}
	return processResult{}, nil
}
*/

// (tlino) partially verified
// (tlino) TODO: use scionPacketProcessor.Mem in contracts, show termination
requires acc(&p.ingressID, 1/1000)
requires p.ingressID != 0 ==> acc(&p.hopField) && path.HopFieldInv(p.hopField) && acc(&p.infoField) && acc(p.infoField)
ensures acc(&p.ingressID, 1/1000)
ensures p.ingressID != 0 ==>  acc(&p.hopField) && path.HopFieldInv(p.hopField) && acc(&p.infoField) && acc(p.infoField)
func (p *scionPacketProcessor) handleIngressRouterAlert() (processResult, error) {
	if p.ingressID == 0 {
		return processResult{}, nil
	}
	unfold path.HopFieldInv(p.hopField)
	ingressAlert := (!p.infoField.ConsDir && p.hopField.EgressRouterAlert) ||
		(p.infoField.ConsDir && p.hopField.IngressRouterAlert)
	if !ingressAlert {
		fold path.HopFieldInv(p.hopField)
		return processResult{}, nil
	}
	p.hopField.IngressRouterAlert = false
	fold path.HopFieldInv(p.hopField)
	return p.handleSCMPTraceRouteRequest(p.ingressID)
}

// (joao) TODO: clean-up, minimize permissions, write postconditions
requires acc(&p.infoField) && acc(&p.infoField.ConsDir)
requires acc(&p.hopField) && acc(&p.hopField.EgressRouterAlert) && acc(&p.hopField.IngressRouterAlert)
requires acc(&p.hopField.ConsIngress) && acc(&p.hopField.ConsEgress)
requires acc(&p.d) && acc(&p.d.external) && /* (p.d.external != nil ==> acc(p.d.external)) */ acc(p.d.external)
func (p *scionPacketProcessor) handleEgressRouterAlert() (processResult, error) {
	egressAlert := (p.infoField.ConsDir && p.hopField.EgressRouterAlert) ||
		(!p.infoField.ConsDir && p.hopField.IngressRouterAlert)
	if !egressAlert {
		return processResult{}, nil
	}
	egressID := p.egressInterface(1/2)
	// (joao) put parentheses surrounding p.d.external to make it parse
	if _, ok := (p.d.external)[egressID]; !ok {
		return processResult{}, nil
	}
	p.hopField.EgressRouterAlert = false
	return p.handleSCMPTraceRouteRequest(egressID)
}


// (tlino) p.scionLayer.Payload is subsliced in scmpH and scmpP
func (p *scionPacketProcessor) handleSCMPTraceRouteRequest(
	interfaceID uint16) (processResult, error) // {
//	var scmpH slayers.SCMP
//	if err := scmpH.DecodeFromBytes(p.scionLayer.Payload, gopacket.NilDecodeFeedback); err != nil {
//		log.Debug("Parsing SCMP header of router alert", "err", err)
//		return processResult{}, nil
//	}
//	if scmpH.TypeCode != slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteRequest, 0) {
//		log.Debug("Packet with router alert, but not traceroute request",
//			"type_code", scmpH.TypeCode)
//		return processResult{}, nil
//	}
//	var scmpP slayers.SCMPTraceroute
//	if err := scmpP.DecodeFromBytes(scmpH.Payload, gopacket.NilDecodeFeedback); err != nil {
//		log.Debug("Parsing SCMPTraceroute", "err", err)
//		return processResult{}, nil
//	}
//	scmpH = slayers.SCMP{
//		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeTracerouteReply, 0),
//	}
//	scmpP = slayers.SCMPTraceroute{
//		Identifier: scmpP.Identifier,
//		Sequence:   scmpP.Sequence,
//		IA:         p.d.localIA,
//		Interface:  uint64(interfaceID),
//	}
//	return p.packSCMP(&scmpH, &scmpP, nil)
//}

// (tlino) Verified
requires p.Mem()
ensures p.Mem()
ensures pr.Mem()
decreases
func (p *scionPacketProcessor) validatePktLen() (pr processResult, errRet error) {
	unfold p.Mem()
	// (joao) adapted to avoid unfolding predicates
	// if int(p.scionLayer.PayloadLen) == len(p.scionLayer.Payload) {
	if int(p.scionLayer.getPayloadLen()) == len(p.scionLayer.LayerPayload()) {
		fold p.Mem()
		pr, errRet = processResult{}, nil
		fold pr.Mem()
		return 
	}
	// (tlino) original code, adapted code is below
	// return p.packSCMP(
	// 	&slayers.SCMP{
	// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
	// 			slayers.SCMPCodeInvalidPacketSize),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: 0},
	// 	serrors.New("bad packet size",
	// 		"header", p.scionLayer.PayloadLen, "actual", len(p.scionLayer.Payload)),
	// )

	scmpH := &slayers.SCMP{
			TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem,
			slayers.SCMPCodeInvalidPacketSize),
		}
	fold scmpH.Mem()
	scmpP := &slayers.SCMPParameterProblem{Pointer: 0}
	fold scmpP.Mem()
	e := serrors.New("bad packet size", 
		"header", p.scionLayer.getPayloadLen(), "actual", len(p.scionLayer.LayerPayload()))
	
	fold p.Mem()
	return p.packSCMP(scmpH, scmpP, e)
}

// (tlino) TODO: verify
requires acc(p)
requires acc(DataPlaneMutexInvariant(p.d), _)
requires verifyutils.BytesAcc(p.origPacket)
requires cap(p.rawPkt) == bufSize
requires (p.buffer).Mem()
requires p.scionLayer != nil && (p.scionLayer).Mem() && (p.scionLayer).getRawPkt() == p.rawPkt
ensures acc(p)
ensures verifyutils.BytesAcc(p.origPacket)
ensures cap(p.rawPkt) == bufSize
ensures (p.buffer).Mem()
ensures pr.Mem() --* (verifyutils.BytesAcc(p.rawPkt))
func (p *scionPacketProcessor) process() (pr processResult, errProcess error) //{
	// if r, err := p.parsePath(); err != nil {
	// 	// (tlino) create magic wand to later get back access to p.rawPkt
	// 	pr, errProcess := r, err

	// 	assert pr.Mem()

	// 	// get access to rawPkt, use new variables to make Gobra work
	// 	assert p.scionLayer.Mem()
	// 	sl := p.scionLayer
	// 	rp := p.rawPkt
	// 	sl.getRawPktAccWithoutPreservePath(rp)
	// 	assert verifyutils.BytesAcc(rp) --* (sl.Mem() && rp == sl.getRawPkt())
	// 	assert verifyutils.BytesAcc(rp)
	// 	assert p.rawPkt == rp
	// 	assert acc(&(p.rawPkt))
	// 	assert verifyutils.BytesAcc(p.rawPkt)

	// 	package pr.Mem() --* (verifyutils.BytesAcc(p.rawPkt)) {}

	// 	assert pr.Mem() --* (verifyutils.BytesAcc(rp))
	// 	assert pr.Mem() --* (verifyutils.BytesAcc(p.rawPkt))
	// 	return pr, errProcess
	// }
	// assume false

	// if r, err := p.validatePktLen(); err != nil {
	// 	return r, err
	// }
	// // (tlino) TODO: needs p.path.Mem()
	// // if err := p.updateNonConsDirIngressSegID(); err != nil {
	// // 	return processResult{}, err
	// // }
	// if r, err := p.verifyCurrentMAC(); err != nil {
	// 	return r, err
	// }
	// if r, err := p.handleIngressRouterAlert(); err != nil {
	// 	return r, err
	// }

	// (tlino) TODO: needs p.path.Mem()
	// // Inbound: pkts destined to the local IA.
	// if p.scionLayer.DstIA.Equal(p.d.localIA) && int(p.path.PathMeta.CurrHF)+1 == p.path.NumHops {
	// 	a, r, err := p.resolveInbound()
	// 	if err != nil {
	// 		return r, err
	// 	}
	//	// (tlino) insert here magic wand
	// 	return processResult{OutConn: p.d.internal, OutAddr: a, OutPkt: p.rawPkt}, nil
	// }

	// // Outbound: pkts leaving the local IA.
	// // BRTransit: pkts leaving from the same BR different interface.

	// // (joao) initially, we will assume that there is no crossOver
	// if p.path.IsXover() {
	// 	if r, err := p.doXover(); err != nil {
	// 		return r, err
	// 	}
	// }
	// if r, err := p.validateEgressID(); err != nil {
	// 	return r, err
	// }
	// // handle egress router alert before we check if it's up because we want to
	// // send the reply anyway, so that trace route can pinpoint the exact link
	// // that failed.
	// if r, err := p.handleEgressRouterAlert(); err != nil {
	// 	return r, err
	// }
	// if r, err := p.validateEgressUp(); err != nil {
	// 	return r, err
	// }

	// egressID := p.egressInterface()
	// if c, ok := p.d.external[egressID]; ok {
	// 	if err := p.processEgress(); err != nil {
	// 		return processResult{}, err
	// 	}
	//  // (tlino) insert here magic wand
	// 	return processResult{EgressID: egressID, OutConn: c, OutPkt: p.rawPkt}, nil
	// }

	// // ASTransit: pkts leaving from another AS BR.
	// if a, ok := p.d.internalNextHops[egressID]; ok {
	//	// (tlino) insert here magic wand
	// 	return processResult{OutConn: p.d.internal, OutAddr: a, OutPkt: p.rawPkt}, nil
	// }
	// errCode := slayers.SCMPCodeUnknownHopFieldEgress
	// if !p.infoField.ConsDir {
	// 	errCode = slayers.SCMPCodeUnknownHopFieldIngress
	// }
	// return p.packSCMP(
	// 	&slayers.SCMP{
	// 		TypeCode: slayers.CreateSCMPTypeCode(slayers.SCMPTypeParameterProblem, errCode),
	// 	},
	// 	&slayers.SCMPParameterProblem{Pointer: p.currentHopPointer()},
	// 	cannotRoute,
	// )
//}

requires acc(DataPlaneMutexInvariant(d), _)
requires s.Mem() && s.getRawPkt() == rawPkt
requires buffer.Mem()
ensures buffer.Mem()
ensures pr.Mem()
ensures pr.Mem() --* verifyutils.BytesAcc(rawPkt)
// (tlino) s is now a *slayers.SCION
// func (d *DataPlane) processOHP(ingressID uint16, rawPkt []byte, s slayers.SCION,
//	buffer gopacket.SerializeBuffer) (processResult, error) {
func (d *DataPlane) processOHP(ingressID uint16, rawPkt []byte, s *slayers.SCION,
	buffer gopacket.SerializeBuffer) (pr processResult, err error) //{

// 	// (tlino) add path variable
// 	p, ok := (s.Path).(*onehop.Path)
// 	if !ok {
// 		// TODO parameter problem -> invalid path // (tlino) original scion comment
// 		// (tlino) globals not supported
// 		// return processResult{}, malformedPath
// 		return processResult{}, malformedPath()
// 	}
// 	if !p.Info.ConsDir {
// 		// TODO parameter problem -> invalid path // (tlino) original scion comment
		
// 		// (tlino) globals not supported
// 		// return processResult{}, serrors.WrapStr(
// 		// 	"OneHop path in reverse construction direction is not allowed",
// 		// 	malformedPath, "srcIA", s.SrcIA, "dstIA", s.DstIA)

// 		return processResult{}, serrors.WrapStr(
// 			"OneHop path in reverse construction direction is not allowed",
// 			malformedPath(), "srcIA", s.SrcIA, "dstIA", s.DstIA)
// 	}
// 	if !d.localIA.Equal(s.DstIA) && !d.localIA.Equal(s.SrcIA) {
// 		// TODO parameter problem -> invalid path // (tlino) original scion comment
		
// 		// (tlino) globals not supported
// 		// return processResult{}, serrors.WrapStr("OneHop neither destined or originating from IA",
// 		// 	cannotRoute, "localIA", d.localIA, "srcIA", s.SrcIA, "dstIA", s.DstIA)

// 		return processResult{}, serrors.WrapStr("OneHop neither destined or originating from IA",
// 			cannotRoute(), "localIA", d.localIA, "srcIA", s.SrcIA, "dstIA", s.DstIA)
// 	}
// 	// OHP leaving our IA
// 	if d.localIA.Equal(s.SrcIA) {
// 		// if err := path.VerifyMAC(d.macFactory(), &p.Info, &p.FirstHop); err != nil {
// 		// 	// TODO parameter problem -> invalid MAC
// 		// 	return processResult{}, serrors.WithCtx(err, "type", "ohp")
// 		// }
// 		// p.Info.UpdateSegID(p.FirstHop.Mac)

// 		// if err := updateSCIONLayer(rawPkt, s, buffer); err != nil {
// 		// 	return processResult{}, err
// 		// }
// 		// // OHP should always be directed to the correct BR.
// 		// if c, ok := d.external[p.FirstHop.ConsEgress]; ok {
// 		// 	// buffer should already be correct
//		//  // (tlino) insert here magic wand
// 		// 	return processResult{EgressID: p.FirstHop.ConsEgress, OutConn: c, OutPkt: rawPkt}, nil
// 		// }
// 		// // TODO parameter problem invalid interface
// 		// return processResult{}, serrors.WithCtx(cannotRoute, "type", "ohp",
// 		// 	"egress", p.FirstHop.ConsEgress, "consDir", p.Info.ConsDir)

// 		// (tlino) dummy result, remove later
// 		return processResult{}, nil
// 	}

// 	// OHP entering our IA
// 	// p.SecondHop = path.HopField{
// 	// 	ConsIngress: ingressID,
// 	// 	ExpTime:     p.FirstHop.ExpTime,
// 	// }
// 	// p.SecondHop.Mac = path.MAC(d.macFactory(), &p.Info, &p.SecondHop)

// 	// if err := updateSCIONLayer(rawPkt, s, buffer); err != nil {
// 	// 	return processResult{}, err
// 	// }
// 	// a, err := d.resolveLocalDst(s)
// 	// if err != nil {
// 	// 	return processResult{}, err
// 	// }
//  // // (tlino) insert here magic wand
// 	// return processResult{OutConn: d.internal, OutAddr: a, OutPkt: rawPkt}, nil

// 	// (tlino) dummy result, remove later
// 	return processResult{}, nil
// }

// (tlino) reverify
// (tlino) TODO d.svc not supported yet
requires acc(s.Mem(), 1/100)
requires acc(DataPlaneMutexInvariant(d), _)
ensures acc(s.Mem(), 1/200)
ensures err == nil ==> acc(res.Mem(), _)
// (tlino) use *slayers.SCION instead of *slayers.SCION
// func (d *DataPlane) resolveLocalDst(s slayers.SCION) (net.Addr, error) 
func (d *DataPlane) resolveLocalDst(s *slayers.SCION) (res net.Addr, err error) //{
// 	// (joao) DstAddr expects a *SCION, not a SCION. Gobra does not support this
// 	dst, err := s.DstAddr()
// 	if err != nil {
// 		// TODO parameter problem. // (joao) this is an original comment from SCION
// 		return nil, err
// 	}
// 	// if v, ok := dst.(addr.HostSVC); ok {
// 	// 	// For map lookup use the Base address, i.e. strip the multi cast
// 	// 	// information, because we only register base addresses in the map.
// 	// 	// (tlino) svc not supported yet
// 	// 	// a, ok := d.svc.Any(v.Base())
// 	// 	// if !ok {
// 	// 	// 	return nil, noSVCBackend
// 	// 	// }
// 	// 	// return a, nil
// 	// }
// 	// res, isNew := addEndhostPort(dst, perm(1/200))
// 	// return res, nil
// }

// (tlino) Verified
requires dst.Mem()
ensures ret.Mem()
decreases
func addEndhostPort(dst net.Addr) (ret net.Addr) {
	if ip, ok := dst.(*net.IPAddr); ok {
		unfold dst.Mem()
		ret := &net.UDPAddr{IP: ip.IP, Port: topology.EndhostPort}
		fold ret.Mem()
		return ret
	}
	return dst
}

// (tlino) Verified
requires s.Mem() && buffer.Mem()
requires rawPkt == s.getRawPkt()
ensures s.Mem() && buffer.Mem()
ensures rawPkt == s.getRawPkt()
ensures s.getRawPkt() == old(s.getRawPkt()) && s.getRawScionPath() == old(s.getRawScionPath())
decreases
// (tlino) use *slayers.SCION instead of slayers.SCION
// func updateSCIONLayer(rawPkt []byte, s slayers.SCION, buffer gopacket.SerializeBuffer) error {
func updateSCIONLayer(rawPkt []byte, s *slayers.SCION, buffer gopacket.SerializeBuffer) (err error) {
	if err := buffer.Clear(); err != nil {
		return err
	}
	if err := s.SerializeTo(buffer, gopacket.SerializeOptions{}); err != nil {
		return err
	}
	// TODO(lukedirtwalker): We should add a method to the scion layers
	// which can write into the existing buffer, see also the discussion in
	// https://fsnets.slack.com/archives/C8ADBBG0J/p1592805884250700
	
	// (tlino) obtain access to rawPkt
	assert rawPkt == s.getRawPkt()
	s.getRawPktAcc(rawPkt)
	assert verifyutils.BytesAcc(rawPkt) --* (s.Mem() && rawPkt == s.getRawPkt() && s.getRawScionPath() == old(s.getRawScionPath()))
	assert verifyutils.BytesAcc(rawPkt)
	unfold verifyutils.BytesAcc(rawPkt)

	rawContents := buffer.Bytes()
	assert verifyutils.BytesAcc(rawContents) --* buffer.Mem()
	unfold verifyutils.BytesAcc(rawContents)
	// (tlino) use Gobra's copy
	// copy(rawPkt[:len(rawContents)], rawContents)

	// rawContents cannot have a higher length than rawPkt, since it only contains the SCION fields without the payload
	assume len(rawContents) <= len(rawPkt)
	assert forall i int :: { rawContents[i] } (0 <= i && i < len(rawContents)) ==> acc(&rawContents[i], 1/100000)
	assert forall i int :: { rawPkt[i] } (0 <= i && i < len(rawPkt)) ==> acc(&rawPkt[i])
	assert forall i int :: 0 <= i && i < len(rawContents) ==> &(rawPkt[:len(rawContents)])[i] == &rawPkt[i]
	assert forall i int :: 0 <= i && i < len(rawContents) ==> acc(&(rawPkt[:len(rawContents)])[i])

	verifyutils.OutlineMemorySafeCopy(rawPkt[:len(rawContents)], rawContents)

	fold verifyutils.BytesAcc(rawPkt)
	apply verifyutils.BytesAcc(rawPkt) --* (s.Mem() && rawPkt == s.getRawPkt() && s.getRawScionPath() == old(s.getRawScionPath()))

	fold verifyutils.BytesAcc(rawContents)
	apply verifyutils.BytesAcc(rawContents) --* buffer.Mem()

	return nil
}

type bfdSend struct {
	conn             BatchConn
	srcAddr, dstAddr *net.UDPAddr
	srcIA, dstIA     addr.IA
//	macFactory       func() hash.Hash
	ifID             uint16
}

//pure func (b *bfdSend) String() string {
//	return b.srcAddr.String()
//}

//func (b *bfdSend) Send(bfd *layers.BFD) error {
//	scn := &slayers.SCION{
//		Version:      0,
//		TrafficClass: 0xb8,
//		FlowID:       0xdead,
//		NextHdr:      common.L4BFD,
//		SrcIA:        b.srcIA,
//		DstIA:        b.dstIA,
//	}
//
//	if err := scn.SetSrcAddr(&net.IPAddr{IP: b.srcAddr.IP}); err != nil {
//		return err
//	}
//	if err := scn.SetDstAddr(&net.IPAddr{IP: b.dstAddr.IP}); err != nil {
//		return err
//	}
//
//	if b.ifID == 0 {
//		scn.PathType = slayers.PathTypeEmpty
//		scn.Path = &empty.Path{}
//	} else {
//		ohp := &onehop.Path{
//			Info: path.InfoField{
//				ConsDir: true,
//				// Subtract 10 seconds to deal with possible clock drift.
//				Timestamp: uint32(time.Now().Unix() - 10),
//			},
//			FirstHop: path.HopField{
//				ConsEgress: b.ifID,
//				ExpTime:    hopFieldDefaultExpTime,
//			},
//		}
//		ohp.FirstHop.Mac = path.MAC(b.macFactory(), &ohp.Info, &ohp.FirstHop)
//		scn.PathType = slayers.PathTypeOneHop
//		scn.Path = ohp
//	}
//
//	buffer := gopacket.NewSerializeBuffer()
//	err := gopacket.SerializeLayers(buffer, gopacket.SerializeOptions{FixLengths: true},
//		scn, bfd)
//	if err != nil {
//		return err
//	}
//	msg := ipv4.Message{}
//	msg.Buffers = make([][]byte, 1)
//	raw := buffer.Bytes()
//	msg.Buffers[0] = make([]byte, len(raw))
//	copy(msg.Buffers[0], raw)
//	msg.N = len(raw)
//	msg.Addr = b.dstAddr
//	_, err = b.conn.WriteBatch(underlayconn.Messages{msg})
//	return err
//}

//type pathUpdater interface {
//	update(p *scion.Raw) error
//}

type scmpPacker struct {
	internalIP net.IP
	localIA    addr.IA
	origPacket []byte
	ingressID  uint16

	scionL *slayers.SCION
	buffer gopacket.SerializeBuffer
	quote  []byte
}

pred (s scmpPacker) Mem() {
	verifyutils.BytesAcc(s.origPacket) &&
	s.scionL != nil && s.scionL.Mem() &&
	s.buffer != nil && s.buffer.Mem() &&
	verifyutils.BytesAcc(s.quote)
}

requires s.Mem() && scmpH.Mem() && scmpP.Mem()
ensures s.scionL.Mem()
ensures b != nil ==> verifyutils.BytesAcc(b)
decreases _
// (tlino) use *scmpPacker instead of scmpPacker
func (s scmpPacker) prepareSCMP(scmpH *slayers.SCMP, scmpP gopacket.SerializableLayer, 
	incPath bool, cause error) (b []byte, e error) //{

	// // We use the original packet but put the already updated path, because usually a router will
	// // not keep a copy of the original/unmodified packet around.
	// unfold s.Mem()
	// unfold s.scionL.Mem()
	// // (tlino) access Raw over tmp, added check
	// // (tlino) find more elegant solution
	// // pathRaw := (s.scionL.Path).(*scion.Raw).Raw
	// tmpPath, ok := (s.scionL.Path).(*scion.Raw)
	// // if !ok {
	// // 	assume false
	// // 	panic(e)
	// // }

	// assume typeOf(tmpPath) == *scion.Raw && tmpPath != nil
	// unfold tmpPath.Mem()
	// pathRaw := tmpPath.Raw
	// assert forall i int :: 0 <= i && i < len(pathRaw) ==> acc(&pathRaw[i])
	// // (tlino) use gopacket.NilDecodeFeedback{} instead of global gopacket.NilDecodeFeedback
	// // if err := s.scionL.DecodeFromBytes(s.origPacket, gopacket.NilDecodeFeedback); err != nil {
	// // 	panic(err)
	// // }
	
	// fold tmpPath.Mem()
	// unfold verifyutils.BytesAcc(s.origPacket)
	// df := gopacket.NilDecodeFeedback{}
	// fold df.Mem()
	// if err := s.scionL.DecodeFromBytes(s.origPacket, df); err != nil {
	// 	assume false
	// 	panic(err)
	// }

	// unfold s.scionL.Mem()
	// path := (s.scionL.Path).(*scion.Raw)

 	// path.Raw = pathRaw
// 	decPath, err := path.ToDecoded()
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "decoding raw path")
// 	}
// 	s.scionL.Path = decPath
// 	if err := decPath.Reverse(); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "reversing path for SCMP")
// 	}
// 	if incPath || decPath.IsXover() {
// 		infoField := decPath.InfoFields[decPath.PathMeta.CurrINF]
// 		if infoField.ConsDir {
// 			hopField := decPath.HopFields[decPath.PathMeta.CurrHF]
// 			infoField.UpdateSegID(hopField.Mac)
// 		}
// 		if err := decPath.IncPath(); err != nil {
// 			return nil, serrors.Wrap(cannotRoute, err, "details", "incrementing path for SCMP")
// 		}
// 	}

// 	s.scionL.DstIA = s.scionL.SrcIA
// 	s.scionL.SrcIA = s.localIA
// 	srcA, err := s.scionL.SrcAddr()
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "extracting src addr")
// 	}
// 	if err := s.scionL.SetDstAddr(srcA); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "setting dest addr")
// 	}
// 	if err := s.scionL.SetSrcAddr(&net.IPAddr{IP: s.internalIP}); err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "setting src addr")
// 	}
// 	s.scionL.NextHdr = common.L4SCMP

// 	scmpH.SetNetworkLayerForChecksum(s.scionL)

// 	if err := s.buffer.Clear(); err != nil {
// 		return nil, err
// 	}

// 	sopts := gopacket.SerializeOptions{
// 		ComputeChecksums: true,
// 		FixLengths:       true,
// 	}
// 	scmpLayers := []gopacket.SerializableLayer{s.scionL, scmpH, scmpP}
// 	if cause != nil {
// 		add quote for errors.
// 		hdrLen := slayers.CmnHdrLen + s.scionL.AddrHdrLen() + s.scionL.Path.Len()
// 		switch scmpH.TypeCode.Type() {
// 		case slayers.SCMPTypeExternalInterfaceDown:
// 			hdrLen += 20
// 		case slayers.SCMPTypeInternalConnectivityDown:
// 			hdrLen += 28
// 		default:
// 			hdrLen += 8
// 		}
// 		maxQuoteLen := slayers.MaxSCMPPacketLen - hdrLen
// 		if len(s.quote) > maxQuoteLen {
// 			s.quote = s.quote[:maxQuoteLen]
// 		}
// 		scmpLayers = append(scmpLayers, gopacket.Payload(s.quote))
// 	}
// 	err = gopacket.SerializeLayers(s.buffer, sopts, scmpLayers...)
// 	if err != nil {
// 		return nil, serrors.Wrap(cannotRoute, err, "details", "serializing SCMP message")
// 	}
// 	return s.buffer.Bytes(), scmpError{TypeCode: scmpH.TypeCode, Cause: cause}
//}

type segIDUpdater struct{}

//func (segIDUpdater) update(p *scion.Raw) error {
//	cHF, err := p.GetCurrentHopField()
//	if err != nil {
//		return err
//	}
//	cIF, err := p.GetCurrentInfoField()
//	if err != nil {
//		return err
//	}
//	cIF.UpdateSegID(cHF.Mac)
//	return nil
//}

type pathIncrementer struct{}

//func (pathIncrementer) update(p *scion.Raw) error {
//	return p.IncPath()
//}

//func interfaceToMetricLabels(id uint16, localIA addr.IA,
//	neighbors map[uint16]addr.IA) prometheus.Labels {
//
//	if id == 0 {
//		return prometheus.Labels{
//			"isd_as":          localIA.String(),
//			"interface":       "internal",
//			"neighbor_isd_as": localIA.String(),
//		}
//	}
//	return prometheus.Labels{
//		"isd_as":          localIA.String(),
//		"interface":       strconv.FormatUint(uint64(id), 10),
//		"neighbor_isd_as": neighbors[id].String(),
//	}
//}

//func serviceMetricLabels(localIA addr.IA, svc addr.HostSVC) prometheus.Labels {
//	return prometheus.Labels{
//		"isd_as":  localIA.String(),
//		"service": svc.BaseString(),
//	}
//}